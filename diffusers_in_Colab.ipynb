{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suzukimain/diffusers_in_Colab/blob/main/diffusers_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>Detail</summary>\n",
        "\n",
        ">Disclaimer:\n",
        "\n",
        "* This project was created as a hobby and is not intended for commercial use.\n",
        "\n",
        "* I am not responsible for any problems that may arise from the use of this project.\n",
        "\n",
        "* Please check the [License](https://github.com/suzukimain/diffusers_in_Colab/blob/main/LICENSE) for more information.\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "\n",
        ">Project Objectives\n",
        "\n",
        "1. Personal learning of programming.\n",
        "\n",
        "2. An image generation notebook based on diffusers.\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "\n",
        ">Acknowledgment\n",
        "\n",
        "I used open source resources and free tools in the creation of this project. These resources and tools made this possible.\\\n",
        "I would like to take this opportunity to thank the open source community and those who provided free tools.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "irVVq_Sup6N6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eicnuls7qg7l"
      },
      "outputs": [],
      "source": [
        "#@title   (option) Mount GoogleDrive { run: \"auto\", display-mode: \"form\"}\n",
        "Conect_GoogleDrive = True  # @param {type:\"boolean\"}\n",
        "\n",
        "conect_drive=False\n",
        "\n",
        "from google.colab import drive\n",
        "if Conect_GoogleDrive:\n",
        "    if not drive._os.path.ismount('/content/drive'):\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            conect_drive=True\n",
        "        except:\n",
        "            print(\"GoogleDrive is not mounted\")\n",
        "            conect_drive=False\n",
        "else:\n",
        "    if drive._os.path.ismount('/content/drive'):\n",
        "        drive.flush_and_unmount()\n",
        "        conect_drive=False\n",
        "        print(\"GoogleDrive unmounted\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  #Step.1 Runtime Setup {display-mode: \"form\"}\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "\n",
        "import os\n",
        "import queue\n",
        "import subprocess\n",
        "import sys\n",
        "import threading\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import codecs\n",
        "import datetime\n",
        "import difflib\n",
        "import gc\n",
        "import glob\n",
        "import imageio\n",
        "import importlib\n",
        "import inspect\n",
        "import jax\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import urllib.request\n",
        "from base64 import b64encode\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "from requests import HTTPError\n",
        "from torch import Generator\n",
        "from typing import Any, Dict, List, Literal, Optional, Union\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    AutoModelForCausalLM,\n",
        "    CLIPTokenizer,\n",
        "    AutoTokenizer,\n",
        "    FlaxAutoModelForCausalLM\n",
        ")\n",
        "from transformers import logging as tf_logging\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from PIL import Image, PngImagePlugin\n",
        "from google.colab import drive\n",
        "from huggingface_hub import hf_hub_download\n",
        "import yaml\n",
        "\n",
        "\n",
        "\n",
        "class runtime_func:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        NOTE:\n",
        "        Functions that should be included in the `basic_config` class are needed in the `install_packages` class, so these functions are separated into the `runtime_func` class.\n",
        "        This is because the `install_packages` class is executed before the `basic_config` class is executed, so these functions are separated and inherited later.\n",
        "        \"\"\"\n",
        "        self.device_type = self.device_type_check()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def module_version(module_name):\n",
        "        try:\n",
        "            version = importlib.metadata.version(module_name)\n",
        "            return re.match(r\"^\\d+\\.\\d+\\.\\d+\", version).group(0)\n",
        "        except importlib.metadata.PackageNotFoundError:\n",
        "            return None\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def device_type_check():\n",
        "        _device_type = jax.devices()[0].device_kind\n",
        "        if \"TPU\" in _device_type:\n",
        "            return \"TPU\"\n",
        "        elif \"cpu\" in _device_type:\n",
        "            return \"cpu\"\n",
        "        else:\n",
        "            return \"cuda\"\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def is_url_valid(url) -> bool:\n",
        "        response = requests.head(url)\n",
        "        try:\n",
        "            response.raise_for_status()\n",
        "        except requests.RequestException:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "        finally:\n",
        "            logger.debug(f\"response.status_code: {response.status_code}\")\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def custom_logger(DEBUG=False):\n",
        "        format = '%(levelname)s:<cell line: %(lineno)d> <funcName: %(funcName)s>: %(message)s'\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.propagate = False\n",
        "        if not logger.handlers:\n",
        "            formatter = logging.Formatter(format)\n",
        "            handler = logging.StreamHandler()\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "        if DEBUG:\n",
        "            logger.setLevel(logging.DEBUG)\n",
        "        else:\n",
        "            logger.setLevel(logging.WARNING)\n",
        "        return logger\n",
        "\n",
        "\n",
        "run_func = runtime_func()\n",
        "device_type = run_func.device_type\n",
        "logger = run_func.custom_logger(DEBUG)\n",
        "\n",
        "\n",
        "\n",
        "class ProcessBarRun:\n",
        "    \"\"\"\n",
        "    Example:\n",
        "    if __name__ == \"__main__\":\n",
        "    bar = ProcessBarRun(total=11)\n",
        "\n",
        "    for s in range(4):\n",
        "        bar.bar_update(3)\n",
        "        time.sleep(1)\n",
        "\n",
        "    bar.bar_update(exit=True)\n",
        "\n",
        "    Args:\n",
        "    desc:str = \"Running\",\n",
        "    default_desc:str = \"Running\",\n",
        "    fin_desc = \"\",\n",
        "    pofix:str=\"\",\n",
        "    default_pofix:str = \"\",\n",
        "    fin_pofix= \"Finish!\",\n",
        "    desc_dot:bool = False,\n",
        "    pofix_dot:bool = False\n",
        "\n",
        "    If the download_bar is true, the URL and save_path are required\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 total: int = 0,\n",
        "                 desc: str = \"\",\n",
        "                 default_desc: str = \"\",\n",
        "                 fin_desc=\"\",\n",
        "                 pofix: str = \"\",\n",
        "                 default_pofix: str = \"\",\n",
        "                 fin_pofix=\"Finish!\",\n",
        "                 desc_dot: bool = False,\n",
        "                 pofix_dot: bool = False,\n",
        "                 download_bar:bool = False,\n",
        "                 url:str = \"\",\n",
        "                 save_path:str = \"\",\n",
        "                 **ex_word):\n",
        "\n",
        "        self.total = total\n",
        "        self.default_desc = default_desc\n",
        "        self.default_pofix = default_pofix\n",
        "        self.fin_desc = fin_desc\n",
        "        self.fin_pofix = fin_pofix\n",
        "        self.desc_dot = desc_dot\n",
        "        self.pofix_dot = pofix_dot\n",
        "        self.ex_word = ex_word\n",
        "        self.queue_obj = queue.Queue()\n",
        "        self._count = 0\n",
        "        self._run_count = 0\n",
        "        self.dot_count = 0\n",
        "        self.max_dots = 5\n",
        "        self.desc = desc\n",
        "        self.pofix = pofix\n",
        "        self.base_desc_txt = \"\"\n",
        "        self.base_pofix_txt = \"\"\n",
        "        self.stop_event = threading.Event()\n",
        "        self.stop_dot = threading.Event()\n",
        "        self.tqdm_lock = threading.Lock()\n",
        "        self.tqdm_obj = tqdm(total=total, desc=desc, postfix=pofix)\n",
        "        self.arg_update(desc=desc, postfix=pofix, **ex_word)\n",
        "        self.dot_thread = threading.Thread(target=self.prosess_dot)\n",
        "        self.dot_thread.start()\n",
        "\n",
        "\n",
        "    def __del__(self):\n",
        "        self.stop()\n",
        "\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.stop()\n",
        "\n",
        "\n",
        "    def stop(self):\n",
        "        self.stop_event.set()\n",
        "        self.stop_dot.set()\n",
        "        self.tqdm_obj.n = self.total\n",
        "        if self.fin_desc:\n",
        "            setattr(self.tqdm_obj,\"desc\",self.fin_desc)\n",
        "        if self.fin_pofix:\n",
        "            setattr(self.tqdm_obj,\"postfix\",self.fin_pofix)\n",
        "        self.tqdm_obj.refresh()\n",
        "        self.tqdm_obj.close()\n",
        "\n",
        "\n",
        "    def arg_update(self, *ex_word, **input_dict):\n",
        "        for extra_word in ex_word:\n",
        "            if isinstance(extra_word, dict):\n",
        "                for _key, _value in extra_word.items():\n",
        "                    setattr(self, _key, _value)\n",
        "        for key, value in input_dict.items():\n",
        "            if hasattr(self, key):\n",
        "                setattr(self, key, value)\n",
        "\n",
        "\n",
        "    def run_downlaod_with_bar(self):\n",
        "        with self.tqdm_lock:\n",
        "            for chunk in response.iter_content(chunk_size=4096):\n",
        "                self.tqdm_obj.write(chunk)\n",
        "\n",
        "\n",
        "    def prosess_dot(self,):\n",
        "        \"\"\"\n",
        "        NOTE:\n",
        "        set_description_str and set_description_str are not used,\n",
        "        because they cannot be used in the case of the download_with_bar function.\n",
        "        \"\"\"\n",
        "        self.dot_count = 0\n",
        "        chenge_check = False\n",
        "        while not self.stop_dot.is_set():\n",
        "            for num in range(self.max_dots):\n",
        "                with self.tqdm_lock:\n",
        "                    dot_txt = \".\" * num\n",
        "                    if self.desc and self.desc_dot:\n",
        "                        desc_dot_txt = dot_txt\n",
        "                    else:\n",
        "                        desc_dot_txt = \"\"\n",
        "\n",
        "                    if self.pofix and self.pofix_dot:\n",
        "                        pofix_dot_txt = dot_txt\n",
        "                    else:\n",
        "                        pofix_dot_txt = \"\"\n",
        "\n",
        "                    setattr(self.tqdm_obj, \"desc\", self.desc + desc_dot_txt)\n",
        "                    setattr(self.tqdm_obj, \"postfix\", self.pofix + pofix_dot_txt)\n",
        "                    self.tqdm_obj.refresh()\n",
        "\n",
        "                    if self.stop_dot.is_set():\n",
        "                        break\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "\n",
        "    def bar_update(\n",
        "            self,\n",
        "            update_rate: int = 1,\n",
        "            exit: bool = False,\n",
        "            desc = None,\n",
        "            pofix = None,\n",
        "            desc_dot = None,\n",
        "            pofix_dot= None):\n",
        "        \"\"\"\n",
        "        args:\n",
        "        desc : str\n",
        "        pofix : str\n",
        "        desc_dot : bool\n",
        "        pofix_dot : bool\n",
        "        \"\"\"\n",
        "        self.desc = desc or self.desc or self.default_desc\n",
        "        self.pofix = pofix or self.pofix or self.default_pofix\n",
        "        self.desc_dot = desc_dot or self.desc_dot\n",
        "        self.pofix_dot = pofix_dot or self.pofix_dot\n",
        "        self.tqdm_obj.update(int(update_rate))\n",
        "        self.tqdm_obj.set_description_str(self.desc)\n",
        "        self.tqdm_obj.set_postfix_str(self.pofix)\n",
        "        self.tqdm_obj.refresh()\n",
        "        if exit:\n",
        "            self.stop()\n",
        "\n",
        "\n",
        "\n",
        "class config_check:\n",
        "    base_config_json = \"/tmp/diffusers_in_colab_config.json\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def get_json_dict(self):\n",
        "        \"\"\"Retrieve the JSON dictionary from the config file.\"\"\"\n",
        "        config_dict = {}\n",
        "        if os.path.isfile(self.base_config_json):\n",
        "            try:\n",
        "                with open(self.base_config_json, \"r\") as basic_json:\n",
        "                    config_dict = json.load(basic_json)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "        return config_dict\n",
        "\n",
        "\n",
        "    def update_json_dict(self, key, value):\n",
        "        \"\"\"Update the JSON dictionary with a new key-value pair.\"\"\"\n",
        "        basic_json_dict = self.get_json_dict()\n",
        "        basic_json_dict[key] = value\n",
        "        with open(self.base_config_json, \"w\") as json_file:\n",
        "            json.dump(basic_json_dict, json_file, indent=4)\n",
        "\n",
        "\n",
        "    def check_func_hist(self,*return_key, **kwargs):\n",
        "        \"\"\"\n",
        "        Check and optionally update the history of a given element.\n",
        "\n",
        "        Args:\n",
        "            *return_key (str): Variable for which to get the history.\n",
        "            **kwargs: Keyword arguments for additional options.\n",
        "                - update (bool): Whether to update the dictionary. Default is True.\n",
        "                - return_value (bool): Whether to return the element value. Default is False.\n",
        "                - key (str): Specific key to look up in the dictionary.\n",
        "                - value (Any): Value to be matched or updated in the dictionary.\n",
        "\n",
        "        Returns:\n",
        "            Any: The historical value if `return_value` is True, or a boolean indicating\n",
        "                 if the value matches the historical value.\n",
        "        \"\"\"\n",
        "        update = kwargs.pop(\"update\", True)\n",
        "        return_value = kwargs.pop(\"return_value\", False)\n",
        "        if kwargs:\n",
        "            if \"key\" in kwargs:\n",
        "                key = kwargs[\"key\"]\n",
        "                if \"value\" in kwargs:\n",
        "                    value = kwargs[\"value\"]\n",
        "                else:\n",
        "                    value = None\n",
        "                    update = False\n",
        "                    return_value = True\n",
        "            else:\n",
        "                key, value = next(iter(kwargs.items()))\n",
        "        elif return_key:\n",
        "            key, value = return_key[0], None\n",
        "            update = False\n",
        "            return_value = True\n",
        "        else:\n",
        "            raise TypeError(\"Missing 'key' argument.\")\n",
        "\n",
        "        basic_json_dict = self.get_json_dict()\n",
        "        hist_value = basic_json_dict.get(key)\n",
        "        if hist_value == value:\n",
        "            value_match = True\n",
        "        else:\n",
        "            value_match = False\n",
        "\n",
        "        if update:\n",
        "            self.update_json_dict(key, value)\n",
        "\n",
        "        if return_value:\n",
        "            return hist_value\n",
        "        else:\n",
        "            return value_match\n",
        "\n",
        "\n",
        "\n",
        "class install_packages(runtime_func):\n",
        "    repo_url = \"https://github.com/huggingface/diffusers.git\"\n",
        "    repo_dir = \"diffusers\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def torch_install_packages(self):\n",
        "        __sub_process_list =[\n",
        "            (f'if [ ! -d {self.repo_dir} ]; then git clone {self.repo_url} {self.repo_dir}; fi', 'Cloning diffusers'),\n",
        "            (f'cd {self.repo_dir} && pip install .[torch]', 'Installing diffusers'),\n",
        "        ]\n",
        "        if self.device_type == \"cuda\":\n",
        "            cuda_ex_prosess = (f'pip install accelerate', 'Installing accelerate')\n",
        "            __sub_process_list.append(cuda_ex_prosess)\n",
        "\n",
        "        torch_install = ProcessBarRun(\n",
        "            total=len(__sub_process_list),\n",
        "            desc = \"Installing packages\",\n",
        "            pofix = \"Install process Start\",\n",
        "            pofix_dot = True,\n",
        "            )\n",
        "\n",
        "        for torch_sub_process,update_pofix in __sub_process_list:\n",
        "            torch_install.arg_update(pofix=update_pofix)\n",
        "            subprocess.run(torch_sub_process, shell=True, check=True)\n",
        "            torch_install.bar_update()\n",
        "\n",
        "        torch_install.bar_update(exit=True)\n",
        "\n",
        "\n",
        "    def flax_install_packages(self):\n",
        "        \"\"\"\n",
        "        'natsort' is not installed by default in the TPUv2 runtime\n",
        "        \"\"\"\n",
        "        __sub_process_list = [\n",
        "            (f'if [ ! -d {self.repo_dir} ]; then git clone {self.repo_url} {self.repo_dir}; fi', 'Cloning diffusers'),\n",
        "            (f'cd {self.repo_dir} && pip install .[flax]', 'Installing diffusers'),\n",
        "            ('pip uninstall -y tensorflow', 'Uninstalling tensorflow'),\n",
        "            ('pip install tensorflow-cpu', 'Installing tensorflow-cpu'),\n",
        "            ('pip install natsort', 'Installing other librarys')\n",
        "        ]\n",
        "\n",
        "        flax_install = ProcessBarRun(\n",
        "            total=len(__sub_process_list),\n",
        "            desc = \"Installing packages\",\n",
        "            pofix = \"Install process Start\",\n",
        "            pofix_dot = True,\n",
        "            )\n",
        "\n",
        "        for flax_sub_process,up_pofix in __sub_process_list:\n",
        "            flax_install.arg_update(pofix=up_pofix)\n",
        "            subprocess.run(flax_sub_process, shell=True, check=True)\n",
        "            flax_install.bar_update()\n",
        "\n",
        "        flax_install.bar_update(exit=True)\n",
        "\n",
        "\n",
        "    def package_install(self):\n",
        "\n",
        "        if self.device_type == \"TPU\":\n",
        "            self.flax_install_packages()\n",
        "        else:\n",
        "            self.torch_install_packages()\n",
        "\n",
        "\n",
        "Step1 = ProcessBarRun(\n",
        "    total=4,\n",
        "    desc = f\"{device_type} runtime setting\",\n",
        "    pofix_dot = True)\n",
        "\n",
        "Step1.bar_update(pofix=\"Installing libraries\")\n",
        "\n",
        "install_packages().package_install()\n",
        "\n",
        "Step1.bar_update(pofix=\"Importing libraries\")\n",
        "\n",
        "\n",
        "\n",
        "from natsort import natsorted\n",
        "\n",
        "import diffusers\n",
        "from diffusers import (\n",
        "    DiffusionPipeline,\n",
        "    FlaxAutoencoderKL,\n",
        "    FlaxDiffusionPipeline,\n",
        "    FlaxStableDiffusionPipeline,\n",
        "    StableDiffusionPipeline,\n",
        "    AutoencoderKL,\n",
        "    schedulers\n",
        ")\n",
        "from diffusers import logging as df_logging\n",
        "\n",
        "\n",
        "# Device-specific imports\n",
        "if device_type == \"TPU\":\n",
        "    from flax.jax_utils import replicate\n",
        "    from flax.training.common_utils import shard\n",
        "else:\n",
        "    from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "\n",
        "# Configure warnings\n",
        "if DEBUG:\n",
        "    df_logging.set_verbosity_warning()\n",
        "    tf_logging.set_verbosity_warning()\n",
        "    warnings.filterwarnings(\"always\", category=DeprecationWarning)\n",
        "else:\n",
        "    df_logging.set_verbosity_error()\n",
        "    tf_logging.set_verbosity_error()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "class data_config:\n",
        "    Config_file=\"model_index.json\"\n",
        "\n",
        "    VALID_URL_PREFIXES = [\"https://huggingface.co/\", \"huggingface.co/\", \"hf.co/\", \"https://hf.co/\"]\n",
        "    exts =  [\".safetensors\", \".ckpt\",\".bin\"]\n",
        "\n",
        "    model_dict = {\n",
        "            \"stable diffusion-v2.1\" : \"stabilityai/stable-diffusion-2-1\",\n",
        "            \"waifu diffusion-v1.4\": \"hakurei/waifu-diffusion\",\n",
        "            \"Anything-v3.0\": \"Linaqruf/anything-v3.0\",\n",
        "            \"anything-midjourney-v-4-1\": \"Joeythemonster/anything-midjourney-v-4-1\",\n",
        "            \"Anything-v4.5\": \"shibal1/anything-v4.5-clone\",\n",
        "            \"AB4.5_AC0.2\": \"aioe/AB4.5_AC0.2\",\n",
        "            \"basil_mix\": \"nuigurumi/basil_mix\",\n",
        "            \"Waifu-Diffusers\": \"Nilaier/Waifu-Diffusers\",\n",
        "            \"Double-Exposure-Diffusion\": \"joachimsallstrom/Double-Exposure-Diffusion\",\n",
        "            \"openjourney-v4\": \"prompthero/openjourney-v4\",\n",
        "            \"ACertainThing\": \"JosephusCheung/ACertainThing\",\n",
        "            \"Counterfeit-V2.0\": \"gsdf/Counterfeit-V2.0\",\n",
        "            \"Counterfeit-V2.5\": \"gsdf/Counterfeit-V2.5\",\n",
        "            \"chilled_remix\":\"chilled_remix\",\n",
        "            \"chilled_reversemix\":\"chilled_reversemix\",\n",
        "            \"7th_Layer\": \"syaimu/7th_test\",\n",
        "            \"EimisAnimeDiffusion_1.0v\": \"eimiss/EimisAnimeDiffusion_1.0v\",\n",
        "            \"JWST-Deep-Space-diffusion\" : \"dallinmackay/JWST-Deep-Space-diffusion\",\n",
        "            \"Riga_Collection\": \"natsusakiyomi/Riga_Collection\",\n",
        "            \"sd-db-epic-space-machine\" : \"rabidgremlin/sd-db-epic-space-machine\",\n",
        "            \"spacemidj\" : \"Falah/spacemidj\",\n",
        "            \"anime-kawai-diffusion\": \"Ojimi/anime-kawai-diffusion\",\n",
        "            \"Realistic_Vision_V2.0\": \"SG161222/Realistic_Vision_V2.0\",\n",
        "            \"nasa-space-v2\" : \"sd-dreambooth-library/nasa-space-v2-768\",\n",
        "            \"meinamix_meinaV10\": \"namvuong96/civit_meinamix_meinaV10\",\n",
        "            \"loliDiffusion\": \"JosefJilek/loliDiffusion\",\n",
        "            }\n",
        "    exclude =  [\"safety_checker/model.safetensors\",\n",
        "                \"unet/diffusion_pytorch_model.safetensors\",\n",
        "                \"vae/diffusion_pytorch_model.safetensors\",\n",
        "                \"text_encoder/model.safetensors\",\n",
        "                \"unet/diffusion_pytorch_model.fp16.safetensors\",\n",
        "                \"text_encoder/model.fp16.safetensors\",\n",
        "                \"vae/diffusion_pytorch_model.fp16.safetensors\",\n",
        "                \"safety_checker/model.fp16.safetensors\",\n",
        "\n",
        "                \"safety_checker/model.ckpt\",\n",
        "                \"unet/diffusion_pytorch_model.ckpt\",\n",
        "                \"vae/diffusion_pytorch_model.ckpt\",\n",
        "                \"text_encoder/model.ckpt\",\n",
        "                \"text_encoder/model.fp16.ckpt\",\n",
        "                \"safety_checker/model.fp16.ckpt\",\n",
        "                \"unet/diffusion_pytorch_model.fp16.ckpt\",\n",
        "                \"vae/diffusion_pytorch_model.fp16.ckpt\"]\n",
        "\n",
        "    Auto_pipe_class=[\n",
        "            \"AutoPipelineForText2Image\",\n",
        "            \"AutoPipelineForImage2Image\",\n",
        "            \"AutoPipelineForInpainting\",\n",
        "     ]\n",
        "\n",
        "    Error_M1 = (\n",
        "        '''\n",
        "        Could not load URL.\n",
        "        Format:\"https://huggingface.co/<repo_name>/<model_name>/blob/main/<path_to_file>\"\n",
        "        EX1: \"https://huggingface.co/gsdf/Counterfeit-V3.0/blob/main/Counterfeit-V3.0.safetensors\"\n",
        "        EX2: \"https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.ckpt\"\n",
        "        '''\n",
        "        )\n",
        "\n",
        "    Error_M2= (\n",
        "        '''\n",
        "        Could not load hugface_path.\n",
        "        Format: <repo_name>/<model_name>\"\n",
        "        EX1: \"Linaqruf/anything-v3.0\"\n",
        "        EX2: \"stabilityai/stable-diffusion-2-1\"\n",
        "\n",
        "        Suport_model:\n",
        "\n",
        "                \"stable diffusion-v2.1\"\n",
        "                \"waifu diffusion-v1.4\"\n",
        "                \"Anything-v3.0\"\n",
        "                \"anything-midjourney-v-4-1\"\n",
        "                \"Anything-v4.5\"\n",
        "                \"AB4.5_AC0.2\"\n",
        "                \"basil_mix\"\n",
        "                \"Waifu-Diffusers\"\n",
        "                \"Double-Exposure-Diffusion\"\n",
        "                \"openjourney-v4\"\n",
        "                \"ACertainThing\"\n",
        "                \"Counterfeit-V2.0\"\n",
        "                \"Counterfeit-V2.5\"\n",
        "                \"7th_Layer\"\n",
        "                \"EimisAnimeDiffusion_1.0v\"\n",
        "                \"Riga_Collection\"\n",
        "                \"anime-kawai-diffusion\"\n",
        "                \"Realistic_Vision_V2.0\"\n",
        "                \"meinamix_meinaV10\"\n",
        "                \"loliDiffusion\"\n",
        "                ''')\n",
        "\n",
        "    Error_M3 = ('''\n",
        "                The specified path could not be recognized. Please try the following\n",
        "                ・Check that the path to the file exists.\n",
        "                ・Check that there is no whitespace in the path.\n",
        "                ・Check if there are any special symbols such as \"\\\" or \".\" and other special symbols (may not be recognized).\n",
        "                ''')\n",
        "\n",
        "\n",
        "\n",
        "class basic_config(data_config,config_check,runtime_func):\n",
        "    def __init__(self):\n",
        "        self.device_count = self.count_device()\n",
        "        self.device_type = self.device_type_check()\n",
        "        self.device = self.device_set()\n",
        "        if self.device_type == \"TPU\":\n",
        "            self.use_TPU = True\n",
        "        else:\n",
        "            self.use_TPU = False\n",
        "\n",
        "        if drive._os.path.ismount(\"/content/drive\"):\n",
        "            self.conect_gdrive = True\n",
        "        else:\n",
        "            self.conect_gdrive = False\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def get_inherited_class(cls,class_name) -> list:\n",
        "        inherited_class = inspect.getmro(class_name)\n",
        "        return [cls_method.__name__ for cls_method in inherited_class]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def device_set():\n",
        "        logger.debug(f\"device_type: {device_type}\")\n",
        "        if device_type == \"TPU\":\n",
        "            #import torch_xla.core.xla_model as xm\n",
        "            #device = xm.xla_device()\n",
        "            device = device_type\n",
        "        else:\n",
        "            device = device_type\n",
        "        return device\n",
        "\n",
        "\n",
        "    def is_TPU(self):\n",
        "        if self.device_type_check() == \"TPU\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def is_safetensors(self,path):\n",
        "        if \".safetensors\" == os.path.splitext(path)[1]:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def count_device(self):\n",
        "        return jax.device_count()\n",
        "\n",
        "\n",
        "    def get_item(self,dict_obj):\n",
        "        \"\"\"\n",
        "        Returns the first element of the dictionary\n",
        "        \"\"\"\n",
        "        return next(iter(dict_obj.items()))[1]\n",
        "\n",
        "\n",
        "    def pipeline_metod_type(self,Target_class) -> str:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        Target_class : class\n",
        "\n",
        "        Returns:\n",
        "        Literal['torch','flax','onnx']\n",
        "        \"\"\"\n",
        "        torch_list=[\"DiffusionPipeline\",\n",
        "                    \"AutoPipelineForText2Image\",\n",
        "                    \"AutoPipelineForImage2Image\",\n",
        "                    \"AutoPipelineForInpainting\",]\n",
        "\n",
        "        flax_list = [\"FlaxDiffusionPipeline\",]\n",
        "\n",
        "        if isinstance(Target_class,str):\n",
        "            Target_class = getattr(diffusers, Target_class)\n",
        "\n",
        "        cls_method= self.get_inherited_class(Target_class)\n",
        "\n",
        "        if any(method in torch_list for method in cls_method):\n",
        "            class_type= \"torch\"\n",
        "        elif any(method in flax_list for method in cls_method):\n",
        "            class_type= \"flax\"\n",
        "        else:\n",
        "            class_type= \"onnx\"\n",
        "        return class_type\n",
        "\n",
        "\n",
        "    def sort_by_version(self,sorted_list) -> list:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "        Sorted by version in order of newest to oldest\n",
        "        \"\"\"\n",
        "        return natsorted(sorted_list,reverse = True)\n",
        "\n",
        "\n",
        "    def key_check(self,keyword) -> bool:\n",
        "        global key_dict\n",
        "        if \"key_dict\" not in globals():\n",
        "            key_dict = {}\n",
        "        key = str(keyword)\n",
        "        key_in = False\n",
        "        if key in key_dict:\n",
        "            if keyword == key_dict[key]:\n",
        "                key_in = True\n",
        "        key_dict[key] = keyword\n",
        "        return key_in\n",
        "\n",
        "\n",
        "    def get_call_method(\n",
        "            self,\n",
        "            class_name,\n",
        "            method_name : str = '__call__'\n",
        "            ) ->list:\n",
        "        \"\"\"\n",
        "        Acquire the arguments of the function specified by 'method_name'\n",
        "        for the class specified by 'class_name'\n",
        "        \"\"\"\n",
        "        if isinstance(class_name,str):\n",
        "            class_name = getattr(getattr(diffusers, class_name),method_name)\n",
        "        parameters = inspect.signature(class_name).parameters\n",
        "        arg_names = []\n",
        "        for param in parameters.values():\n",
        "            arg_names.append(param.name)\n",
        "        return arg_names\n",
        "\n",
        "\n",
        "    def get_class_elements(\n",
        "            self,\n",
        "            search\n",
        "            ):\n",
        "        return list(search.__class__.__annotations__.keys())\n",
        "\n",
        "\n",
        "    def check_for_safetensors(\n",
        "            self,\n",
        "            path\n",
        "            ):\n",
        "        _ext = os.path.basename(path).split(\".\")[-1]\n",
        "        if _ext == \"safetensors\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def pipe_class_type(\n",
        "            self,\n",
        "            class_name\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        class_name : class\n",
        "\n",
        "        Returns:\n",
        "        Literal['txt2img','img2img','txt2video']\n",
        "        \"\"\"\n",
        "        _txt2img_method_list = [] #else\n",
        "        _img2img_method_list = [\"image\"]\n",
        "        _img2video_method_list = [\"video_length\",\"fps\"]\n",
        "\n",
        "        call_method = self.get_call_method(class_name,method_name = '__call__')\n",
        "\n",
        "        if any(method in call_method for method in _img2video_method_list):\n",
        "            pipeline_type = \"txt2video\"\n",
        "        elif any(method in call_method for method in _img2img_method_list):\n",
        "            pipeline_type = \"img2img\"\n",
        "        else:\n",
        "            pipeline_type = \"txt2img\"\n",
        "        return pipeline_type\n",
        "\n",
        "\n",
        "    def import_on_str(\n",
        "            self,\n",
        "            desired_function_or_class,\n",
        "            module_name = \"\"\n",
        "            ):\n",
        "        if not module_name:\n",
        "            import_object = __import__(desired_function_or_class)\n",
        "        else:\n",
        "            import_object = getattr(__import__(module_name), desired_function_or_class)\n",
        "        return import_object\n",
        "\n",
        "\n",
        "    def max_temper(\n",
        "            self,\n",
        "            search_word,\n",
        "            search_list\n",
        "            ):\n",
        "        return difflib.get_close_matches(search_word, search_list,cutoff=0, n=1)\n",
        "\n",
        "\n",
        "    def sort_list_obj(\n",
        "            self,\n",
        "            list_obj,\n",
        "            need_txt\n",
        "            ):\n",
        "        sorted_list=[]\n",
        "        for module_obj in list_obj:\n",
        "            if need_txt.lower() in module_obj.lower():\n",
        "                sorted_list.append(module_obj)\n",
        "        return sorted_list\n",
        "\n",
        "\n",
        "    def checkpoint_type_get(\n",
        "            self,\n",
        "            checkpoint_path_or_dict ,\n",
        "            config_files= None,\n",
        "            original_config_file= None,\n",
        "            model_type = None,\n",
        "            is_upscale = False\n",
        "            ):\n",
        "        \"\"\"\n",
        "        NOTE:\n",
        "        Return SD if you do not know, because an error may occur if None is used.\n",
        "\n",
        "        About model_type:\n",
        "        The model_type itself will be left for possible use at some point.\n",
        "        \"\"\"\n",
        "\n",
        "        from_safetensors = False\n",
        "        checkpoint = None\n",
        "        if isinstance(checkpoint_path_or_dict, str):\n",
        "            if os.path.isfile(checkpoint_path_or_dict):\n",
        "                from_safetensors: bool = self.check_for_safetensors(checkpoint_path_or_dict)\n",
        "                if from_safetensors:\n",
        "                    from safetensors.torch import load_file as safe_load\n",
        "                    checkpoint = safe_load(checkpoint_path_or_dict, device=self.device)\n",
        "                else:\n",
        "                    checkpoint = torch.load(checkpoint_path_or_dict, map_location=self.device)\n",
        "            elif os.path.isdir(checkpoint_path_or_dict):\n",
        "                model_index_path = os.path.join(checkpoint_path_or_dict,\"model_index.json\")\n",
        "                if os.path.isfile(model_index_path):\n",
        "                    with open(model_index_path,\"r\") as loaded_model_index:\n",
        "                        cls_name = loaded_model_index[\"_class_name\"]\n",
        "                        #Fixed in due course.\n",
        "                        if \"XL\" in cls_name:\n",
        "                            return \"SDXL\"\n",
        "                        else:\n",
        "                            return \"SD\"\n",
        "\n",
        "        elif isinstance(checkpoint_path_or_dict, dict):\n",
        "            checkpoint = checkpoint_path_or_dict\n",
        "        else:\n",
        "            raise TypeError(f\"checkpoint_path_or_dict: {checkpoint_path_or_dict}\")\n",
        "\n",
        "        if \"global_step\" in checkpoint:\n",
        "            global_step = checkpoint[\"global_step\"]\n",
        "        else:\n",
        "            global_step = None\n",
        "\n",
        "        while \"state_dict\" in checkpoint:\n",
        "            checkpoint = checkpoint[\"state_dict\"]\n",
        "        if original_config_file is None:\n",
        "            key_name_v2_1 = \"model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight\"\n",
        "            key_name_sd_xl_base = \"conditioner.embedders.1.model.transformer.resblocks.9.mlp.c_proj.bias\"\n",
        "            key_name_sd_xl_refiner = \"conditioner.embedders.0.model.transformer.resblocks.9.mlp.c_proj.bias\"\n",
        "            #is_upscale = pipeline_class == StableDiffusionUpscalePipeline\n",
        "            config_url = None\n",
        "            # model_type = \"v1\"\n",
        "            if config_files is not None and \"v1\" in config_files:\n",
        "                original_config_file = config_files[\"v1\"]\n",
        "            else:\n",
        "                config_url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\"\n",
        "\n",
        "            if key_name_v2_1 in checkpoint and checkpoint[key_name_v2_1].shape[-1] == 1024:\n",
        "                # model_type = \"v2\"\n",
        "                if config_files is not None and \"v2\" in config_files:\n",
        "                    original_config_file = config_files[\"v2\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\"\n",
        "                if global_step == 110000:\n",
        "                    # v2.1 needs to upcast attention\n",
        "                    upcast_attention = True\n",
        "\n",
        "            elif key_name_sd_xl_base in checkpoint:\n",
        "                # only base xl has two text embedders\n",
        "                if config_files is not None and \"xl\" in config_files:\n",
        "                    original_config_file = config_files[\"xl\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_base.yaml\"\n",
        "\n",
        "            elif key_name_sd_xl_refiner in checkpoint:\n",
        "                # only refiner xl has embedder and one text embedders\n",
        "                if config_files is not None and \"xl_refiner\" in config_files:\n",
        "                    original_config_file = config_files[\"xl_refiner\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_refiner.yaml\"\n",
        "\n",
        "            if is_upscale:\n",
        "                config_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/x4-upscaling.yaml\"\n",
        "\n",
        "            if config_url is not None:\n",
        "                try:\n",
        "                    original_config_file = BytesIO(requests.get(config_url).content)\n",
        "                except:\n",
        "                    logger.error(f\"Could not download the Config_file to find out the model type from the following URL: {config_url}\")\n",
        "                    if model_type is None:\n",
        "                        logger.warning(\"model_type is set to None\")\n",
        "                    return model_type\n",
        "            else:\n",
        "                with open(original_config_file, \"r\") as f:\n",
        "                    original_config_file = f.read()\n",
        "        else:\n",
        "            with open(original_config_file, \"r\") as f:\n",
        "                original_config_file = f.read()\n",
        "\n",
        "        original_config = yaml.safe_load(original_config_file)\n",
        "\n",
        "        if (\n",
        "            model_type is None\n",
        "            and \"cond_stage_config\" in original_config[\"model\"][\"params\"]\n",
        "            and original_config[\"model\"][\"params\"][\"cond_stage_config\"] is not None\n",
        "        ):\n",
        "\n",
        "            model_type = original_config[\"model\"][\"params\"][\"cond_stage_config\"][\"target\"].split(\".\")[-1]\n",
        "            return \"SD\"\n",
        "\n",
        "        elif model_type is None and original_config[\"model\"][\"params\"][\"network_config\"] is not None:\n",
        "            if original_config[\"model\"][\"params\"][\"network_config\"][\"params\"][\"context_dim\"] == 2048:\n",
        "                model_type = \"SDXL\"\n",
        "            else:\n",
        "                model_type = \"SDXL-Refiner\"\n",
        "            return \"SDXL\"\n",
        "\n",
        "        else:\n",
        "            if model_type is None:\n",
        "                logger.warning(\"model_type is set to None\")\n",
        "            return model_type\n",
        "\n",
        "\n",
        "'''\n",
        "about: unexplained crash\n",
        "\n",
        "If you get an unexplained crash in transfomers or diffusers while using TPUv2, try the following\n",
        "\n",
        "----do----\n",
        "pip uninstall tensorflow\n",
        "pip install tensorflow-cpu\n",
        "----------\n",
        "'''\n",
        "\n",
        "\n",
        "if not drive._os.path.ismount('/content/drive'):\n",
        "    conect_drive = False\n",
        "    Connect_Gdrive=\"\\033[33mNo connection\\033[0m\"\n",
        "else:\n",
        "    conect_drive = True\n",
        "    Connect_Gdrive=\"\\033[34mConnection Successful\\033[0m\"\n",
        "\n",
        "#base dir\n",
        "os.makedirs(\"/content/script\",exist_ok=True)\n",
        "sys.path.append(\"/content/script\")\n",
        "\n",
        "\n",
        "Step1.bar_update(exit=True, pofix=\"Finish!\")\n",
        "\n",
        "print(\"\\n\\033[34m___________________________________________\\n\")\n",
        "print(f\"Devie: {runtime_func().device_type_check()}\\n\")\n",
        "print(f\"Googledrive: {Connect_Gdrive}\")\n",
        "print(\"\\n\\033[32mSetup completed successfully\\033[0m\")\n",
        "\n",
        "step1_finish =True"
      ],
      "metadata": {
        "id": "lRJ148nGucXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "t3tO0kbyDGtT"
      },
      "outputs": [],
      "source": [
        "#@title (option) hf_login\n",
        "#@markdown If you use a secret variable, store the token under the name **hf_token**\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login, logout\n",
        "\n",
        "Logout = False # @param {type:\"boolean\"}\n",
        "\n",
        "if not Logout:\n",
        "    try:\n",
        "        hf_login_token = userdata.get(\"hf_token\")\n",
        "    except userdata.SecretNotFoundError:\n",
        "        hf_login_token = None\n",
        "    finally:\n",
        "        login(hf_login_token)\n",
        "else:\n",
        "    logout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9YtvPtgOGZi"
      },
      "outputs": [],
      "source": [
        "#@title #Step.2 Model Selection {display-mode: \"form\"}\n",
        "\n",
        "#@markdown >Selecting the model to use [#info](#model_select_help)\n",
        "\n",
        "\n",
        "model_select = \"stable diffusion-v2.1(basic)\" # @param [\"stable diffusion-v2.1(basic)\", \"Counterfeit-V2.5(Anime)(better)\", \"loliDiffusion(Anime)\", \"waifu diffusion-v1.4(Anime)\", \"Anything-v3.0(Anime)\", \"Anything-v4.5(Anime)\", \"anything-midjourney-v-4-1(Anime)\", \"ACertainThing(Anime)\", \"anime-kawai-diffusion(Anime)\", \"AB4.5_AC0.2(Anime)\", \"basil_mix(Anime)\", \"Counterfeit(Anime)\", \"Counterfeit-V2.0(Anime)\", \"chilled_remix(Anime)\", \"Double-Exposure-Diffusion(Anime)\", \"EimisAnimeDiffusion_1.0v(Anime)\", \"7th_Layer(Anime)\", \"Riga_Collection(Anime)\", \"Waifu-Diffusers(Anime)\", \"JWST-Deep-Space-diffusion(space)\", \"sd-db-epic-space-machine(space_ship)\", \"spacemidj(space)\", \"nasa-space-v2(space)\", \"openjourney-v4(Reality)\", \"Realistic_Vision_V2.0(Reality)\", \"meinamix_meinaV10(Reality)\", \"search\"] {allow-input: true}\n",
        "del_word_list=[\"(basic)\",\"(Anime)\",\"(Reality)\",\"(space_ship)\",\"(space)\",\"(better)\"]\n",
        "if model_select in [\"stable diffusion-v2.1(basic)\", \"Counterfeit-V2.5(Anime)(better)\", \"loliDiffusion(Anime)\", \"waifu diffusion-v1.4(Anime)\", \"Anything-v3.0(Anime)\", \"Anything-v4.5(Anime)\", \"anything-midjourney-v-4-1(Anime)\", \"ACertainThing(Anime)\", \"anime-kawai-diffusion(Anime)\", \"AB4.5_AC0.2(Anime)\", \"basil_mix(Anime)\", \"Counterfeit(Anime)\", \"Counterfeit-V2.0(Anime)\", \"chilled_remix(Anime)\", \"Double-Exposure-Diffusion(Anime)\", \"EimisAnimeDiffusion_1.0v(Anime)\", \"7th_Layer(Anime)\", \"Riga_Collection(Anime)\", \"Waifu-Diffusers(Anime)\", \"JWST-Deep-Space-diffusion(space)\", \"sd-db-epic-space-machine(space_ship)\", \"spacemidj(space)\", \"nasa-space-v2(space)\", \"openjourney-v4(Reality)\", \"Realistic_Vision_V2.0(Reality)\", \"meinamix_meinaV10(Reality)\"]:\n",
        "    for del_word in del_word_list:\n",
        "        model_select=model_select.replace(del_word, \"\" )\n",
        "\n",
        "#@markdown * Words to search models\n",
        "\n",
        "#@markdown * Select from pull-down menu\n",
        "\n",
        "#@markdown * Enter the name of the model and the path or URL where the model is stored\n",
        "\n",
        "#@markdown *  **\"search\"** to search all directories for candidate files or folders.\n",
        "\n",
        "\n",
        "#@markdown >Config [#info](#auto_help)\n",
        "\n",
        "auto = True  # @param {type:\"boolean\"}\n",
        "#@markdown Automatically select repository & model files (recommended: ON)\n",
        "\n",
        "\n",
        "\n",
        "if \"step1_finish\"not in globals():\n",
        "    raise NameError(\"\\033[33mPlease execute Step.1 first\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "class Huggingface(basic_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.num_prints=20\n",
        "        self.model_id=\"\"\n",
        "        self.model_name=\"\"\n",
        "        self.vae_name=\"\"\n",
        "        self.model_file=\"\"\n",
        "        self.input_url=False\n",
        "        self.diffuser_model=False\n",
        "        self.check_choice_key = \"\"\n",
        "        self.choice_number = -1\n",
        "        self.file_path_dict={}\n",
        "        self.special_file=\"\"\n",
        "        self.hf_repo_id = \"\"\n",
        "        #self.model_select = \"\"\n",
        "\n",
        "\n",
        "    def repo_name_or_path(self,model_name_or_path):\n",
        "        pattern = r\"([^/]+)/([^/]+)/(?:blob/main/)?(.+)\"\n",
        "        weights_name = None\n",
        "        repo_id = None\n",
        "        for prefix in self.VALID_URL_PREFIXES:\n",
        "            model_name_or_path = model_name_or_path.replace(prefix, \"\")\n",
        "        match = re.match(pattern, model_name_or_path)\n",
        "        if not match:\n",
        "            return repo_id, weights_name\n",
        "        repo_id = f\"{match.group(1)}/{match.group(2)}\"\n",
        "        weights_name = match.group(3)\n",
        "        return repo_id, weights_name\n",
        "\n",
        "\n",
        "    def run_hf_download(self,url_or_path):\n",
        "        \"\"\"\n",
        "        retrun:\n",
        "        os.path\n",
        "        \"\"\"\n",
        "        def _hf_repo_download(path):\n",
        "            model_path = DiffusionPipeline.download(path)\n",
        "            return model_path\n",
        "\n",
        "        if any(url_or_path.startswith(checked) for checked in self.VALID_URL_PREFIXES):\n",
        "            if not self.self.is_url_valid(url_or_path):\n",
        "                raise HTTPError(\"Invalid URL\")\n",
        "            hf_path, file_name =self.repo_name_or_path(url_or_path)\n",
        "            logger.debug(f\"url_or_path:{url_or_path}\")\n",
        "            logger.debug(f\"hf_path: {hf_path} \\nfile_name: {file_name}\")\n",
        "            if hf_path and file_name:\n",
        "                model_file_path = hf_hub_download(hf_path, file_name)\n",
        "            elif hf_path and (not file_name):\n",
        "                if self.diffusers_model_check(hf_path):\n",
        "                    model_file_path = _hf_repo_download(url_or_path)\n",
        "                else:\n",
        "                    raise HTTPError(\"Invalid hf_path\")\n",
        "            else:\n",
        "                raise TypeError(\"Invalid path_or_url\")\n",
        "\n",
        "        #from hf_repo\n",
        "        elif self.diffusers_model_check(url_or_path):\n",
        "            logger.debug(f\"url_or_path: {url_or_path}\")\n",
        "            model_file_path = _hf_repo_download(url_or_path)\n",
        "        else:\n",
        "            logger.debug(f\"url_or_path:{url_or_path}\")\n",
        "            raise TypeError(\"Invalid path_or_url\")\n",
        "        return model_file_path\n",
        "\n",
        "\n",
        "    def model_safe_check(self,model_list) ->str:\n",
        "        if len(model_list)>1:\n",
        "           for check_model in model_list:\n",
        "                match = bool(re.search(r\"(?i)[-＿]sfw\", check_model))\n",
        "                if match:\n",
        "                    return check_model\n",
        "        return model_list[0]\n",
        "\n",
        "\n",
        "    def list_safe_check(self,model_list) -> list:\n",
        "        for check_model in model_list:\n",
        "            if bool(re.search(r\"(?i)[-ー_＿]sfw\", check_model)):\n",
        "                model_list.remove(check_model)\n",
        "                model_list.insert(0, check_model)\n",
        "                break\n",
        "        return model_list\n",
        "\n",
        "\n",
        "    def diffusers_model_check(self,checked_model: str) -> bool:\n",
        "        index_url=f\"https://huggingface.co/{checked_model}/blob/main/model_index.json\"\n",
        "        return self.is_url_valid(index_url)\n",
        "\n",
        "\n",
        "    def hf_model_check(self,path) -> bool:\n",
        "        return self.is_url_valid(f\"https://huggingface.co/{path}\")\n",
        "\n",
        "\n",
        "    def data_get(self,path) -> list:\n",
        "        url = f\"https://huggingface.co/api/models/{path}\"\n",
        "        data = requests.get(url).json()\n",
        "        file_value_list = []\n",
        "        df_model_bool=False\n",
        "        #fix error': 'Repo model <repo_id>/<model> is gated. You must be authenticated to access it.\n",
        "        try:\n",
        "            siblings=data[\"siblings\"]\n",
        "        except KeyError:\n",
        "            return []\n",
        "\n",
        "        for item in siblings:\n",
        "            data[\"siblings\"]\n",
        "            file_path=item[\"rfilename\"]\n",
        "            #model_index.json outside the root directory is not recognized\n",
        "            if file_path==\"model_index.json\":\n",
        "                df_model_bool=True\n",
        "            elif (any(file_path.endswith(ext) for ext in self.exts) and\n",
        "                not any(file_path.endswith(ex) for ex in self.exclude)):\n",
        "                file_value_list.append(file_path)\n",
        "        #↓{df_model,file_value_list}\n",
        "        self.file_path_dict.update({path:(df_model_bool,file_value_list)})\n",
        "        return file_value_list\n",
        "\n",
        "    def hf_model_search(self,\n",
        "                        model_path,\n",
        "                        limit_num):\n",
        "        url = f\"https://huggingface.co/api/models\"#?search={model_name}\"\n",
        "        params={\"search\":model_path,\"sort\":\"likes\",\"direction\":-1,\"limit\":limit_num}#\"downloads\",}\n",
        "        return requests.get(url,params=params).json()\n",
        "\n",
        "    def hf_models(self,\n",
        "                  model_name,\n",
        "                  limit):\n",
        "        \"\"\"\n",
        "        return:\n",
        "        repo_model_list,with_like : list\n",
        "        \"\"\"\n",
        "        #logger.debug(f\"model_name: {model_name}\")\n",
        "        data=self.hf_model_search(model_name,limit)\n",
        "        final_list = []\n",
        "        if data:\n",
        "            for item in data:\n",
        "                model_id,like,private_value,tag_value = item[\"modelId\"],item[\"likes\"],item[\"private\"],item[\"tags\"]\n",
        "                if  (\"audio-to-audio\" not in tag_value and\n",
        "                    (not private_value)):\n",
        "                    if self.data_get(model_id):\n",
        "                        model_dict = {\"model_id\":model_id,\n",
        "                                      \"like\":like,}\n",
        "                        final_list.append(model_dict)\n",
        "        else:\n",
        "            print(\"No models matching your criteria were found on huggingface.\")\n",
        "            return []\n",
        "        return final_list\n",
        "\n",
        "\n",
        "\n",
        "    def model_name_search(self,\n",
        "                          model_name: str,\n",
        "                          auto_set: bool,\n",
        "                          Recursive_execution:bool = False):\n",
        "\n",
        "        def find_max_like(model_dict_list:list):\n",
        "            \"\"\"\n",
        "            Finds the dictionary with the highest \"like\" value in a list of dictionaries.\n",
        "\n",
        "            Args:\n",
        "                model_dict_list: A list of dictionaries.\n",
        "\n",
        "            Returns:\n",
        "                The dictionary with the highest \"like\" value, or the first dictionary if none have \"like\".\n",
        "            \"\"\"\n",
        "            max_like = 0\n",
        "            max_like_dict = None\n",
        "            for model_dict in model_dict_list:\n",
        "                if model_dict[\"like\"] > max_like:\n",
        "                    max_like = model_dict[\"like\"]\n",
        "                    max_like_dict = model_dict\n",
        "            return max_like_dict[\"model_id\"] or model_dict_list[0][\"model_id\"]\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        auto_set: bool\n",
        "        loads the model with the most likes in hugface\n",
        "        \"\"\"\n",
        "        if Recursive_execution:\n",
        "            limit = 1000\n",
        "        else:\n",
        "            limit = 15\n",
        "\n",
        "\n",
        "\n",
        "        repo_model_list = self.hf_models(model_name,limit)\n",
        "        model_history = self.check_func_hist(key=\"hf_model_name\",\n",
        "                                             return_value=True)\n",
        "        if not auto_set:\n",
        "            print(\"\\033[34mThe following model paths were found\")\n",
        "            if model_history is not None:\n",
        "                print(f\"Previous Choice: {model_history}\")\n",
        "            print(\"0.Search civitai\")\n",
        "            for (i,(model_dict)) in enumerate(repo_model_list,1):\n",
        "                model_name = model_dict[\"model_id\"]\n",
        "                like = model_dict[\"like\"]\n",
        "                print(f\"{i}.model path: {model_name}, evaluation: {like}\")\n",
        "\n",
        "            if Recursive_execution:\n",
        "                print(\"16.Other than above\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    choice = int(input(\"Select the model path to use: \"))\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                    continue\n",
        "                if choice == 0:\n",
        "                    return \"_hf_no_model\"\n",
        "                elif (not Recursive_execution) and choice>=16 and choice == len(repo_model_list)+1:\n",
        "                    return self.model_name_search(model_name = model_name,\n",
        "                                                  auto_set = auto_set,\n",
        "                                                  Recursive_execution = True)\n",
        "                elif 1 <= choice <= len(repo_model_list):\n",
        "                    choice_path_dict = repo_model_list[choice-1]\n",
        "                    choice_path = choice_path_dict[\"model_id\"]\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Please enter the numbers 1~{len(repo_model_list)}\")\n",
        "\n",
        "        else:\n",
        "            if repo_model_list:\n",
        "                choice_path = find_max_like(repo_model_list)\n",
        "            else:\n",
        "                choice_path = \"_hf_no_model\"\n",
        "\n",
        "\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "\n",
        "    def file_name_set_sub(self,model_select,file_value,model_type):\n",
        "        check_key = f\"{model_select}_select\"\n",
        "        if not file_value and (not self.diffuser_model):\n",
        "            print(\"\\033[31mNo candidates found at huggingface\\033[0m\")\n",
        "            res = input(\"Searching for civitai?: \")\n",
        "            if res.lower() in [\"y\",\"yes\"]:\n",
        "                return \"_hf_no_model\"\n",
        "            else:\n",
        "                raise ValueError(\"No available files were found in the specified repository\")\n",
        "        elif not file_value:\n",
        "            print(\"\\033[34mOnly models in Diffusers format found\")\n",
        "            while True:\n",
        "                result=input(\"Do you want to use it?[y/n]: \")\n",
        "                if result.lower() in [\"y\",\"yes\"]:\n",
        "                    return \"_DFmodel\"\n",
        "                elif result.lower() in [\"n\",\"no\"]:\n",
        "                    sec_result=input(\"Searching for civitai?[y/n]: \")\n",
        "                    if sec_result.lower() in [\"y\",\"yes\"]:\n",
        "                        return \"_hf_no_model\"\n",
        "                    elif sec_result.lower() in [\"n\",\"no\"]:\n",
        "                        raise ValueError(\"Processing was stopped because no corresponding model was found.\")\n",
        "                else:\n",
        "                    print(\"Please enter only [y,n]\")\n",
        "        file_value=self.list_safe_check(file_value)\n",
        "        if len(file_value)>=self.num_prints: #15\n",
        "            start_number=\"1\"\n",
        "            #previous_select = self.check_func_hist(key=check_key)\n",
        "            #if previous_select:\n",
        "            choice_history = self.check_func_hist(key = check_key,return_value=True)\n",
        "            if choice_history:\n",
        "                if choice_history>self.num_prints+1:\n",
        "                    choice_history = self.num_prints+1\n",
        "                print(f\"\\033[33m＊Previous number: {choice_history}\\033[0m\")\n",
        "\n",
        "            if self.diffuser_model:\n",
        "                start_number=\"0\"\n",
        "                print(\"\\033[34m0.Use Diffusers format model\")\n",
        "            for i in range(self.num_prints):\n",
        "                print(f\"\\033[34m{i+1}.File name: {file_value[i]}\\033[0m\")\n",
        "            print(f\"\\033[34m{self.num_prints+1}.Other than the files listed above (all candidates will be displayed)\\n\")\n",
        "            while True:\n",
        "                choice = input(f\"select the file you want to use({start_number}~21): \")\n",
        "                try:\n",
        "                    choice=int(choice)\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid\\033[34m\")\n",
        "                    continue\n",
        "                if self.diffuser_model and choice==0:\n",
        "                    old_num=None\n",
        "                    self.input_url=False\n",
        "                    self.choice_number = -1\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return \"_DFmodel\"\n",
        "\n",
        "                elif choice==(self.num_prints+1): #other_file\n",
        "                    break\n",
        "                elif 1<=choice<=self.num_prints:\n",
        "                    self.input_url=True\n",
        "                    old_num=choice\n",
        "                    choice_path=file_value[choice-1]\n",
        "                    self.choice_number = choice\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return choice_path\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter numbers from 1~{self.num_prints}\\033[34m\")\n",
        "            print(\"\\033[0m\",end=\"\")\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "        choice_history = self.check_func_hist(key = check_key,return_value=True)\n",
        "        if choice_history:\n",
        "            print(f\"\\033[33m＊Previous number: {choice_history}\\033[0m\")\n",
        "\n",
        "        start_number=\"1\"\n",
        "        if self.diffuser_model:\n",
        "            start_number=\"0\"\n",
        "            print(\"\\033[34m0.Use Diffusers format model\\033[0m\")\n",
        "        for i, file_name in enumerate(file_value, 1):\n",
        "            print(f\"\\033[34m{i}.File name: {file_name}\")\n",
        "        while True:\n",
        "            choice = input(f\"Select the file you want to use({start_number}~{len(file_value)}): \")\n",
        "            try:\n",
        "                choice=int(choice)\n",
        "            except ValueError:\n",
        "                print(\"\\033[33mOnly natural numbers are valid\\033[34m\")\n",
        "            else:\n",
        "                if self.diffuser_model and choice==0:\n",
        "                    self.input_url=False\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    self.choice_number = -1\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return \"_DFmodel\"\n",
        "                if 1<=choice<=len(file_value):\n",
        "                    self.input_url=True\n",
        "                    old_num=choice\n",
        "                    choice_path=file_value[choice-1]\n",
        "                    self.choice_number = choice\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return choice_path\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter numbers from 1~{len(file_value)}\\033[34m\")\n",
        "        #print(\"\\033[0m\",end=\"\")\n",
        "\n",
        "\n",
        "    def file_name_set(self,model_select,auto,model_type=\"Checkpoint\",download=False):\n",
        "        logger.debug(f\"model_select: {model_select}\")\n",
        "        del_dir_name = [\"VAEs\"]\n",
        "        if self.diffusers_model_check(model_select) and model_type==\"Checkpoint\":\n",
        "            self.diffuser_model=True\n",
        "        #check_choice_key = f\"model_select_{model_type}\"\n",
        "        url = f\"https://huggingface.co/api/models/{model_select}\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.HTTPError:\n",
        "            raise HTTPError(\"A hugface login or token is required\")\n",
        "        data = response.json()\n",
        "        choice_path=\"\"\n",
        "        file_value = []\n",
        "        logger.debug(data)\n",
        "        logger.debug(element for element in data)\n",
        "        siblings = data[\"siblings\"]\n",
        "        if data:\n",
        "            for item in siblings:\n",
        "                fi_path=item[\"rfilename\"]\n",
        "                if (any(fi_path.endswith(ext) for ext in self.exts) and\n",
        "                    (not any(fi_path.endswith(ex) for ex in self.exclude)) and\n",
        "                    (not any(fi_path.startswith(st) for st in del_dir_name))):\n",
        "                    file_value.append(fi_path)\n",
        "        else:\n",
        "            raise ValueError(\"No available file was found.\\nPlease check the name.\")\n",
        "        if file_value:\n",
        "            file_value=self.sort_by_version(file_value)\n",
        "            if not auto:\n",
        "                print(\"\\033[34mThe following model files were found\\033[0m\")\n",
        "                choice_path=self.file_name_set_sub(model_select,file_value,model_type)\n",
        "                #if not self.choice_number == -1:\n",
        "                #    choice_key_update = self.check_func_hist(key=check_key,value=self.choice_number)\n",
        "            else:\n",
        "                if self.diffuser_model:\n",
        "                    self.input_url=False\n",
        "                else:\n",
        "                    self.input_url=True\n",
        "                    choice_path=self.model_safe_check(file_value)\n",
        "\n",
        "\n",
        "        elif self.diffuser_model:\n",
        "            print(\"\\033[32mOnly models in Diffusers format found\")\n",
        "            choice_path = \"_DFmodel\"\n",
        "        else:\n",
        "            raise FileNotFoundError(\"No available files found in the specified repository\")\n",
        "        #if model_type!=\"Checkpoint\" and model_type!=\"_DFmodel\":\n",
        "            #self.input_url=False\n",
        "        if download and not choice_path==\"_DFmodel\":\n",
        "            choice_path=hf_hub_download(repo_id=model_select, filename=choice_path)\n",
        "        #if not self.choice_number== -1:\n",
        "        #    choice_key_update = self.check_func_hist(key=check_choice_key,value=self.choice_number)\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "\n",
        "class Civitai(basic_config):\n",
        "    '''\n",
        "    Example:\n",
        "    item = requests.get(\"http://civitai.example\").json\n",
        "    state_list = [{\n",
        "        \"repo_name\": item[\"name\"],\n",
        "        \"repo_id\": item[\"id\"],\n",
        "        \"favoriteCount\": item[\"stats\"][\"favoriteCount\"],\n",
        "        \"downloadCount\": item[\"stats\"][\"downloadCount\"],\n",
        "        \"CreatorName\": item[\"creator\"][\"username\"],\n",
        "        \"version_list\": [{\n",
        "            \"id\": item[\"modelVersions\"][\"id\"],\n",
        "            \"name\": item[\"modelVersions\"][\"name\"],\n",
        "            \"downloadCount\": item[\"modelVersions\"][\"downloadCount\"],\n",
        "            \"files\": [{\n",
        "                \"filename\": item[\"modelVersions\"][\"files\"][\"name\"],\n",
        "                \"file_id\": item[\"modelVersions\"][\"files\"][\"id\"],\n",
        "                \"download_url\": item[\"modelVersions\"][\"files\"][\"downloadUrl\"],\n",
        "            }]\n",
        "        }]\n",
        "    }]\n",
        "    return:\n",
        "        state_list = {\n",
        "            \"repo_name\": item[\"name\"],\n",
        "            \"repo_id\": item[\"id\"],\n",
        "            \"favoriteCount\": item[\"stats\"][\"favoriteCount\"],\n",
        "            \"downloadCount\": item[\"stats\"][\"downloadCount\"],\n",
        "            \"CreatorName\": item[\"creator\"][\"username\"],\n",
        "            \"version_list\": <file_list>\n",
        "        }\n",
        "    '''\n",
        "\n",
        "    base_civitai_dir = \"/root/.cache/Civitai\"\n",
        "    max_number_of_choices:int = 15\n",
        "    chunk_size:int = 1024\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.path_dict = {}\n",
        "        self.save_file_name = \"\"\n",
        "\n",
        "\n",
        "    def civitai_download(\n",
        "            self,\n",
        "            seach_word,\n",
        "            auto,\n",
        "            model_type,\n",
        "            download=True):\n",
        "        \"\"\"\n",
        "        Function to download models from civitai.\n",
        "\n",
        "        Parameters:\n",
        "        - seach_word(str): Search query string.\n",
        "        - auto(bool): Flag for automatic selection.\n",
        "        - model_type(str): Type of model to search for.\n",
        "            arg:[Checkpoint,\n",
        "                 TextualInversion,\n",
        "                 Hypernetwork,\n",
        "                 AestheticGradient,\n",
        "                 LORA,\n",
        "                 Controlnet,\n",
        "                 Poses\n",
        "                ]\n",
        "        - download(bool): Whether to download the model\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        Local storage path if download is true,\n",
        "        model download URL if false\n",
        "        ---\n",
        "        (model_url:str, save_path:str)\n",
        "        ---\n",
        "        \"\"\"\n",
        "\n",
        "        model_url, save_path = self.requests_civitai(\n",
        "            query=seach_word,\n",
        "            auto=auto,\n",
        "            model_type=model_type)\n",
        "        if download:\n",
        "            self.download_model(\n",
        "                url=model_url,\n",
        "                save_path=save_path)\n",
        "            return (model_url, self.civitai_save_path())\n",
        "        else:\n",
        "            return (model_url, None)\n",
        "\n",
        "\n",
        "    def download_model(self, url, save_path):\n",
        "        if not self.is_url_valid(url):\n",
        "            raise requests.HTTPError(\"URL is invalid.\")\n",
        "\n",
        "        response = requests.get(url, stream=True)\n",
        "\n",
        "        try:\n",
        "            response.raise_for_status()\n",
        "        except requests.HTTPError:\n",
        "            raise requests.HTTPError(f\"Invalid URL: {response.status_code}\")\n",
        "\n",
        "        os.makedirs(os.path.dirname(save_path),exist_ok=True)\n",
        "\n",
        "        with tqdm.wrapattr(open(save_path, \"wb\"), \"write\",\n",
        "            miniters=1, desc=\"Downloading model\",\n",
        "            total=int(response.headers.get('content-length', 0))) as fout:\n",
        "            for chunk in response.iter_content(chunk_size=4096):\n",
        "                fout.write(chunk)\n",
        "        print(f\"Downloaded file saved to {save_path}\")\n",
        "\n",
        "\n",
        "    def repo_select_civitai(self, state: list, auto: bool, recursive: bool = True):\n",
        "        \"\"\"\n",
        "        Set repository requests for Civitai.\n",
        "\n",
        "        Parameters:\n",
        "        - state (list): List of repository information.\n",
        "        - auto (bool): Flag for automatic selection.\n",
        "        - recursive (bool): Flag for recursion.\n",
        "\n",
        "        Returns:\n",
        "        - dict: Selected repository information.\n",
        "        \"\"\"\n",
        "        if not state:\n",
        "            raise ValueError(\"state is empty\")\n",
        "\n",
        "        if auto:\n",
        "            return max(state, key=lambda x: x['downloadCount'])\n",
        "        else:\n",
        "            sorted_list = sorted(state, key=lambda x: x['downloadCount'], reverse=True)\n",
        "            if recursive and self.max_number_of_choices < len(sorted_list):\n",
        "                Limit_choice = True\n",
        "            else:\n",
        "                Limit_choice = False\n",
        "\n",
        "            if recursive:\n",
        "                print(\"\\n\\n\\033[34mThe following repo paths were found\\033[0m\")\n",
        "            else:\n",
        "                print(\"\\n\\n\\n\")\n",
        "\n",
        "            max_number = min(self.max_number_of_choices, len(sorted_list)) if recursive else len(sorted_list)\n",
        "            for number, states_dict in enumerate(sorted_list[:max_number]):\n",
        "                print(f\"\\033[34m{number + 1}. Repo_id: {states_dict['CreatorName']} / {states_dict['repo_name']}, download: {states_dict['downloadCount']}\")\n",
        "\n",
        "            if Limit_choice:\n",
        "                max_number += 1\n",
        "                print(f\"\\033[34m{max_number}. Other than above\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    choice = int(input(f\"choice repo [1~{max_number}]: \"))\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                    continue\n",
        "\n",
        "                if Limit_choice and choice == max_number:\n",
        "                    return self.repo_select_civitai(state=state, auto=auto, recursive=False)\n",
        "                elif 1 <= choice <= max_number:\n",
        "                    self.path_dict[\"repo_id\"] = sorted_list[choice - 1][\"repo_id\"]\n",
        "                    return sorted_list[choice - 1]\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter the numbers 1~{max_number}\\033[34m\")\n",
        "\n",
        "\n",
        "    def version_select_civitai(self, state, auto, recursive: bool = True):\n",
        "        \"\"\"\n",
        "        Set model requests for Civitai.\n",
        "\n",
        "        Parameters:\n",
        "        - state: Model information state.\n",
        "        - auto: Flag for automatic selection.\n",
        "        - recursive (bool): Flag for recursion.\n",
        "\n",
        "        Returns:\n",
        "        - dict: Selected model information.\n",
        "        \"\"\"\n",
        "        if not state:\n",
        "            raise ValueError(\"state is empty\")\n",
        "\n",
        "        ver_list = sorted(state[\"version_list\"], key=lambda x: x['downloadCount'], reverse=True)\n",
        "\n",
        "        if recursive and self.max_number_of_choices < len(ver_list):\n",
        "            Limit_choice = True\n",
        "        else:\n",
        "            Limit_choice = False\n",
        "\n",
        "        if auto:\n",
        "            result_dict = max(ver_list, key=lambda x: x['downloadCount'])\n",
        "            ver_files_list = self.sort_by_version(result_dict[\"files\"])\n",
        "            return_dict = ver_files_list[0]\n",
        "            self.path_dict[\"version_id\"] = return_dict[\"id\"]\n",
        "            return return_dict\n",
        "        else:\n",
        "            if recursive:\n",
        "                print(\"\\n\\n\\033[34mThe following model paths were found\\033[0m\")\n",
        "            else:\n",
        "                print(\"\\n\\n\\n\")\n",
        "\n",
        "            if len(ver_list) == 1:\n",
        "                return ver_list\n",
        "\n",
        "            max_number = min(self.max_number_of_choices, len(ver_list)) if recursive else len(ver_list)\n",
        "\n",
        "            for number_, state_dict_ in enumerate(ver_list[:max_number]):\n",
        "                print(f\"\\033[34m{number_ + 1}. model_version: {state_dict_['name']}, download: {state_dict_['downloadCount']}\")\n",
        "\n",
        "            if Limit_choice:\n",
        "                max_number += 1\n",
        "                print(f\"{max_number}. Other than above\")\n",
        "\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    choice = int(input(\"Select the model path to use: \"))\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                    continue\n",
        "                if Limit_choice and choice == max_number:\n",
        "                    return self.version_select_civitai(state=state, auto=auto, recursive=False)\n",
        "                elif 1 <= choice <= max_number:\n",
        "                    return_dict = ver_list[choice - 1]\n",
        "                    self.path_dict[\"version_id\"] = return_dict[\"id\"]\n",
        "                    return return_dict[\"files\"]\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter the numbers 1~{max_number}\\033[34m\")\n",
        "\n",
        "\n",
        "    def file_select_civitai(self, state_list, auto,recursive:bool=True):\n",
        "        \"\"\"\n",
        "        Return the download URL for the selected file.\n",
        "\n",
        "        Parameters:\n",
        "        - state_list: List of file information.\n",
        "        - auto: Flag for automatic selection.\n",
        "\n",
        "        Returns:\n",
        "        - str: Download URL of the selected file.\n",
        "        \"\"\"\n",
        "        if recursive and self.max_number_of_choices < len(state_list):\n",
        "            Limit_choice = True\n",
        "        else:\n",
        "            Limit_choice = False\n",
        "\n",
        "        if len(state_list) > 1 and (not auto):\n",
        "            max_number = min(self.max_number_of_choices, len(state_list)) if recursive else len(state_list)\n",
        "            for number, states_dict in enumerate(state_list[:max_number]):\n",
        "                print(f\"\\033[34m{number + 1}. File_name: {states_dict['filename']}\")\n",
        "\n",
        "            if Limit_choice:\n",
        "                max_number += 1\n",
        "                print(f\"{max_number}. Other than above\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    choice = int(input(f\"Select the file to download[1~{max_number}]: \"))\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                    continue\n",
        "                if Limit_choice and choice == max_number:\n",
        "                    return self.file_select_civitai(state_list=state_list, auto=auto, recursive=False)\n",
        "                elif 1 <= choice <= len(state_list):\n",
        "                    self.path_dict[\"filename\"] = state_list[choice - 1][\"filename\"]\n",
        "                    return state_list[choice - 1]\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter the numbers 1~{len(state_list)}\\033[34m\")\n",
        "        else:\n",
        "            self.path_dict[\"filename\"] = state_list[0][\"filename\"]\n",
        "            return state_list[0]\n",
        "\n",
        "    def civitai_save_path(self):\n",
        "        \"\"\"\n",
        "        Set the save path using the information in path_dict.\n",
        "\n",
        "        Returns:\n",
        "        - str: Save path.\n",
        "        \"\"\"\n",
        "        repo_level_dir = str(self.path_dict['repo_id'])\n",
        "        file_version_dir = str(self.path_dict['version_id'])\n",
        "        save_file_name = str(self.path_dict['filename'])\n",
        "        save_path = os.path.join(self.base_civitai_dir, repo_level_dir, file_version_dir, save_file_name)\n",
        "        logger.debug(f\"save: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "    def requests_civitai(self, query, auto, model_type):\n",
        "        \"\"\"\n",
        "        Fetch models from Civitai based on a query and model type.\n",
        "\n",
        "        Parameters:\n",
        "        - query: Search query string.\n",
        "        - auto: Flag for automatic selection.\n",
        "        - model_type: Type of model to search for.\n",
        "            arg:[Checkpoint,\n",
        "                 TextualInversion,\n",
        "                 Hypernetwork,\n",
        "                 AestheticGradient,\n",
        "                 LORA,\n",
        "                 Controlnet,\n",
        "                 Poses\n",
        "                ]\n",
        "\n",
        "        Returns:\n",
        "        - str: Download URL of the selected file.\n",
        "        (url, save_path)\n",
        "        \"\"\"\n",
        "        state = []\n",
        "        repo_list = []\n",
        "        model_ver_list = []\n",
        "        version_dict = {}\n",
        "\n",
        "        params = {\"query\": query, \"types\": model_type, \"sort\": \"Most Downloaded\"}\n",
        "\n",
        "        try:\n",
        "            response = requests.get(\"https://civitai.com/api/v1/models\", params=params)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.HTTPError as err:\n",
        "            raise HTTPError(f\"Could not get elements from the URL. {err}\")\n",
        "        else:\n",
        "            try:\n",
        "                data = response.json()\n",
        "            except AttributeError:\n",
        "                raise ValueError(\"Invalid JSON response\")\n",
        "\n",
        "        items = data[\"items\"]\n",
        "\n",
        "        for item in items:\n",
        "            for model_ver in item[\"modelVersions\"]:\n",
        "                files_list = []\n",
        "\n",
        "                for model_value in model_ver[\"files\"]:\n",
        "                    if any(check_word in model_value for check_word in [\"downloadUrl\", \"name\"]):\n",
        "                        file_status = {\n",
        "                            \"filename\": model_value[\"name\"],\n",
        "                            \"file_id\": model_value[\"id\"],\n",
        "                            \"download_url\": model_value[\"downloadUrl\"],\n",
        "                        }\n",
        "                        files_list.append(file_status)\n",
        "\n",
        "                version_dict = {\n",
        "                    \"id\": model_ver[\"id\"],\n",
        "                    \"name\": model_ver[\"name\"],\n",
        "                    \"downloadCount\": model_ver[\"stats\"][\"downloadCount\"],\n",
        "                    \"files\": files_list,\n",
        "                }\n",
        "\n",
        "                if files_list:\n",
        "                    model_ver_list.append(version_dict)\n",
        "\n",
        "            if all(check_txt in item.keys() for check_txt in [\"name\", \"stats\", \"creator\"]):\n",
        "                state_dict = {\n",
        "                    \"repo_name\": item[\"name\"],\n",
        "                    \"repo_id\": item[\"id\"],\n",
        "                    \"favoriteCount\": item[\"stats\"][\"favoriteCount\"],\n",
        "                    \"downloadCount\": item[\"stats\"][\"downloadCount\"],\n",
        "                    \"CreatorName\": item[\"creator\"][\"username\"],\n",
        "                    \"version_list\": model_ver_list,\n",
        "                }\n",
        "\n",
        "                if model_ver_list:\n",
        "                    state.append(state_dict)\n",
        "\n",
        "        if not state:\n",
        "            raise ValueError(\"No matches found for your criteria\")\n",
        "\n",
        "        model_dict = self.repo_select_civitai(\n",
        "            state = state,\n",
        "            auto = auto\n",
        "            )\n",
        "        files_list = self.version_select_civitai(\n",
        "            state = model_dict,\n",
        "            auto = auto\n",
        "            )\n",
        "\n",
        "        file_status_dict = self.file_select_civitai(\n",
        "            state_list = files_list,\n",
        "            auto = auto)\n",
        "\n",
        "        save_path = self.civitai_save_path()\n",
        "\n",
        "        return (file_status_dict[\"download_url\"], save_path)\n",
        "\n",
        "\n",
        "\n",
        "class with_Flax(basic_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def sd_to_flax(self,url_or_path):\n",
        "        hf_path,file_name,model_file_path=\"\",\"\",\"\"\n",
        "        #from_config or from_single_file\n",
        "        if os.path.isfile(url_or_path):\n",
        "            model_file_path=url_or_path\n",
        "\n",
        "        #from_pretrain\n",
        "        elif os.path.isdir(url_or_path):\n",
        "            if os.path.exists(os.path.join(url_or_path, self.Config_file)):\n",
        "                return url_or_path\n",
        "\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"model_index.json not found in '{url_or_path}'\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Invalid dir_path.\")\n",
        "\n",
        "\n",
        "        model_saved_dir = os.path.join(os.path.dirname(model_file_path),\"converted\")\n",
        "        os.makedirs(model_saved_dir,exist_ok=True)\n",
        "        if not os.path.isfile(os.path.join(model_saved_dir,\"model_index.json\")):\n",
        "            print(\"Converting the model...\")\n",
        "            #from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "            is_from_safetensors = self.check_for_safetensors(url_or_path)\n",
        "            from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "            save_pipeline = download_from_original_stable_diffusion_ckpt(url_or_path, from_safetensors = is_from_safetensors)\n",
        "            #can not use output format :safetensors\n",
        "            save_pipeline.save_pretrained(model_saved_dir, safe_serialization = False)\n",
        "            print(\"End of model conversion\")\n",
        "            del save_pipeline\n",
        "        return model_saved_dir\n",
        "\n",
        "    def Flax_pipe_create(self,url_or_path):\n",
        "        model_dir_path=self.sd_to_flax(url_or_path)\n",
        "        model_index_path=os.path.join(model_dir_path,self.Config_file)\n",
        "        with open(model_index_path, \"r\") as f:\n",
        "            pipeline_class_name = json.load(f)[\"_class_name\"]\n",
        "        pipeline_class = getattr(diffusers, pipeline_class_name)\n",
        "        logger.info(f\"Pipeline class imported: {pipeline_class_name}.\")\n",
        "        try:\n",
        "            base_pipe,base_params = FlaxDiffusionPipeline.from_pretrained(model_dir_path,\n",
        "                                                                           dtype=jax.numpy.bfloat16,\n",
        "                                                                           use_safetensors=True)\n",
        "\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Insufficient memory.\")\n",
        "        params = replicate(base_params)\n",
        "        return base_pipe,params\n",
        "\n",
        "\n",
        "class Config_Mix(Huggingface,\n",
        "                 Civitai,\n",
        "                 with_Flax,\n",
        "                 basic_config,\n",
        "                 data_config,\n",
        "                 config_check):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "class pipeline_setup(Config_Mix):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.use_TPU = self.is_TPU()\n",
        "        super().__init__()\n",
        "        self.model_path = \"\"\n",
        "\n",
        "\n",
        "    def File_search(self):\n",
        "        \"\"\"\n",
        "        only single file\n",
        "        \"\"\"\n",
        "\n",
        "        search_path=\"\"\n",
        "        paths = []\n",
        "        for root, dirs, files in os.walk(\"/\"):\n",
        "            for file in files:\n",
        "                if any(file.endswith(ext) for ext in self.exts):\n",
        "                    path = os.path.join(root, file)\n",
        "                    if path not in self.exclude:\n",
        "                        if not path.startswith(\"/root/.cache\"):\n",
        "                            paths.append(path)\n",
        "        num_path=len(paths)\n",
        "        if not num_path:\n",
        "            raise FileNotFoundError(\"\\033[33mModel File not found\\033[0m\")\n",
        "        else:\n",
        "            print(f\"{num_path} candidate model files found.\")\n",
        "        for s, path in enumerate(paths, 1):\n",
        "            print(f\"{s}: {path}\")\n",
        "        num = int(input(f\"Please enter a number(1〜{num_path}): \"))\n",
        "        if 1 <= num <= len(paths):\n",
        "            search_path=(paths[num-1])\n",
        "            print(f\"Selected model file: {search_path}\\n\")\n",
        "        else:\n",
        "            raise TypeError(f\"\\033[33mOnly natural numbers in the following range are valid : (1〜{len(paths)})\\033[0m\")\n",
        "        return search_path\n",
        "\n",
        "\n",
        "    def model_set(self,\n",
        "                  model_select,\n",
        "                  auto = False,\n",
        "                  model_type = \"Checkpoint\",\n",
        "                  branch = \"main\",\n",
        "                  download: bool = False) -> list:\n",
        "        \"\"\"\n",
        "        return:\n",
        "        [model_path:str, {base_model_path: str,from_single_file: bool}]\n",
        "        \"\"\"\n",
        "\n",
        "        if not model_type  in [\"Checkpoint\", \"TextualInversion\", \"LORA\", \"Hypernetwork\", \"AestheticGradient\", \"Controlnet\", \"Poses\"]:\n",
        "            raise TypeError(f'Wrong argument. Valid values are \"Checkpoint\", \"TextualInversion\", \"LORA\", \"Hypernetwork\", \"AestheticGradient\", \"Controlnet\", \"Poses\". What was passed on {model_type}')\n",
        "        local = True if download else False\n",
        "        return_dict = {\"base_model_path\":model_select,\n",
        "                       \"from_dingle_file\":False,\n",
        "                       \"local\":local,\n",
        "                       \"model_url\":\"\",\n",
        "                       }\n",
        "        show_url_or_path = \"\"\n",
        "        from_single_file = False\n",
        "        model_path = \"\"\n",
        "        file_path = \"\"\n",
        "        if model_select in self.model_dict:\n",
        "            model_path_to_check = self.model_dict[model_select]\n",
        "            if self.is_url_valid(f\"https://huggingface.co/{model_path_to_check}\"):\n",
        "                model_select = model_path_to_check\n",
        "\n",
        "        if model_select == \"search\":\n",
        "            #only file\n",
        "            model_path = self.File_search()\n",
        "            return_dict[\"from_single_file\"] = False\n",
        "            return_dict[\"url_or_path\"] = model_path\n",
        "\n",
        "        elif model_select.startswith(\"https://huggingface.co/\"):\n",
        "            if not self.is_url_valid(model_select):\n",
        "                raise ValueError(self.Error_M1)\n",
        "            else:\n",
        "                if download:\n",
        "                    model_path = self.run_hf_download(model_select)\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "                    return_dict[\"url_or_path\"] = model_path\n",
        "                else:\n",
        "                    model_path = model_select\n",
        "                    return_dict[\"from_single_file\"] = True\n",
        "                    return_dict[\"url_or_path\"] = model_path\n",
        "\n",
        "        elif model_select.startswith(\"https://civitai.com/\"):\n",
        "            #local file\n",
        "            model_path = self.public_civiai(model_select,\n",
        "                                            auto,\n",
        "                                            model_type)\n",
        "            return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        elif os.path.isfile(model_select):\n",
        "            model_path = model_select\n",
        "            return_dict[\"from_single_file\"] = True\n",
        "            return_dict[\"local\"] = True\n",
        "\n",
        "        elif os.path.isdir(model_select):\n",
        "            if os.path.exists(os.path.join(model_select,self.Config_file)):\n",
        "                return_dict[\"model_path\"] = model_select\n",
        "                return_dict[\"from_single_file\"] = False\n",
        "                return_dict[\"local\"] = True\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"model_index.json not found in {model_select}\")\n",
        "\n",
        "        elif model_select.count(\"/\") == 1:\n",
        "            if auto and self.diffusers_model_check(model_select):\n",
        "                if download:\n",
        "                    model_path = self.run_hf_download(model_select)\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "                else:\n",
        "                    model_path = model_select\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "            elif auto and (not self.hf_model_check(model_select)):\n",
        "                raise ValueError(f'The specified repository could not be found, please try turning off \"auto\" (model_select:{model_select})')\n",
        "            else:\n",
        "                file_path=self.file_name_set(model_select,auto,model_type)\n",
        "                if file_path == \"_hf_no_model\":\n",
        "                    raise ValueError(\"Model not found\")\n",
        "                elif file_path == \"_DFmodel\":\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(model_select)\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                    else:\n",
        "                        model_path = model_select\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                else:\n",
        "                    hf_model_path=f\"https://huggingface.co/{model_select}/blob/{branch}/{file_path}\"\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(hf_model_path)\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "                    else:\n",
        "                        model_path = hf_model_path\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        else:\n",
        "            model_name = self.model_name_search(model_select,auto)\n",
        "            #self.hf_repo_id = model_name\n",
        "            #hf->civit\n",
        "            if not model_name == \"_hf_no_model\":\n",
        "                file_path = self.file_name_set(model_name,auto,model_type)\n",
        "                if model_path == \"_DFmodel\":\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(file_path)\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                    else:\n",
        "                        model_path = model_name #f\"https://huggingface.co/{model_name}\"\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "\n",
        "                else:\n",
        "                    hf_model_path = f\"https://huggingface.co/{model_name}/blob/{branch}/{file_path}\"\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(hf_model_path)\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "                    else:\n",
        "                        model_path = hf_model_path\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "\n",
        "            else:\n",
        "                model_url, model_path = self.civitai_download(\n",
        "                    model_select,\n",
        "                    auto,\n",
        "                    model_type)\n",
        "\n",
        "                return_dict[\"from_single_file\"] = True\n",
        "                return_dict[\"model_url\"] = model_url\n",
        "\n",
        "        if not return_dict[\"model_url\"]:\n",
        "            return_dict[\"model_url\"] = model_path\n",
        "\n",
        "        return [model_path,return_dict]\n",
        "\n",
        "\n",
        "\n",
        "    def pipe_status_check(self,pipeline):\n",
        "        from diffusers.pipelines.stable_diffusion import (StableDiffusionSafetyChecker,FlaxStableDiffusionSafetyChecker)\n",
        "        from transformers import CLIPImageProcessor\n",
        "        pipe_class_name_ = pipeline.__class__.__name__\n",
        "        pipe_type = self.pipeline_metod_type(self.import_on_str(pipe_class_name_,\"diffusers\"))\n",
        "        if hasattr(pipeline,\"safety_checker\"):\n",
        "            if getattr(pipeline,\"safety_checker\") is None:\n",
        "                if pipe_type == \"flax\":\n",
        "                    pipeline.safety_checker = FlaxStableDiffusionSafetyChecker.from_pretrained(\n",
        "                        \"CompVis/stable-diffusion-safety-checker\", from_pt=True\n",
        "                    )\n",
        "                elif pipe_type in [\"torch\", \"onnx\"]:\n",
        "                    pipeline.safety_checker = StableDiffusionSafetyChecker.from_pretrained(\n",
        "                        \"CompVis/stable-diffusion-safety-checker\"\n",
        "                    )\n",
        "        if hasattr(pipeline,\"feature_extractor\"):\n",
        "            if getattr(pipeline,\"feature_extractor\") is None:\n",
        "                pipeline.feature_extractor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        return pipeline\n",
        "\n",
        "\n",
        "    def pipe_create(self,\n",
        "                    model_path,\n",
        "                    from_single_file):\n",
        "        logger.debug(f\"input_url; {self.input_url}\")\n",
        "        logger.debug(f\"model_path; {self.model_path}\")\n",
        "\n",
        "        if from_single_file:\n",
        "            #not from_confg\n",
        "            base_pipe = StableDiffusionPipeline.from_single_file(\n",
        "                model_path\n",
        "                ).to(self.device)\n",
        "        else:\n",
        "            base_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                model_path\n",
        "                ).to(self.device)\n",
        "\n",
        "        if self.device == \"cuda\":\n",
        "            base_pipe.to(torch_dtype = torch.float16)\n",
        "\n",
        "        return base_pipe\n",
        "\n",
        "    def pipeline_task(self,model_select,auto):\n",
        "        logger.debug(f\"auto: {auto}\")\n",
        "        logger.debug(f\"model_select: {model_select}\")\n",
        "        params = None\n",
        "        model_path,model_dict = self.model_set(model_select,\n",
        "                                               auto = auto,\n",
        "                                               download = False)\n",
        "        #model_path = model_dict[\"base_model_path\"]\n",
        "        from_single_file = model_dict[\"from_single_file\"]\n",
        "\n",
        "        update_model_path = self.check_func_hist(key=\"model_path\",value=model_path)\n",
        "\n",
        "        if self.use_TPU:\n",
        "            try:\n",
        "                base_pipe,params = self.Flax_pipe_create(model_path)\n",
        "            except OSError as a:\n",
        "                logger.debug(a)\n",
        "                raise OSError(\"Check your internet connection\")\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                base_pipe = self.pipe_create(model_path, from_single_file)\n",
        "            except OSError as a:\n",
        "                logger.debug(a)\n",
        "                raise OSError(\"Check your internet connection\")\n",
        "        base_pipe = self.pipe_status_check(base_pipe)\n",
        "        return base_pipe, params, model_dict[\"model_url\"]\n",
        "\n",
        "\n",
        "pipe_set = pipeline_setup()\n",
        "base_pipe, parmer, model_path = pipe_set.pipeline_task(\n",
        "    model_select = model_select,\n",
        "    auto = auto)\n",
        "\n",
        "if device_type == \"cpu\" and base_pipe.dtype == torch.float16:\n",
        "    if DEBUG:\n",
        "        logger.warning(\"base_pipe.dtype is torch.float16 with cpu\")\n",
        "    else:\n",
        "        raise RuntimeError(\"CPU cannot use base_pipe with half precision (torch.float16)\")\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\033[32m\\n------------------\\n\")\n",
        "print(f\"\\033[32mmodel_path: {model_path}\\033[0m\\n\")\n",
        "print(\"\\033[32mModel set-up has been completed.\\033[0m\")\n",
        "\n",
        "Step2_finish = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCtR5TwuUvY"
      },
      "outputs": [],
      "source": [
        "#@title  #Step.3 Pipeline Setup{display-mode: \"form\"}\n",
        "\n",
        "# @markdown >Pipeline class set [#info](#Pipeline_class_set_help)\n",
        "\n",
        "Pipeline_type = \"txt2img\" # @param [\"txt2img\", \"img2img\", \"Inpaint\", \"txt2video\"] {allow-input: true}\n",
        "\n",
        "#@markdown * Select from pull-down menu\n",
        "\n",
        "#@markdown * Enter pipeline class name\n",
        "\n",
        "#@markdown >Scheduler set [#info](#Scheduler_select)\n",
        "\n",
        "Scheduler_select = \"DDIM\" # @param [\"DPM\", \"DDPM\", \"DDIM\", \"DEISM\", \"DPM_S\", \"EulerA\", \"Euler\", \"HeunD\", \"K_DPM2D\", \"K_DPM2AD\", \"LMSD\", \"PNDM\", \"UniPCM\", \"EulerA_with_sonar\", \"Euler_with_sonar\"] {allow-input: true}\n",
        "\n",
        "#@markdown >Vae set (Enter only if you want to exchange vae) [#info](#Vae_set)\n",
        "\n",
        "vae_select = \"\" # @param [\"waifu-diffusion\", \"Counterfeit-V2.5\", \"anything-v3.0\"] {allow-input: true}\n",
        "\n",
        "auto = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown >Extra parameter\n",
        "\n",
        "set_extra_parameter = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown * If you change them, you can update the parameters by pressing Update Values.\n",
        "\n",
        "#@markdown >Filter switching\n",
        "\n",
        "#@markdown **Caution : Be careful when changing it**\n",
        "\n",
        "Filter_off = False  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if \"Step2_finish\"not in globals():\n",
        "    raise NameError(\"\\033[33mPlease execute Step.2 first\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "class vae_set(Config_Mix):\n",
        "    def __init__(self):\n",
        "        self.use_input_url=False\n",
        "        self.vae_path=\"\"\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def vae_load(self,vae_model_name=\"\",auto=False):\n",
        "        if vae_model_name:\n",
        "            model_names = self.model_name_search(vae_model_name,auto)\n",
        "            vae_path = self.file_name_set(model_names,auto,download=True)\n",
        "            if vae_path == \"_DFmodel\":\n",
        "                vae_path = model_names\n",
        "                single_file = False\n",
        "\n",
        "            elif os.path.isfile(vae_path):\n",
        "                single_file = True\n",
        "            elif os.path.isdir(vae_path):\n",
        "                single_file = False\n",
        "            else:\n",
        "                single_file = True\n",
        "\n",
        "            if self.use_TPU:\n",
        "                if single_file:\n",
        "                    vae = FlaxAutoencoderKL.from_single_file(vae_path)\n",
        "                else:\n",
        "                    try:\n",
        "                        vae = FlaxAutoencoderKL.from_pretrained(vae_path)\n",
        "                    except Exception:\n",
        "                        vae = FlaxAutoencoderKL.from_pretrained(vae_path , subfolder=\"vae\")\n",
        "            else:\n",
        "                if single_file:\n",
        "                    vae = AutoencoderKL.from_single_file(vae_path)\n",
        "                else:\n",
        "                    try:\n",
        "                        vae = AutoencoderKL.from_pretrained(vae_path)\n",
        "                    except Exception:\n",
        "                        vae = AutoencoderKL.from_pretrained(vae_path , subfolder=\"vae\")\n",
        "\n",
        "        else:\n",
        "            vae = self.base_pipe.vae\n",
        "            vae_path = \"\"\n",
        "        return vae, vae_path\n",
        "\n",
        "\n",
        "\n",
        "class Scheduler_set(Config_Mix):\n",
        "    Scheduler_dict={\n",
        "            \"DDPM\": \"DDPMScheduler\",\n",
        "            \"DDIM\": \"DDIMScheduler\",\n",
        "            \"PNDM\": \"PNDMScheduler\",\n",
        "            \"LMSD\" : \"LMSDiscreteScheduler\",\n",
        "            \"DPM\":  \"DPMSolverMultistepScheduler\",\n",
        "            \"EulerA\": \"EulerAncestralDiscreteScheduler\",\n",
        "            \"Euler\": \"EulerDiscreteScheduler\",\n",
        "            \"DEISM\":\"DEISMultistepScheduler\",\n",
        "            \"UniPCM\":\"UniPCMultistepScheduler\",\n",
        "            \"K_DPM2D\":\"KDPM2DiscreteScheduler\",\n",
        "            \"DPM_S\":\"DPMSolverSinglestepScheduler\",\n",
        "            \"K_DPM2AD\":\"KDPM2AncestralDiscreteScheduler\",\n",
        "            \"HeunD\":\"HeunDiscreteScheduler\",\n",
        "            }\n",
        "    Special_Scheduler_dict={\n",
        "            \"Euler_with_sonar\":\"Euler_Scheduler_with_sonar\",\n",
        "            \"EulerA_with_sonar\":\"EulerA_Scheduler_with_sonar\",\n",
        "            }\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.scheduler_name = \"\"\n",
        "    \"\"\"\n",
        "    def Euler_sh_set(self,Scheduler_name):\n",
        "        '''\n",
        "        Args:\n",
        "            Scheduler_name: Either \"CustomEuler\" or \"CustomEulerA\".\n",
        "        '''\n",
        "        assert Scheduler_name in [\"CustomEuler\", \"CustomEulerA\"]\n",
        "        if not os.path.exists(\"./script/Euler_mod\"):\n",
        "            os.makedirs(\"./script/Euler_mod\",exist_ok=True)\n",
        "            !git clone https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git ./script/Euler_mod\n",
        "        path_1 = \"./script/Euler_mod/EulerANew.py\"\n",
        "        path_2 = \"./script/Euler_mod/EulerNew.py\"\n",
        "        if path_1 not in sys.path:\n",
        "            sys.path.append(path_1)\n",
        "            sys.path.append(path_2)\n",
        "        os.chdir(\"./script/Euler_mod\")\n",
        "        if Scheduler_name==\"CustomEulerA\":\n",
        "            !python EulerANew.py\n",
        "            Scheduler_object=self.import_on_str(\"EulerA\",module_name=\"EulerANew\")\n",
        "        else:\n",
        "            !python EulerNew.py\n",
        "            Scheduler_object=self.import_on_str(\"Euler\",module_name=\"EulerNew\")\n",
        "        os.chdir(\"../..\")\n",
        "        return Scheduler_object\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def scheduler_setup(self,Scheduler_select):\n",
        "        if Scheduler_select in self.Special_Scheduler_dict:\n",
        "            if not os.path.isdir(\"/content/script/Euler_sonar\"):\n",
        "                !git clone -q  https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git /content/script/Euler_sonar\n",
        "            from Euler_sonar.EulerNew import Euler as Euler_Scheduler_with_sonar\n",
        "            from Euler_sonar.EulerANew import EulerA as EulerA_Scheduler_with_sonar\n",
        "            if Scheduler_select == \"Euler_with_sonar\":\n",
        "                Scheduler_class = Euler_Scheduler_with_sonar\n",
        "            else:\n",
        "                Scheduler_class = EulerA_Scheduler_with_sonar\n",
        "        else:\n",
        "            logger.debug(f\"scheduler: {Scheduler_select}\")\n",
        "            if Scheduler_select in self.Scheduler_dict:\n",
        "                Scheduler_select = self.Scheduler_dict[Scheduler_select]\n",
        "            try:\n",
        "                Scheduler_class = getattr(diffusers, Scheduler_select)\n",
        "            except AttributeError:\n",
        "                _error = self.make_Error_message(Scheduler_select,dir(diffusers),need_txt=\"Scheduler\")\n",
        "                raise AttributeError(f'\"{Scheduler_select}\" not found. Maybe \"{_error}\" ?')\n",
        "        return Scheduler_class\n",
        "\n",
        "\n",
        "\n",
        "class make_main_pipe(Scheduler_set,\n",
        "                     vae_set,\n",
        "                     Config_Mix\n",
        "                     ):\n",
        "    def __init__(self,\n",
        "                 pipe_name,\n",
        "                 Filter_off,\n",
        "                 Scheduler_select,\n",
        "                 vae_select,\n",
        "                 auto,\n",
        "                 base_pipe,\n",
        "                 parmer):\n",
        "        super().__init__()\n",
        "        self.pipeline_name = self.pipeline_name_convert(pipe_name)\n",
        "        self.pipeline_class = self.pipeline_class_set(self.pipeline_name)\n",
        "        self.pipeline_type = self.pipeline_metod_type(self.pipeline_class)\n",
        "        self.Scheduler_class = super().scheduler_setup(Scheduler_select)\n",
        "        self.Filter_off = Filter_off\n",
        "        self.base_pipe = base_pipe\n",
        "        self.parmer = parmer\n",
        "        self.vae,self.vae_path = self.vae_load(vae_select, auto)\n",
        "        self.auto = auto\n",
        "        self.pipe_args_setup = {}\n",
        "        self.stetas = {}\n",
        "        self.from_pipe_args = {}\n",
        "        self.main_name = \"\"\n",
        "        self.pipe_module = None\n",
        "\n",
        "\n",
        "\n",
        "    def make_Error_message(self,\n",
        "                           base_txt,\n",
        "                           list_obj,\n",
        "                           need_txt=\"\"):\n",
        "            \"\"\"\n",
        "            Args:\n",
        "            base_txt : base_txt: Returns the string most similar to the one specified here. Note that if \"need_txt\" is specified, it must be included.\n",
        "            list_obj : Search list for candidate strings\n",
        "            need_txt : Strings that must be included in the candidate list\n",
        "            \"\"\"\n",
        "            if not list_obj:\n",
        "                list_obj = dir(diffusers)\n",
        "\n",
        "            if need_txt:\n",
        "                _diffusers_module = self.sort_list_obj(list_obj,need_txt)\n",
        "            else:\n",
        "                _diffusers_module = (dir(diffusers))\n",
        "            logger.debug(type(_diffusers_module))\n",
        "            pretxt = self.max_temper(base_txt,_diffusers_module)\n",
        "            if pretxt:\n",
        "                return pretxt[0]\n",
        "            else:\n",
        "                raise AttributeError(\"Please try another pipeline\")\n",
        "\n",
        "    def pipeline_name_convert(self,pipeline_name: str):\n",
        "        #\"StableDiffusionPipeline\"\n",
        "        pipe_class_dict={\n",
        "            \"txt2img\":\"AutoPipelineForText2Image\",\n",
        "            \"img2img\":\"AutoPipelineForImage2Image\",\n",
        "            \"Inpaint\":\"AutoPipelineForInpainting\",\n",
        "            \"txt2video\":\"TextToVideoZeroPipeline\",\n",
        "            }\n",
        "        #FlaxStableDiffusionPipeline,FlaxStableDiffusionImg2ImgPipeline\n",
        "        Flax_pipe_class_dict={\n",
        "        \"txt2img\":\"FlaxStableDiffusionPipeline\",\n",
        "        \"img2img\":\"FlaxStableDiffusionImg2ImgPipeline\",\n",
        "        \"Inpaint\":\"FlaxStableDiffusionInpaintPipeline\",\n",
        "        \"txt2video\": \"\",\n",
        "        }\n",
        "        params = None\n",
        "        if self.use_TPU:\n",
        "            if pipeline_name == \"txt2video\":\n",
        "                raise ValueError(\"Video generation in TPU requires direct specification of the class. (At the time of development, there was no class for video generation in TPU)\")\n",
        "            elif pipeline_name in Flax_pipe_class_dict:\n",
        "                pipeline_name = Flax_pipe_class_dict[pipeline_name]\n",
        "        else:\n",
        "            if pipeline_name in pipe_class_dict:\n",
        "                pipeline_name = pipe_class_dict[pipeline_name]\n",
        "\n",
        "        return pipeline_name\n",
        "\n",
        "\n",
        "    def pipeline_class_set(self,\n",
        "                           pipeline_name : str):\n",
        "        try:\n",
        "            pipe_class = getattr(diffusers, pipeline_name)\n",
        "        except AttributeError:\n",
        "            pretxt = self.make_Error_message(pipeline_name , dir(diffusers),need_txt=\"Pipeline\")\n",
        "            raise AttributeError(f\"'{pipeline_name}' not found. Maybe '{pretxt}' ?\")\n",
        "        return pipe_class\n",
        "\n",
        "\n",
        "    def main_pipe_set(self):\n",
        "        txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe=None,None,None,None,None\n",
        "        textual_inversion_dict ={\n",
        "            \"EasyNegativeV2.safetensors\": \"EasyNegative\",\n",
        "            \"bad-hands-5.pt\": \"bad-hands\",\n",
        "            }\n",
        "        init_method_list = [\n",
        "            \"text_encoder\",\n",
        "            \"tokenizer\",\n",
        "            \"unet\",\n",
        "            \"image_encoder\",\n",
        "            ]\n",
        "\n",
        "        logger.debug(self.Scheduler_class)\n",
        "        self.stetas[\"vae\"] = self.vae\n",
        "        self.stetas[\"scheduler\"] = self.Scheduler_class.from_config(self.base_pipe.scheduler.config)\n",
        "        logger.debug(self.stetas[\"scheduler\"])\n",
        "        stetas_check = self.get_call_method(class_name=self.pipeline_name,method_name='__init__')\n",
        "        for init_method in init_method_list:\n",
        "            if ((init_method in stetas_check) and\n",
        "                (hasattr(self.base_pipe, init_method))):\n",
        "                self.stetas[init_method] = getattr(self.base_pipe, init_method)\n",
        "        if self.Filter_off:\n",
        "            if \"feature_extractor\" in stetas_check:\n",
        "                self.stetas[\"feature_extractor\"] = None\n",
        "                self.from_pipe_args[\"feature_extractor\"] = None\n",
        "\n",
        "            if \"safety_checker\" in stetas_check or (self.pipeline_name in self.Auto_pipe_class):\n",
        "                self.stetas[\"safety_checker\"] = None\n",
        "\n",
        "            elif \"load_safety_checker\" in stetas_check:\n",
        "                self.stetas[\"load_safety_checker\"] = False\n",
        "\n",
        "            elif \"requires_safety_checker\" in stetas_check:\n",
        "                 self.stetas[\"requires_safety_checker\"] = False\n",
        "\n",
        "            else:\n",
        "                print(f'\"{self.pipeline_name}\"ではsatety_checkerの指定が使用できません')\n",
        "        else:\n",
        "            if \"feature_extractor\" in stetas_check:\n",
        "                self.stetas[\"feature_extractor\"] = self.base_pipe.feature_extractor\n",
        "\n",
        "            if \"safety_checker\" in stetas_check or (self.pipeline_name in self.Auto_pipe_class):\n",
        "                self.stetas[\"safety_checker\"] = self.base_pipe.safety_checker\n",
        "\n",
        "            if \"load_safety_checker\" in stetas_check:\n",
        "                self.stetas[\"load_safety_checker\"] = True\n",
        "\n",
        "\n",
        "\n",
        "        logger.debug(f\"steate: {self.stetas.keys()}\")\n",
        "        if \"from_pipe\" in dir(self.pipeline_class):\n",
        "            use_from_pipe = True\n",
        "        else:\n",
        "            use_from_pipe = False\n",
        "        if self.use_TPU:\n",
        "            if use_from_pipe:\n",
        "                if self.Filter_off:\n",
        "                    self.base_pipe.safety_checker = None\n",
        "                self.base_pipe.sheduler = self.stetas[\"scheduler\"]\n",
        "                self.base_pipe.vae = self.vae.to(torch.float16)\n",
        "                main_pipe = self.pipeline_class.from_pipe(self.base_pipe).to(dtype=jax.numpy.bfloat16)\n",
        "                for key,value in self.stetas.items():\n",
        "                    setattr(main_pipe,key,value)\n",
        "\n",
        "            else:\n",
        "                main_pipe = self.pipeline_class(**self.stetas,dtype=jax.numpy.bfloat16)\n",
        "\n",
        "        else:\n",
        "            if use_from_pipe:\n",
        "\n",
        "                if self.Filter_off:\n",
        "                    self.base_pipe.safety_checker = None\n",
        "                main_pipe = self.pipeline_class.from_pipe(self.base_pipe).to(self.device, torch.float16)\n",
        "                for key,value in self.stetas.items():\n",
        "                    setattr(main_pipe,key,value)\n",
        "            else:\n",
        "                main_pipe = self.pipeline_class(**self.stetas).to(self.device, torch.float16)\n",
        "\n",
        "\n",
        "\n",
        "        if hasattr(main_pipe.__class__,\"load_textual_inversion\"):\n",
        "            if \"EasyNegative\" not in main_pipe.tokenizer.get_vocab():\n",
        "                try:\n",
        "                    main_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                except Exception:\n",
        "                    logger.info(\"EasyNegativeの適用に失敗しました\")\n",
        "            if \"bad-hands\" not in main_pipe.tokenizer.get_vocab():\n",
        "                try:\n",
        "                    main_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                except Exception:\n",
        "                    logger.info(\"bad-handsの適用に失敗しました\")\n",
        "\n",
        "\n",
        "        if self.device == \"cpu\" and hasattr(self.pipeline_class,\"enable_model_cpu_offload\"):\n",
        "\n",
        "            main_pipe.enable_model_cpu_offload()\n",
        "\n",
        "        if hasattr(self.pipeline_class,\"fuse_qkv_projections\"):\n",
        "            #torch.compile -> bug\n",
        "            main_pipe.fuse_qkv_projections()\n",
        "\n",
        "        if self.device_type == \"TPU\":\n",
        "            main_pipe.to(dtype=jax.numpy.bfloat16)\n",
        "        else:\n",
        "            main_pipe.to(device=self.device_type,dtype=torch.float16)\n",
        "\n",
        "        return main_pipe\n",
        "\n",
        "MMP=make_main_pipe(pipe_name = Pipeline_type,\n",
        "                   Filter_off = Filter_off,\n",
        "                   Scheduler_select = Scheduler_select,\n",
        "                   vae_select = vae_select,\n",
        "                   auto = auto,\n",
        "                   base_pipe = base_pipe,\n",
        "                   parmer = parmer)\n",
        "main_pipe = MMP.main_pipe_set()\n",
        "\n",
        "\n",
        "\n",
        "class PipeSetUI:\n",
        "    def __init__(self):\n",
        "        self.del_key_list = [\n",
        "            \"self\", \"prompt\", \"prompt_ids\", \"negative_prompt\", \"neg_prompt\", \"device\",\n",
        "            \"guidance_scale\", \"num_inference_steps\", \"generator\", \"height\", \"width\", \"image\",\n",
        "            \"strength\", \"t0\", \"t1\", \"video_length\", \"num_frames\", \"prng_seed\", \"params\",\n",
        "            \"return_dict\", \"callback_on_step_end_tensor_inputs\",\"timesteps\", \"sigmas\"\n",
        "        ]\n",
        "        self.widgets_dict = {}\n",
        "\n",
        "\n",
        "    def display(self, pipeline, input_dict):\n",
        "        args_info = self.get_call_args_info(pipeline)\n",
        "        self.display_args(args_info, input_dict)\n",
        "\n",
        "\n",
        "    def get_call_args_info(self, pipeline):\n",
        "        if not hasattr(pipeline.__class__, '__call__'):\n",
        "            raise ValueError(\"pipeline does not have a __call__ method\")\n",
        "        else:\n",
        "            sig = inspect.signature(pipeline.__call__)\n",
        "\n",
        "        args_info = {}\n",
        "        for name, param in sig.parameters.items():\n",
        "            if param.kind in (param.VAR_POSITIONAL, param.VAR_KEYWORD):\n",
        "                continue\n",
        "\n",
        "            arg_info = {\n",
        "                'type': param.annotation if param.annotation != inspect.Parameter.empty else None,\n",
        "                'default': param.default if param.default != inspect.Parameter.empty else None\n",
        "            }\n",
        "            args_info[name] = arg_info\n",
        "        return args_info\n",
        "\n",
        "\n",
        "    def on_button_click(self, _):\n",
        "        for arg, widget in self.widgets_dict.items():\n",
        "            parameter_dict[arg] = widget.value if widget.value != 'None' else None\n",
        "        output.clear(output_tags=\"button_click_txt\")\n",
        "        with output.use_tags(\"button_click_txt\"):\n",
        "            sys.stdout.write(\"\\n\\033[34m----------------------\\n\")\n",
        "            sys.stdout.write(\"Updated parameter \\n\\n\")\n",
        "            for key, value in parameter_dict.items():\n",
        "                sys.stdout.write(f\"{key}: {value}\\n\\n\")\n",
        "                sys.stdout.flush();\n",
        "            sys.stdout.write(\"\\033[0m\")\n",
        "\n",
        "\n",
        "    def extract_union_options(self, union_type):\n",
        "        options = set()\n",
        "        for ut in union_type.__args__:\n",
        "            if hasattr(ut, '__origin__') and ut.__origin__ == Union:\n",
        "                options.update(self.extract_union_options(ut))\n",
        "            elif ut is type(None):\n",
        "                options.add('None')\n",
        "            elif isinstance(ut, type):\n",
        "                options.add(ut.__name__)\n",
        "            else:\n",
        "                options.add(str(ut))\n",
        "        return options\n",
        "\n",
        "\n",
        "    def display_args(self, args_info, input_dict):\n",
        "        widget_list=[]\n",
        "        for checked_key in list(args_info.keys()):\n",
        "            if checked_key in self.del_key_list:\n",
        "                del args_info[checked_key]\n",
        "\n",
        "        for arg, info in args_info.items():\n",
        "            if not isinstance(info[\"type\"], type):\n",
        "                arg_type = tuple(t for t in get_args(info[\"type\"]) if t is not type(None))\n",
        "                if len(arg_type) == 1:\n",
        "                    info[\"type\"] = arg_type[0]\n",
        "                else:\n",
        "                    info[\"type\"] = arg_type\n",
        "\n",
        "            if info['type'] == int:\n",
        "                widget = widgets.IntText(\n",
        "                    value=info['default'],\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == float:\n",
        "                widget = widgets.FloatText(\n",
        "                    value=info['default'],\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == str:\n",
        "                widget = widgets.Text(\n",
        "                    value=str(info['default']),\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == bool:\n",
        "                widget = widgets.Checkbox(\n",
        "                    value=info['default'] if isinstance(info['default'], bool) else True,\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            self.widgets_dict[arg] = widget\n",
        "            widget_list.append(widget)\n",
        "            self.widgets_dict[arg] = widget\n",
        "\n",
        "        for widget in widget_list:\n",
        "            if isinstance(widget, (widgets.Text, widgets.IntText, widgets.FloatText)):\n",
        "                display(widget)\n",
        "\n",
        "        for widget in widget_list:\n",
        "            if isinstance(widget, widgets.Checkbox):\n",
        "                display(widget)\n",
        "\n",
        "        button = widgets.Button(description=\"Update Values\",button_style=\"info\")\n",
        "        button.on_click(self.on_button_click)\n",
        "        display(button)\n",
        "\n",
        "\"\"\"\n",
        "ANSI Escape Code List\n",
        "\n",
        "Red: \\033[31m\n",
        "Yellow: \\033[33m\n",
        "Blue: \\033[34m\n",
        "Green: \\033[32m\n",
        "white(default): \\033[0m\n",
        "Light-blue: \\033[38;2;0;255;255m\n",
        "Yellowish-green: \\033[38;2;74;229;110m\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "if main_pipe.dtype == torch.float16 and device_type == \"cpu\":\n",
        "    print(\"\\033[31mWarning: float16 pipeline is not available on CPU\\033[0m\")\n",
        "\n",
        "if Scheduler_select not in Scheduler_set().Special_Scheduler_dict:\n",
        "    warning_txt = \" or \".join(Scheduler_set().Special_Scheduler_dict.keys())\n",
        "    print(f'\\n\\nMoment is only valid if Scheduler_select is either {warning_txt}.\\n')\n",
        "\n",
        "if Filter_off == False:\n",
        "    filter_level = \"Filter: Enabled\"\n",
        "else:\n",
        "    filter_level = \"\\033[33mFilter: Disabled\\033[0m\"\n",
        "\n",
        "print(\"\\033[34m____________________________________________________________________________\\n\\n\")\n",
        "\n",
        "print(f\"model_path: {model_path}\"+\"\\n\\n\")\n",
        "\n",
        "print(f\"scheduler: {main_pipe.scheduler.__class__.__name__}\\n\\n\")\n",
        "\n",
        "if vae_select:\n",
        "    print(f\"vae_path: {MMP.vae_path}\\n\\n\")\n",
        "\n",
        "print(f\"pipeline_class: {main_pipe.__class__.__name__}\\n\\n\")\n",
        "\n",
        "print(filter_level+\"\\n\\n\")\n",
        "\n",
        "print(\"\\033[32mReady for generation\\033[0m\")\n",
        "\n",
        "\n",
        "parameter_dict = {}\n",
        "if set_extra_parameter:\n",
        "    print(\"\\n\\033[34m____________________________________________________________________________\\n\")\n",
        "    print(\"Extra parameter\\033[0m\")\n",
        "    PipeSetUI().display(main_pipe.__class__, parameter_dict)\n",
        "\n",
        "\n",
        "Step3_finish = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONEtEJyRGYSL"
      },
      "source": [
        "#Option\n",
        "\n",
        "<details>\n",
        "<summary>Note</summary>\n",
        "\n",
        "* Available only if **Step.3** has already been performed.\n",
        "\n",
        "* If Step.3 is performed again, the runtime will be initialized, so the option must be applied again.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmpMRkz2QOyP"
      },
      "outputs": [],
      "source": [
        "#@title  (option) Load Lora{display-mode: \"form\"}\n",
        "\n",
        "model_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "auto = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "unload_lora = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if not unload_lora:\n",
        "    LORA_dict = pipe_set.model_set(\n",
        "        model_select = model_name,\n",
        "        auto=auto,\n",
        "        model_type=\"LORA\",\n",
        "        download=True)\n",
        "    LORA_PATH = LORA_dict[\"model_path\"]\n",
        "    try:\n",
        "        main_pipe.load_lora_weights(LORA_PATH)\n",
        "    except Exception:\n",
        "        raise ValueError(\"Failed to load LORA\")\n",
        "else:\n",
        "    try:\n",
        "        main_pipe.unload_lora_weights()\n",
        "    except Exception:\n",
        "        raise ValueError(\"Lora is not installed\")\n",
        "\n",
        "print(\"\\033[32mLora successfully loaded.\\033[0m\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KBSJk1kqN3Z"
      },
      "outputs": [],
      "source": [
        "#@title   (option) load textual inversion {display-mode: \"form\"}\n",
        "\n",
        "model_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#weight_name= \"\" # @param {type:\"string\"}\n",
        "\n",
        "token = \"\" # @param {type:\"string\"}\n",
        "\n",
        "auto = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "unload_textual_inversion = False # @param {type:\"boolean\"}\n",
        "\n",
        "class load_textual_inversion_cls(pipeline_setup):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tokenizer_names = [\"tokenizer\",\n",
        "                               \"tokenizer1\",\n",
        "                               \"tokenizer2\",]\n",
        "    def load_textual(\n",
        "            self,\n",
        "            pretrained_path,\n",
        "            token,\n",
        "            auto,\n",
        "            main_pipe):\n",
        "        state={}\n",
        "\n",
        "        tokenizer_list = []\n",
        "\n",
        "\n",
        "        for tokenizer_name in self.tokenizer_names:\n",
        "            base_tokenizer = getattr(main_pipe, tokenizer_name, None)\n",
        "            if base_tokenizer is not None:\n",
        "                tokenizer_list.append(base_tokenizer)\n",
        "\n",
        "        assert tokenizer_list, \"Tokenizer is not Found\"\n",
        "\n",
        "        check_tokenizer = tokenizer_list[0]\n",
        "\n",
        "        if token in check_tokenizer.get_vocab():\n",
        "            raise ValueError(\"Token has been used, please select another token.\")\n",
        "        elif os.path.isfile(pretrained_path):\n",
        "            state[\"pretrained_model_name_or_path\"] = pretrained_path\n",
        "            state[\"token\"] = token\n",
        "            #state[\"weight_name\"]=weight_name\n",
        "        else:\n",
        "            embed_path = self.model_set(model_select=pretrained_path,\n",
        "                                        model_type=\"TextualInversion\",\n",
        "                                        auto=auto,\n",
        "                                        download=True)\n",
        "            state[\"pretrained_model_name_or_path\"] = embed_path\n",
        "            state[\"token\"] = token\n",
        "            #state[\"weight_name\"] = self.weight_name\n",
        "        print(state)\n",
        "\n",
        "        main_pipe.load_textual_inversion(**state)\n",
        "        print(f\"CustomToken: {','.join(token_list)}\\n\")\n",
        "        return main_pipe\n",
        "\n",
        "\n",
        "    def unload_textual(\n",
        "            self,\n",
        "            token,\n",
        "            main_pipe):\n",
        "        if token:\n",
        "            print(f\"Only the following tokens will be unloaded: {token}\")\n",
        "            print(\"If you want to unload all tokens together, empty the tokens\")\n",
        "        try:\n",
        "            main_pipe.unload_textual_inversion(token)\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Unloadable Lora does not exist\")\n",
        "        return main_pipe\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ct=text_cadd_textual(Repo_id_or_path,weight_name,token,main_pipe)\n",
        "textual_cls = load_textual_inversion_cls()\n",
        "if not unload_textual_inversion:\n",
        "    main_pipe = textual_cls.load_textual(\n",
        "        pretrained_path=model_path,\n",
        "        token=token,\n",
        "        auto=auto,\n",
        "        main_pipe=main_pipe)\n",
        "else:\n",
        "    main_pipe = textual_cls.unload_textual(\n",
        "        token=token,\n",
        "        main_pipe=main_pipe)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Info\n",
        "If you have any questions, please read the description in the sub-function at the bottom."
      ],
      "metadata": {
        "id": "LUDG795doeli"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXSW3nl8UT7x"
      },
      "outputs": [],
      "source": [
        "#@title  #Step.4 Generation_Step{display-mode: \"form\"}\n",
        "\n",
        "##@markdown ># Basic Config\n",
        "\n",
        "# @markdown >Basic Status [#info](#Prompt_special_tokens_help)\n",
        "\n",
        "\n",
        "prompt = \"Please draw a beautiful Mount Fuji with the sun rising from the summit\" # @param [\"smail,girl, white hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\", \"smail,1girl, {white,blue,red,purple} hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress,loli\", \"Please draw a beautiful Mount Fuji with the sun rising from the summit\", \"Earth, space, high resolution\"] {allow-input: true}\n",
        "\n",
        "negative_prompt = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "seed = -1 # @param {type:\"number\"}\n",
        "\n",
        "num_imgs = 4 # @param {type:\"integer\"}\n",
        "\n",
        "input_image_path_or_dir = \"\" # @param {type:\"string\"}\n",
        "\n",
        "guidance_scale = 7 # @param {type:\"slider\", min:5, max:15, step:0.5}\n",
        "\n",
        "\n",
        "# @markdown >Special Status [#info](#Prompt_assistant_help)\n",
        "\n",
        "\n",
        "num_inference_steps = 30  # @param {type:\"integer\"}\n",
        "height = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\",\"1920\", \"3840\",\"4000\",\"7680\"] {allow-input: true}\n",
        "width = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\", \"1920\", \"3840\",\"4000\",\"7680\"] {allow-input: true}\n",
        "\n",
        "text_generate_model = \"gpt2-prompt-generator\" #@param [\"None\",\"MagicPrompt-Stable-Diffusion\",\"anime-anything-promptgen-v2\",\"gpt2-prompt-generator\"]\n",
        "\n",
        "#@markdown\n",
        "\n",
        "grit_image_width = 2 # @param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown * If 0, it will not be created.\n",
        "\n",
        "# @markdown >output config [#info](#File_name_Special_tokens_help)\n",
        "\n",
        "save_dir = \"\" # @param [\"/content/drive/MyDrive/\"] {allow-input: true}\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown > video config\n",
        "\n",
        "video_length = 10 # @param {type:\"integer\"}\n",
        "\n",
        "video_fps = 10 # @param {type:\"integer\"}\n",
        "\n",
        "num_frames = 9 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown >Sonar config <a name = \"Sonar_config\"></a>\n",
        "momentum = 0.95 # @param {type:\"slider\", min:0.8, max:1, step:0.05}\n",
        "\n",
        "momentum_hist = -0.1 # @param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "\n",
        "history_d = \"rand_init\" # @param [\"rand_new\", \"rand_init\"]\n",
        "\n",
        "# @markdown >Option\n",
        "Recommended_setting = True #@param {type:\"boolean\"}\n",
        "\n",
        "show_result = True  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "Hide_warnings = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if (Recommended_setting and\n",
        " (momentum-momentum_hist)<=0.3 and\n",
        " (Scheduler_select in Scheduler_set().Special_Scheduler_dict.keys())):\n",
        "        momentum_hist=momentum-0.3\n",
        "        print(f\"Momentum_hist is set to '{momentum_hist}' because the difference between momentum_hist and momentum is less than 3.\\n This process is a feature that comes with the 'recommended settings'\")\n",
        "\n",
        "\n",
        "if (not Recommended_setting) and (not Hide_warnings):\n",
        "    print('\\033[33mRecommended_setting is off')\n",
        "\n",
        "\n",
        "\n",
        "def run_html_js(path,moji):\n",
        "    import datetime\n",
        "    num=len(path)\n",
        "    now_a = datetime.datetime.now()\n",
        "    datetimes = now_a.strftime(\"%Y%m%d%H%M%S\")\n",
        "    html_dis = f'''\n",
        "    <style>\n",
        "      #clipborad-text-{datetimes} {{\n",
        "        border: none;\n",
        "        color: #0ff;\n",
        "        font-size: 15px;\n",
        "      }}\n",
        "    </style>\n",
        "    <span style=\"color: #4ae56e\" font-size:16px>{moji}</span> <!-- <p>タグを<span>タグに変更 -->\n",
        "    <input type=\"text\" value=\"{path}\" id=\"clipborad-text-{datetimes}\" size=\"{num}\" readonly> <!-- size属性とid属性を追加 -->\n",
        "    <button id=\"copy-button-{datetimes}\" onclick=\"copyToClipboard('{datetimes}')\">Copy</button> <!-- id属性とonclick属性を追加 -->\n",
        "    '''\n",
        "    js_code = '''\n",
        "    function copyToClipboard(datetimes) {\n",
        "      var copyText = document.getElementById(\"clipborad-text-\" + datetimes); // datetimeを結合\n",
        "      var copyButton = document.getElementById(\"copy-button-\" + datetimes); // datetimeを結合\n",
        "      copyText.select();\n",
        "      navigator.clipboard.writeText(copyText.value);\n",
        "      document.execCommand(\"copy\");\n",
        "      copyButton.textContent = \"Copied!\"; // ボタンの文字を変更\n",
        "      setTimeout(function() {\n",
        "        copyButton.textContent = \"Copy\"; // 1秒後に元に戻す\n",
        "        }, 1000);\n",
        "    }\n",
        "    '''\n",
        "    display(HTML(html_dis))\n",
        "    display(HTML('<script>{}</script>'.format(js_code)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Scheduler_setup(make_main_pipe):\n",
        "    def __init__(self,main_pipe):\n",
        "        self.main_pipe=main_pipe\n",
        "\n",
        "\n",
        "    def moment_set(self,Scheduler_select):\n",
        "        if Scheduler_select in self.Special_Scheduler_dict:\n",
        "            self.main_pipe.scheduler.history_d =history_d\n",
        "            self.main_pipe.scheduler.momentum = momentum\n",
        "            self.main_pipe.scheduler.momentum_hist = momentum_hist\n",
        "\n",
        "\n",
        "sc_set=Scheduler_setup(main_pipe)\n",
        "sc_set.moment_set(Scheduler_select)\n",
        "\n",
        "\n",
        "\n",
        "class txt_model_setup(basic_config):\n",
        "    def __init__(self,\n",
        "                 base_prompt,\n",
        "                 n_prompt,\n",
        "                 num_imgs,\n",
        "                 text_generate_model,\n",
        "                 main_pipe,\n",
        "                 Recommended_setting):\n",
        "        #global Prompt_list , make_images_list\n",
        "        #self.use_TPU=use_TPU\n",
        "        super().__init__()\n",
        "        self.prompt_list=[]\n",
        "        self.num_imgs = num_imgs\n",
        "        self.base_prompt = base_prompt\n",
        "        self.n_prompt = n_prompt\n",
        "        self.text_generate_model = text_generate_model\n",
        "        self.main_pipe = main_pipe\n",
        "        self.Recommended_setting = Recommended_setting\n",
        "\n",
        "        self.good_word = \"masterpiece:2.0,best quality,high quality,\"\n",
        "\n",
        "        self.SP_word_dict = {\"<color>\":[\"Red\",\"Blue\",\"green\",\"yellow\",\"orange\",\"purple\",\"pink\",\"brown\",\"gray\",\"black\",\"white\",]\n",
        "                             }\n",
        "\n",
        "\n",
        "    def txt_pipe(self,text_generate_model):\n",
        "        global gl_txt_pipe\n",
        "\n",
        "        txt_pipe_dict={\"MagicPrompt-Stable-Diffusion\":\"Gustavosta/MagicPrompt-Stable-Diffusion\",\n",
        "                       \"anime-anything-promptgen-v2\":\"FredZhang7/anime-anything-promptgen-v2\",\n",
        "                       \"gpt2-prompt-generator\":\"Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator\",\n",
        "                       \"None\":\"None\"}\n",
        "\n",
        "\n",
        "        assert text_generate_model in txt_pipe_dict , f\"text_generate_model: {text_generate_model}\"\n",
        "\n",
        "        txt_model_name = txt_pipe_dict[text_generate_model]\n",
        "\n",
        "        try:\n",
        "            if txt_model_name != \"None\" and (not globals().get('gl_txt_pipe') or not self.key_check(txt_model_name)):\n",
        "                if self.use_TPU:\n",
        "                    txt_model = FlaxAutoModelForCausalLM.from_pretrained(txt_model_name)\n",
        "                else:\n",
        "                    txt_model = AutoModelForCausalLM.from_pretrained(txt_model_name).to(self.device)\n",
        "                txt_tokenizer = AutoTokenizer.from_pretrained(txt_model_name)\n",
        "                gl_txt_pipe = pipeline('text-generation', model=txt_model, tokenizer=txt_tokenizer, device=self.device, pad_token_id=50256)\n",
        "            elif \"gl_txt_pipe\" in globals():\n",
        "                gl_txt_pipe = globals()[\"gl_txt_pipe\"]\n",
        "            else:\n",
        "                gl_txt_pipe = None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in setting up txt_pipe: {e}\")\n",
        "            raise e\n",
        "\n",
        "        return gl_txt_pipe\n",
        "\n",
        "\n",
        "    def sp_word_replace(self,base_prompt):\n",
        "        for sp_key, sp_value in self.SP_word_dict.items():\n",
        "            for co in base_prompt:\n",
        "                if isinstance(sp_value, list):\n",
        "                    sp_value = random.choice(sp_value)\n",
        "                base_prompt = re.sub(sp_key, sp_value, base_prompt, count=1)\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "\n",
        "    def convert_special_word(self,base_prompt):\n",
        "        base_prompt = self.sp_word_replace(base_prompt)\n",
        "        contents = re.findall(\"\\\\{(.*?)\\\\}\", base_prompt)\n",
        "        for count, content in enumerate(contents):\n",
        "            if not content:\n",
        "                continue\n",
        "            lst = content.split(\",\")\n",
        "            choice = random.choice(lst)\n",
        "            base_prompt = re.sub(\"\\\\{.*?\\\\}\", choice, base_prompt, count=1)\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "\n",
        "    def prompt_pipe_convert(self,prompt):\n",
        "        n_word=[\"EasyNegative\",\"bat_hands\",\"white background\",\" simple background\",\"logo\",\"text\",\"Loss of eye highlights\",\"freckles\",\"simple background\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"bad hands\",\"bad legs\",\"worst quality\",\"low quality\",\"Not five fingers\",\"blurred\",\"Missing finger\",\"Simple background\",\"Cat with deformed face\",\"medium quality\",\"purple hair\",\"Loss of eye highlights\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"deleted\",\"lowres\",\"Low quality animals\",\"deformed animals\",\"hands emerging from impossible places\",\"bad anatomy\",\"more than three limbs hands/legs\",\"low resolution\",\"blurry\",\"absurdres\",\"pixelated\",\"sketchy\",\"nonsensical anatomy\",\"unrealistic pose\",\"mosaic\",\"unclear details\",\"distorted colors\",\"unrealistic proportions\",\"poor quality\",\"fuzzy\",\"missing head:1.6\",\"out of focus\",\"hazy\",\"grainy\",\"text\",\"error\",\"missing fingers:0.9\",\"extra digit\",\"fewer digits\",\"cropped\",\"jpeg artifacts\",\"signature\",\"watermark\",\"username\",\"standard quality\",\"bad feet_hand_finger_leg_eye\",\"bad\",\"text font ui\",\"bad shadow\",\"poorly drawn\",\"black-white\",\"ugly\",\"duplicate\",\"mutation\",\"mutilated\",\"malformed mutated:1.1\",\"malformed:1.1\",\"The background is incoherent\",\"simple background\",\"low-quality background\",\"low background\",\"bad body\",\"long body\",\"broken limb\",\"anatomical nonsense\",\"extra limbs\",\"missing limb\",\"incorrect limb\",\"multiple heads\",\"twisted head\",\"poorly drawn face\",\"1 unit with multiple heads:1.3\",\"heads together:1.0\",\"abnormal eye:1.2 proportion\",\"cropped:1.0\",\"bad eyes\",\"fused eyes\",\"poorly drawn eyes\",\"bad mouth\",\"poorly drawn mouth\",\"bad tongue\",\"too long tongue\",\"bad ears\",\"poorly drawn ears\",\"extra ears\",\"heavy ears\",\"long neck\",\"too thick neck\",\"bad neck\",\"bad breasts\",\"missing arms\",\"disappearing arms\",\"extra arms\",\"three arms:2.0\",\"mutated hands and fingers\",\"fused hand\",\"missing fingers\",\"extra digits\",\"huge thighs\",\"disappearing thigh\",\"missing thighs\",\"extra thighs\",\"bad feet\",\"huge calf\",\"disappearing legs\",\"bad gloves\",\"fused gloves\",\"beard\",\"artist name\",\"text watermark\",\"unnatural\",\"obviously wrong\",\"distorted face\",\"floating hair\",\"floating body parts\",\"severed body parts\",\"incorrect leg position\",\"deformed\",\"fused body and hands\",\"disregard of physics\",\"distorted shape\",\"doll-like object not present in the image\",\"body fusion\",\"abnormal fingers\",\"fingers resembling fish fins\",\"dot eyes\",\"unclear background\",\"mosaic\",\"body bending\",\"incorrect leg-to-torso ratio\",\"excessively large breasts\",\"unsettling appearance\",\"eyes filled with solid color\",\"lack of lower body\",\"splitting\",\"creepy doll-like appearance\",\"distorted eyes\",\"lines on the skin\",\"legs bending in unnatural directions\",\"abnormal finger count\",\"missing arms\",\"floating hands\",\"lack of nose or mouth\",\"incorrect body part ratios\",\"bad\",\"longbody\",\"lowres\",\"bad anatomy\",\"bad hands\",\"missing fingers\",\"Distorted eye contour\",\"Missing part from the ankles onward\",\"extra digit\",\"fewer digits\",\"split wings\",\"Vampire wings floating in the air\",\"bad wing\",\"wonder egg priority\",\"egg priority\",\"demon\"]\n",
        "        if self.n_prompt:\n",
        "            words =self.n_prompt.split(\",\")\n",
        "            n_word.extend(words)\n",
        "        if self.Recommended_setting:\n",
        "            max_length=64\n",
        "        else:\n",
        "            max_length=74\n",
        "\n",
        "        gl_txt_pipeline = self.txt_pipe(self.text_generate_model)\n",
        "\n",
        "        converted_prompt = gl_txt_pipeline(prompt,\n",
        "                                           max_length=max_length,\n",
        "                                           truncation=True,\n",
        "                                           num_return_sequences=10,\n",
        "                                           repetition_penalty=1.2,\n",
        "                                           early_stopping=False,\n",
        "                                           do_sample=True,\n",
        "                                           temperature=0.4,\n",
        "                                           top_k=10)\n",
        "\n",
        "        converted_prompt = converted_prompt[0]['generated_text']\n",
        "        return converted_prompt\n",
        "\n",
        "\n",
        "    def prompt_converting(self,base_prompt):\n",
        "        sp_word_converted = self.convert_special_word(base_prompt)\n",
        "\n",
        "        if not self.text_generate_model == \"None\":\n",
        "            sp_word_converted = self.prompt_pipe_convert(sp_word_converted)\n",
        "\n",
        "        return_prompt = re.sub(r\",+\", \",\", sp_word_converted)\n",
        "        return return_prompt\n",
        "\n",
        "\n",
        "    def Flax_prompt(self,prompt):\n",
        "        #print(prompt)\n",
        "        num_samples = jax.device_count()\n",
        "        prompt = num_samples * [prompt]\n",
        "        prompt_ids = self.main_pipe.prepare_inputs(prompt)\n",
        "        prompt_ids = shard(prompt_ids)\n",
        "        return prompt_ids\n",
        "\n",
        "\n",
        "    def prompt_processing(self,base_prompt,output_list):\n",
        "        if self.pipeline_type == \"txt2video\":\n",
        "            logger.debug(\"set num_imgs = 1\")\n",
        "            self.num_imgs = 1\n",
        "\n",
        "        for number in range(self.num_imgs):\n",
        "            converted_prompt = self.prompt_converting(base_prompt)\n",
        "\n",
        "\n",
        "            if self.use_TPU:\n",
        "                converted_prompt = self.Flax_prompt(converted_prompt)\n",
        "            #elif self.Recommended_setting:\n",
        "            #    converted_prompt = self.good_word + converted_prompt\n",
        "            output_list.put(converted_prompt)\n",
        "\n",
        "\n",
        "    def use_over_token(self,PROMPT,pipe):\n",
        "        max_length = pipe.tokenizer.model_max_length\n",
        "        input_ids = pipe.tokenizer(PROMPT, return_tensors=\"pt\").input_ids\n",
        "        input_ids = input_ids.to(\"cuda\")\n",
        "\n",
        "        negative_ids = pipe.tokenizer(\"\", truncation=False, padding=\"max_length\", max_length=input_ids.shape[-1], return_tensors=\"pt\").input_ids\n",
        "        negative_ids = negative_ids.to(\"cuda\")\n",
        "\n",
        "        concat_embeds = []\n",
        "        neg_embeds = []\n",
        "        for i in range(0, input_ids.shape[-1], max_length):\n",
        "            concat_embeds.append(pipe.text_encoder(input_ids[:, i: i + max_length])[0])\n",
        "            neg_embeds.append(pipe.text_encoder(negative_ids[:, i: i + max_length])[0])\n",
        "\n",
        "        #prompt_embeds = torch.cat(concat_embeds, dim=1)\n",
        "        negative_prompt_embeds = torch.cat(neg_embeds, dim=1)\n",
        "        return negative_prompt_embeds\n",
        "\n",
        "\n",
        "\n",
        "class generate_config(basic_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.png_num = 0\n",
        "        self.mp_num = 0\n",
        "\n",
        "\n",
        "    def find_max_num(self,\n",
        "                     base_file_name,\n",
        "                     directory,\n",
        "                     ext):\n",
        "        max_num = 0\n",
        "        pattern = re.compile(f\"{base_file_name}-(\\\\d+)\\\\.{ext}\")\n",
        "        for filename in os.listdir(directory):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            if os.path.isfile(filepath):\n",
        "                match = pattern.match(filename)\n",
        "                if match:\n",
        "                    z = int(match.group(1))\n",
        "                    max_num = max(max_num, z)\n",
        "        return max_num\n",
        "\n",
        "\n",
        "    def image_grid(self,\n",
        "                   imgs :list,\n",
        "                   cols : int):\n",
        "        \"\"\"\n",
        "        cols: width\n",
        "        \"\"\"\n",
        "        all_num=len(imgs)\n",
        "        if all_num<cols:\n",
        "            cols=all_num\n",
        "        if all_num>1:\n",
        "            am=0\n",
        "            w, h = imgs[0].size\n",
        "            rows,b= divmod(all_num,cols)\n",
        "            if b!=0:\n",
        "                rows+=1\n",
        "                am=cols-b\n",
        "                white_img = Image.new(\"RGB\", (w,h), (255, 255, 255))\n",
        "                for x in range(am):\n",
        "                    imgs.append(white_img)\n",
        "            grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "            grid_w, grid_h = grid.size\n",
        "            for i, img in enumerate(imgs):\n",
        "                grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "        elif all_num==1:\n",
        "            grid=None\n",
        "            if self.make_grid:\n",
        "                print(\"Unable to create a grid image due to a single image\")\n",
        "        else:\n",
        "            grid=None\n",
        "            if self.make_grid:\n",
        "                print(\"There are no images available for the grid image\")\n",
        "        return grid\n",
        "\n",
        "\n",
        "    def get_save_path(self,\n",
        "                      saved_path,\n",
        "                      result_type=\"image\"):\n",
        "        \"\"\"\n",
        "        args:\n",
        "        result_type = [image,video,music]\n",
        "        \"\"\"\n",
        "        dir_type = {\"image\":\"Images\",\n",
        "                    \"video\":\"Video\",\n",
        "                    \"music\":\"Music\",}\n",
        "        make_dir_name = dir_type[result_type]\n",
        "\n",
        "        if not saved_path:\n",
        "            saved_path = \"/content/Generated\"\n",
        "            if not self.Hide_warnings:\n",
        "                print(f\"The directory to save to has not been entered yet, so save to the following path: {saved_path}\")\n",
        "        elif not self.conect_gdrive:\n",
        "            if \"/content/drive/MyDrive\" in saved_path:\n",
        "                saved_path = \"/content/Generated\"\n",
        "                if not self.Hide_warnings:\n",
        "                    print(f\"\\033[31mSince Google Drive is not mounted, save to the following path: {saved_path}\\033[0m\")\n",
        "\n",
        "        image_save_dir = os.path.join(saved_path,make_dir_name)\n",
        "        os.makedirs(image_save_dir, exist_ok=True)\n",
        "        if result_type == \"image\":\n",
        "            Grid_save_dir = os.path.join(saved_path,\"Grid\")\n",
        "            os.makedirs(Grid_save_dir, exist_ok=True)\n",
        "            base_file_name =\"genrated_grid\"\n",
        "            grid_num = self.find_max_num(\n",
        "                              base_file_name = base_file_name,\n",
        "                              directory = Grid_save_dir,\n",
        "                              ext=\"png\"\n",
        "                              )\n",
        "            Grid_save_path = os.path.join(Grid_save_dir,f\"{base_file_name}-{grid_num+1}.png\")\n",
        "        else:\n",
        "            Grid_save_path= \"\"\n",
        "\n",
        "\n",
        "        return image_save_dir , Grid_save_path\n",
        "\n",
        "\n",
        "    def seed_set(self,seed_number):\n",
        "        Flax_seed=None\n",
        "        if seed_number==-1 or seed_number is None:\n",
        "            seed = random.randint(1,10**10)\n",
        "        else:\n",
        "            seed=seed_number\n",
        "        if self.use_TPU:\n",
        "            Flax_seed=jax.random.split(jax.random.PRNGKey(seed), jax.device_count())\n",
        "        else:\n",
        "            Flax_seed=None\n",
        "        return seed,Flax_seed\n",
        "\n",
        "\n",
        "    def img_set(self,path,height,width)->list:\n",
        "        #↓counter-measure: AttributeError: 'str' object has no attribute 'seek'\n",
        "        init_image_list=[]\n",
        "        def img_open(path,height,width):\n",
        "            _init_image = Image.open(path)\n",
        "            _init_image = _init_image.resize((height, width))\n",
        "            return _init_image\n",
        "\n",
        "        if os.path.isfile(path):\n",
        "            init_image = img_open(path,height,width)\n",
        "            init_image_list.append(init_image)\n",
        "        else:\n",
        "            _ext = [\".jpg\",\".png\"]\n",
        "            #files = glob.glob(f\"{path}/*\")\n",
        "            files = Path(path)\n",
        "            file_paths = [str(file_path) for file_path in files.iterdir() if file_path.is_file()]\n",
        "            for file_path in file_paths:\n",
        "                if file_path.endswith in _ext:\n",
        "                    init_image = img_open(path,height,width)\n",
        "                    init_image_list.append(init_image)\n",
        "        logger.debug(f\"init_image_list: {init_image_list}\")\n",
        "        if not init_image_list:\n",
        "            raise FileNotFoundError(\"No image\")\n",
        "        return init_image_list\n",
        "\n",
        "\n",
        "    def n_prompt_set(self,base_negative_prompt=\"\"):\n",
        "        add_n_prompt = \"Loss of eye :1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0,bad hands:2.0,bad legs:2.0,EasyNegative,bat_hands:1.3,worst quality:2.0, low quality:2.0,Fused fingers,7 fingers, 6 fingers, 4 fingers, 3 fingers,Not five fingers:2.0,blurred,Simple_background:2.0,Missing finger:1.7,Cat with deformed face:1.3 ,medium quality, purple hair,Loss of eye highlights:1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0 ,deleted:0.5, lowres,Low quality animals, deformed animals ,hands emerging from impossible places:1.7, bad anatomy, more than three limbs hands/legs:1.5, low resolution, blurry, absurdres,pixelated, sketchy, nonsensical anatomy, unrealistic pose, mosaic, unclear details, distorted colors, unrealistic proportions, poor quality, fuzzy, missing head:1.6, out of focus, hazy, grainy, text, error, missing fingers:0.9, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, standard quality, bad feet_hand_finger_leg_eye, bad, text font ui, bad shadow, poorly drawn, black-white, ugly, duplicate, mutation, mutilated, malformed mutated:1.1, malformed:1.1, The background is incoherent, simple background, low-quality background, low background, bad body, long body, broken limb, anatomical nonsense, extra limbs, missing limb, incorrect limb, multiple heads, twisted head, poorly drawn face, 1 unit with multiple heads:1.3, heads together:1.0, abnormal eye:1.2 proportion, cropped:1.0, bad eyes, fused eyes, poorly drawn eyes, bad mouth, poorly drawn mouth, bad tongue, too long tongue, bad ears, poorly drawn ears, extra ears, heavy ears, long neck, too thick neck, bad neck,  bad breasts, missing arms, disappearing arms, extra arms, three arms:2.0, mutated hands and fingers, fused hand, missing fingers, extra digits, huge thighs, disappearing thigh, missing thighs, extra thighs, bad feet, huge calf, disappearing legs, bad gloves, fused gloves, beard, artist name, text watermark, unnatural, obviously wrong, distorted face, floating hair, floating body parts, severed body parts, incorrect leg position, deformed, fused body and hands, disregard of physics, distorted shape, doll-like object not present in the image, body fusion, abnormal fingers, fingers resembling fish fins, dot eyes, unclear background, mosaic, body bending, incorrect leg-to-torso ratio, excessively large breasts, unsettling appearance, eyes filled with solid color, lack of lower body, splitting, creepy doll-like appearance, distorted eyes, lines on the skin, legs bending in unnatural directions, abnormal finger count, missing arms, floating hands, lack of nose or mouth,, incorrect body part ratios, bad, longbody, lowres, bad anatomy, bad hands, missing fingers,  Distorted eye contour, Missing part from the ankles onward, extra digit, fewer digits, split wings, Vampire wings floating in the air, bad wing, comic,chainsaw man,demon, simple background\"\n",
        "        if self.Recommended_setting:\n",
        "            #if base_negativev_prompt.endswith(\",\"):\n",
        "            base_negative_prompt = base_negative_prompt + add_n_prompt\n",
        "        elif not self.Hide_warnings:\n",
        "            print('\\033[33mself.Recommended_setting is off\\033[0m')\n",
        "\n",
        "        return re.sub(r\",+\", \",\", base_negative_prompt)\n",
        "\n",
        "\n",
        "\n",
        "    def play_mp4(self,path_new):\n",
        "        mp4 = open(path_new, 'rb').read()\n",
        "        data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "        HTML_code=(f\"\"\"\n",
        "                   <video width=\"70%\" height=\"70%\" controls>\n",
        "                         <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "                   </video>\"\"\")\n",
        "        try:\n",
        "            display(HTML(HTML_code))\n",
        "        except:\n",
        "            display(HTML('<script>{}</script>'.format(HTML_code)))\n",
        "\n",
        "\n",
        "\n",
        "class generate_class(make_main_pipe,\n",
        "                     txt_model_setup,\n",
        "                     generate_config):\n",
        "    def __init__(self,\n",
        "                 base_prompt,\n",
        "                 base_negative_prompt,\n",
        "                 base_seed,\n",
        "                 num_imgs,\n",
        "                 height,\n",
        "                 width,\n",
        "                 num_inference_steps,\n",
        "                 guidance_scale,\n",
        "                 grit_image_width,\n",
        "                 Recommended_setting,\n",
        "                 image_save_dir,\n",
        "                 save_file_name,\n",
        "                 input_img_dir_or_path,\n",
        "                 model_name,\n",
        "                 main_pipe,\n",
        "                 parmer,\n",
        "                 video_length,\n",
        "                 num_frames,\n",
        "                 video_fps ,\n",
        "                 show_result,\n",
        "                 Hide_warnings,\n",
        "                 extra_parameter_dict):\n",
        "\n",
        "        txt_model_setup.__init__(self,\n",
        "                                 base_prompt = base_prompt,\n",
        "                                 n_prompt = base_negative_prompt,\n",
        "                                 num_imgs = num_imgs,\n",
        "                                 text_generate_model = text_generate_model,\n",
        "                                 main_pipe = main_pipe,\n",
        "                                 Recommended_setting = Recommended_setting)\n",
        "\n",
        "        self.base_prompt = base_prompt\n",
        "        self.base_negative_prompt = base_negative_prompt\n",
        "        self.base_seed = base_seed\n",
        "        self.num_imgs = num_imgs\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.guidance_scale = guidance_scale\n",
        "        self.num_inference_steps = num_inference_steps\n",
        "        self.grit_image_width = grit_image_width\n",
        "        self.Recommended_setting = Recommended_setting\n",
        "        self.image_save_dir = image_save_dir\n",
        "        self.save_file_name = save_file_name\n",
        "        self.input_img_dir_or_path = input_img_dir_or_path\n",
        "        self.model_name = model_name\n",
        "        self.main_pipe = main_pipe\n",
        "        self.parmer = parmer\n",
        "        self.video_length = video_length\n",
        "        self.num_frames = num_frames\n",
        "        self.video_fps = video_fps\n",
        "        self.extra_parameter_dict = extra_parameter_dict\n",
        "\n",
        "        self.negative_prompt = self.n_prompt_set(base_negative_prompt)\n",
        "        self.pipeline_name = main_pipe.__class__.__name__\n",
        "        self.pipeline_class = self.pipeline_class_set(self.pipeline_name)\n",
        "        self.pipeline_type = self.pipe_class_type(self.pipeline_name)\n",
        "        self.pipeline_call_method = self.get_call_method(self.pipeline_name,\"__call__\")\n",
        "        if not self.use_TPU:\n",
        "            self.generator = torch.Generator(self.device)\n",
        "        else:\n",
        "            self.generator = None\n",
        "        self.stop_flag = threading.Event()\n",
        "        if self.grit_image_width == 0:\n",
        "            self.make_grid = False\n",
        "        else:\n",
        "            self.make_grid = True\n",
        "\n",
        "        self.pipeline_type = self.pipe_class_type(self.pipeline_name)\n",
        "        if self.pipeline_type == \"txt2video\":\n",
        "            self.make_video = True\n",
        "            self.num_imgs = 1\n",
        "            self.result_type = \"video\"\n",
        "        else:\n",
        "            self.make_video = False\n",
        "            self.result_type = \"image\"\n",
        "\n",
        "        self.prompt_list = queue.Queue()\n",
        "        self.make_images_list = queue.Queue()\n",
        "        self.total_generate_time = 0\n",
        "        self.base_generate_number = 1\n",
        "        self.generation_time_average = 0\n",
        "        self.pipeline_name = main_pipe.__class__.__name__\n",
        "        self.image_save_base_dir = \"\"\n",
        "        self.gird_save_base_dir = \"\"\n",
        "        self.gird_save_path = \"\"\n",
        "        self.prompt_process = None\n",
        "        self.generate_process = None\n",
        "        self.save_and_show_process = None\n",
        "        self.nsfw_detected = None\n",
        "        self.sp_output_module = None\n",
        "        self.grid_imgs=[]\n",
        "        self.call_dict={}\n",
        "\n",
        "        \"---module---\"\n",
        "        self.show_result = show_result\n",
        "        self.Hide_warnings = Hide_warnings\n",
        "\n",
        "    \"\"\"\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            self.prompt_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "        try:\n",
        "            self.generate_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "        try:\n",
        "            self.save_and_show_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def save_path_set(self,\n",
        "                      base_file_name,\n",
        "                      image_save_dir,\n",
        "                      is_images : bool,\n",
        "                      Prompt = \"\",\n",
        "                      seed = 0\n",
        "                      ):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        is_images:When true, returns the path to image generation\n",
        "                  when false, returns the path to video generation\n",
        "        Format:\n",
        "        <base_file_name>-<num>.png\n",
        "        \"\"\"\n",
        "        if base_file_name==\"\":\n",
        "            if is_images:\n",
        "                base_file_name = \"GIMG\"\n",
        "            else:\n",
        "                base_file_name = \"Gvideo\"\n",
        "\n",
        "        if is_images:\n",
        "            extension = \"png\"\n",
        "        else:\n",
        "            extension = \"mp4\"\n",
        "\n",
        "        now = datetime.datetime.now()\n",
        "        path_d = {\"{prompt}\": Prompt,\n",
        "                  \"{seed}\": seed,\n",
        "                  \"{model_name}\": self.model_name,\n",
        "                  \"{g_scale}\": self.guidance_scale,\n",
        "                  \"{time}\":now}\n",
        "        for key, value in path_d.items():\n",
        "            base_file_name = base_file_name.replace(key, str(value))\n",
        "        #NOTE: This function returns the maximum number, so the file will be overwritten if 1 is not added.\n",
        "        number = self.find_max_num(base_file_name,image_save_dir,extension)\n",
        "        return os.path.join(image_save_dir,f\"{base_file_name}-{number+1}.{extension}\")\n",
        "\n",
        "\n",
        "    def generate_images_or_video(self,\n",
        "                                 init_image = None):\n",
        "        seed, Flax_seed = self.seed_set(self.base_seed)\n",
        "        self.image_save_base_dir, self.gird_save_path= self.get_save_path(self.image_save_dir,self.result_type)\n",
        "        for g_number in range(1,self.num_imgs+1):\n",
        "\n",
        "                target_prompt = self.prompt_list.get()\n",
        "\n",
        "                if self.Recommended_setting:\n",
        "                    input_prompt = self.good_word + target_prompt\n",
        "                else:\n",
        "                    input_prompt = target_prompt\n",
        "\n",
        "                if self.base_seed == -1:\n",
        "                    seed,Flax_seed = self.seed_set(self.base_seed)\n",
        "\n",
        "                image_save_path = self.save_path_set(base_file_name =self.save_file_name,\n",
        "                                                     image_save_dir = self.image_save_base_dir,\n",
        "                                                     is_images = True if not self.make_video else False,\n",
        "                                                     Prompt = target_prompt,\n",
        "                                                     seed = seed)\n",
        "\n",
        "\n",
        "                save_file_name = os.path.basename(image_save_path)\n",
        "                now = datetime.datetime.now()\n",
        "                date_str = now.strftime(\"%Y-%m-%d_UTC-%H:%M:%S\")\n",
        "                generate_start_time = time.time()\n",
        "                if not self.use_TPU:\n",
        "                    self.generator.manual_seed(seed)\n",
        "                self.input_method_dict = {\n",
        "                    \"prompt\" : input_prompt,\n",
        "                    \"negative_prompt\" : self.negative_prompt,\n",
        "                    \"neg_prompt\" : self.negative_prompt,\n",
        "                    \"guidance_scale\" : self.guidance_scale,\n",
        "                    \"num_inference_steps\" : self.num_inference_steps,\n",
        "                    \"generator\" : self.generator,\n",
        "                    \"height\" : int(self.height),\n",
        "                    \"width\" : int(self.width),\n",
        "                    \"image\" : init_image,\n",
        "                    \"strength\" : 1,\n",
        "                    \"t0\" : self.num_inference_steps - 5,\n",
        "                    \"t1\" : self.num_inference_steps - 3,\n",
        "                    \"video_length\" : self.video_length,\n",
        "                    \"num_frames\":self.num_frames,\n",
        "                    \"prng_seed\" : Flax_seed,\n",
        "                    \"params\" : self.parmer,\n",
        "                    }\n",
        "                for method_name, input_method in self.input_method_dict.items():\n",
        "                    if method_name in self.pipeline_call_method:\n",
        "                        self.call_dict[method_name] = input_method\n",
        "\n",
        "                self.call_dict = self.extra_parameter_dict | self.call_dict\n",
        "\n",
        "                output = self.main_pipe(**self.call_dict)\n",
        "                output_element_names = self.get_class_elements(output)\n",
        "\n",
        "                if \"nsfw_content_detected\" in output_element_names:\n",
        "                    self.nsfw_detected = output.nsfw_content_detected\n",
        "                else:\n",
        "                    self.nsfw_detected = None\n",
        "\n",
        "                if \"images\" in output_element_names:\n",
        "                    if self.make_video:\n",
        "                        maked_result = output.images\n",
        "                    elif not self.use_TPU:\n",
        "                        maked_result = output.images[0]\n",
        "                    else:\n",
        "                        maked_result = self.main_pipe.numpy_to_pil(np.asarray(output.images.reshape((self.device_count,) + output.images.shape[-3:])))\n",
        "                elif \"frames\" in output_element_names:\n",
        "                    if self.make_video:\n",
        "                        maked_result = output.frames\n",
        "                    else:\n",
        "                        maked_result = output.frames[0]\n",
        "                else:\n",
        "                    maked_result = getattr(output, output_element_names[0])\n",
        "\n",
        "                if self.nsfw_detected is None:\n",
        "                    bloke=False\n",
        "                else:\n",
        "                    if False in self.nsfw_detected:\n",
        "                        bloke = False\n",
        "                    else:\n",
        "                        bloke = True\n",
        "\n",
        "                generate_end_time = time.time()\n",
        "                base_generate_time = generate_end_time - generate_start_time\n",
        "                generate_time = round(base_generate_time,2)\n",
        "                self.total_generate_time += generate_time\n",
        "                metadata = {\n",
        "                    \"seed\": seed,\n",
        "                    \"prompt\": input_prompt,\n",
        "                    \"G_scale\":guidance_scale,\n",
        "                    \"D_step\":self.num_inference_steps,\n",
        "                    \"model_path\":self.model_name,\n",
        "                    \"n_prompt\":self.negative_prompt,\n",
        "                    \"pipeline_name\":self.pipeline_name\n",
        "                    }\n",
        "                save_data = {\"base_prompt\": target_prompt,\n",
        "                             \"save_path\": image_save_path,\n",
        "                             \"file_name\": save_file_name,\n",
        "                             \"generate_time\" : generate_time,\n",
        "                             \"generate_number\" : self.base_generate_number,}\n",
        "\n",
        "                status_dict = {\"bloke\" : bloke,\n",
        "                               \"metadata\" : metadata,\n",
        "                               \"save_data\" : save_data}\n",
        "                self.make_images_list.put([maked_result,status_dict])\n",
        "                if not bloke and self.make_grid:\n",
        "                    self.grid_imgs.append(maked_result)\n",
        "\n",
        "                self.base_generate_number += 1\n",
        "\n",
        "\n",
        "    def save_and_show(self):\n",
        "        for T in range(self.num_imgs):\n",
        "            make_image, status_dict = self.make_images_list.get()\n",
        "            bloke = status_dict[\"bloke\"]\n",
        "            metadata = status_dict[\"metadata\"]\n",
        "            save_data = status_dict[\"save_data\"]\n",
        "            save_path = status_dict[\"save_data\"][\"save_path\"]\n",
        "            file_name = status_dict[\"save_data\"][\"file_name\"]\n",
        "\n",
        "            if not self.make_video:\n",
        "                if not bloke:\n",
        "                    pnginfo = PngImagePlugin.PngInfo()\n",
        "                    info = make_image.info\n",
        "                    for key, value in metadata.items():\n",
        "                        pnginfo.add_text(key, str(value))\n",
        "                    make_image.save(save_path,pnginfo = pnginfo,quality=95)\n",
        "\n",
        "                    print(f'\\033[34mImage generation is complete ({save_data[\"generate_number\"]}/{self.num_imgs})  {save_data[\"generate_time\"]}s')\n",
        "                    print(f'seed:\\033[38;2;0;255;255m {metadata[\"seed\"]}\\033[34m')\n",
        "                    print(f'File_name: \\033[32m{file_name}\\033[0m')\n",
        "                    run_html_js(save_path,\"Save_path: \")\n",
        "                    if self.show_result:\n",
        "                        print()\n",
        "                        #To display including metadata\n",
        "                        with Image.open(save_path) as show_img:\n",
        "                            display(show_img)\n",
        "                    print(f'\\033[92mbase_prompt: {save_data[\"base_prompt\"]}\\033[0m')\n",
        "                else:\n",
        "                    print(\"Blocked\\n\")\n",
        "\n",
        "            else:\n",
        "                logger.debug(f\"num make_image: {len(make_image)} 1の場合、output.images[0]になっていないか確認。output.imagesが正解\")\n",
        "                from diffusers.utils import export_to_video\n",
        "                export_to_video(make_image, save_path, fps = self.video_fps)\n",
        "                print(f'\\033[34mVideo_generation_is_complete ({save_data[\"generate_number\"]}/{self.num_imgs})  {save_data[\"generate_time\"]}s')\n",
        "                print(f'seed:\\033[38;2;0;255;255m {metadata[\"seed\"]}\\033[34m')\n",
        "                print(f'File name: \\033[32m{file_name}\\033[0m')\n",
        "                run_html_js(save_path,\"Save_path: \")\n",
        "                if self.show_result:\n",
        "                    self.play_mp4(save_path)\n",
        "                    print(f'\\033[92mbase_prompt: {save_data[\"base_prompt\"]}\\033[0m')\n",
        "\n",
        "\n",
        "    def grid_task(self):\n",
        "        if num_imgs>1 and self.gird_save_path:\n",
        "            grid = self.image_grid(imgs = self.grid_imgs,\n",
        "                                   cols = self.grit_image_width)\n",
        "            if grid is not None:\n",
        "                grid.save(self.gird_save_path)\n",
        "                if self.show_result:\n",
        "                    with Image.open(self.gird_save_path) as grid_img:\n",
        "                        run_html_js(self.gird_save_path,\"Grid_Image_Path: \")\n",
        "                        display(grid_img)\n",
        "\n",
        "\n",
        "    def generate(self):\n",
        "        if (not self.make_video) and self.pipeline_type == \"img2img\":\n",
        "            #img2img\n",
        "            self.init_images_list = self.img_set(\n",
        "                self.input_img_dir_or_path,\n",
        "                self.height,\n",
        "                self.width)\n",
        "\n",
        "            if len(self.init_images_list)>1:\n",
        "                total_num = self.num_imgs * len(self.init_images_list)\n",
        "                print(f\"Since multiple images were passed, generate {self.num_imgs} images per image, for a total of {total_num} images\")\n",
        "            for init_image in self.init_images_list:\n",
        "                self.generate_images_or_video(init_image = init_image)\n",
        "        else:\n",
        "            self.generate_images_or_video(init_image = None)\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        self.prompt_process = threading.Thread(target=self.prompt_processing, args=(self.base_prompt,self.prompt_list),daemon=True)\n",
        "        self.generate_process = threading.Thread(target=self.generate)\n",
        "        self.save_and_show_process = threading.Thread(target=self.save_and_show)\n",
        "        self.prompt_process.start()\n",
        "        self.generate_process.start()\n",
        "        self.save_and_show_process.start()\n",
        "        self.save_and_show_process.join()\n",
        "        self.generation_time_average = \"{:.2f}\".format(self.total_generate_time/self.base_generate_number)\n",
        "        if not self.make_video:\n",
        "            self.grid_task()\n",
        "        print(f\"\\033[38;2;135;206;235mGeneration time average: {self.generation_time_average}s\\033[0m\")\n",
        "\n",
        "\n",
        "    def debugs(self):\n",
        "        self.prompt_processing(self.base_prompt,self.prompt_list)\n",
        "        self.generate()\n",
        "        self.save_and_show()\n",
        "\n",
        "\n",
        "generate_cls = generate_class(base_prompt = prompt,\n",
        "                              base_negative_prompt = negative_prompt,\n",
        "                              base_seed = seed,\n",
        "                              num_imgs = num_imgs,\n",
        "                              height = height,\n",
        "                              width = width,\n",
        "                              num_inference_steps = num_inference_steps,\n",
        "                              guidance_scale = guidance_scale,\n",
        "                              grit_image_width = grit_image_width,\n",
        "                              Recommended_setting = Recommended_setting,\n",
        "                              image_save_dir = save_dir,\n",
        "                              save_file_name = file_name,\n",
        "                              input_img_dir_or_path = input_image_path_or_dir,\n",
        "                              model_name = model_path,\n",
        "                              main_pipe = main_pipe,\n",
        "                              parmer = parmer,\n",
        "                              video_length = video_length,\n",
        "                              num_frames = num_frames,\n",
        "                              video_fps = video_fps,\n",
        "                              show_result = show_result,\n",
        "                              Hide_warnings = Hide_warnings,\n",
        "                              extra_parameter_dict = parameter_dict)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    generate_cls.run()\n",
        "    #generate_cls.debugs()\n",
        "\n",
        "    if not device_type == \"TPU\":\n",
        "        gc.collect()\n",
        "    if device_type == \"cuda\":\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sub-function"
      ],
      "metadata": {
        "id": "dsaW54HqI_-p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIEW0jvHK7I1"
      },
      "source": [
        "##Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ5y7hyEiCpa"
      },
      "outputs": [],
      "source": [
        "#@title Memory initialization {display-mode: \"form\"}\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "variable_names = [\"base_pipe\",\"txt2img_pipe\",\"img2img_pipe\",\"txt2video_pipe\",\"Inpaint_pipe\",\"safe_pipe\", \"tokenizer\"]\n",
        "\n",
        "for name in variable_names:\n",
        "    if name in globals():\n",
        "        del globals()[name]\n",
        "    if name in locals():\n",
        "        del locals()[name]\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hok9JfsGeQW"
      },
      "outputs": [],
      "source": [
        "#@title View Image Metadata  {display-mode: \"form\"}\n",
        "import os\n",
        "from PIL import Image, PngImagePlugin\n",
        "\n",
        "image_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "def show_png_info(image_path):\n",
        "    try:\n",
        "        output_info = Image.open(image_path).info\n",
        "    except Exception as err:\n",
        "        if not image_path:\n",
        "            print(\"\\33[31mPlease enter the image path\\33[0m\")\n",
        "            return\n",
        "        elif isinstance(err, FileNotFoundError):\n",
        "            print(\"\\33[31mThe specified image file cannot be found\\33[0m\")\n",
        "            return\n",
        "        else:\n",
        "            raise (\"An error occurred while opening the image file.\") from err\n",
        "\n",
        "    if not output_info:\n",
        "        print(\"\\33[31mMetadata not found\\33[0m\")\n",
        "    for key,info in output_info.items():\n",
        "        print(f\"\\33[32m{key} : {info}\\33[0m\\n\")\n",
        "\n",
        "show_png_info(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOtCwKbZpm-q"
      },
      "outputs": [],
      "source": [
        "#@title Unzip 7zip{display-mode: \"form\"}\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "\n",
        "try:\n",
        "    subprocess.run(['7z'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "except FileNotFoundError:\n",
        "    !apt-get install -y p7zip-full\n",
        "\n",
        "\n",
        "path = \"\"  # @param {type:\"string\"}\n",
        "if not path:\n",
        "    path = \"/content/Generated-No.1.7z\"\n",
        "\n",
        "if os.path.isfile(path) and path.endswith('.7z'):\n",
        "    try:\n",
        "        extract_path = path.replace('.7z', '')\n",
        "        os.makedirs(extract_path, exist_ok=True)\n",
        "        subprocess.run(['7z', 'x', path, f'-o{extract_path}'], check=True)\n",
        "        print(f'\\033[34mSuccessfully extracted to {extract_path} \\033[0m')\n",
        "    except Exception as e:\n",
        "        print(f\"\\033[31mExtraction failed. {e}\\033[0m\")\n",
        "else:\n",
        "    print(\"\\033[31mThe specified file is not a valid .7z file or it does not exist.\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH5cPNi297Lr"
      },
      "outputs": [],
      "source": [
        "#@title  download{display-mode: \"form\"}\n",
        "#@markdown >Specify file or directory to download.\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "path = \"/content/Generated-No.3\"  # @param {type:\"string\"}\n",
        "if not path:\n",
        "    path = \"/content/Generated\"\n",
        "\n",
        "if os.path.isfile(path):\n",
        "    try:\n",
        "        files.download(path)\n",
        "    except:\n",
        "        print(\"\\033[31mThe specified file could not be found.\\033[0m\")\n",
        "    else:\n",
        "        print(\"\\33[32mSuccessfully downloaded\\33[0m\")\n",
        "elif os.path.isdir(path):\n",
        "    for zip_number in range(1, 100000):\n",
        "        zip_name = f\"Generated-No.{zip_number}.zip\"\n",
        "        zip_path = os.path.join(\"/content\", zip_name)\n",
        "        if not os.path.isfile(zip_path):\n",
        "            break\n",
        "    try:\n",
        "        shutil.make_archive(zip_path.replace('.zip', ''), 'zip', path)\n",
        "        files.download(zip_path)\n",
        "\n",
        "        print(f'\\033[34mZip file name is {os.path.basename(zip_path)} \\033[0m')\n",
        "    except Exception as e:\n",
        "        print(f\"\\033[31mDownload failed.{e}\\033[0m\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i6YlYLKMSU6K"
      },
      "outputs": [],
      "source": [
        "#@title txt2audio\n",
        "prompt = \"Techno-style  music\" #@param {type:\"string\"}\n",
        "negative_prompt = \"Low quality.\" #@param {type:\"string\"}\n",
        "audio_length_in_s = 30 #@param {type:\"number\"}\n",
        "num_inference_steps = 500 #@param {type:\"number\"}\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "\n",
        "prompt+=\",masterpiece\"\n",
        "import os\n",
        "import scipy\n",
        "import torch\n",
        "from diffusers import AudioLDM2Pipeline\n",
        "from IPython.display import Audio\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "repo_id = \"cvssp/audioldm2\"\n",
        "if \"pipe\" not in locals() and \"pipe\" not in globals():\n",
        "    pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "if \"numa\" in globals():\n",
        "    numa+=1\n",
        "else:\n",
        "    numa=1\n",
        "if seed is None or seed==-1:\n",
        "    seed = random.randint(1,1000000)\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "audio = pipe(prompt,\n",
        "             negative_prompt=negative_prompt,\n",
        "             num_inference_steps=num_inference_steps,\n",
        "             audio_length_in_s=audio_length_in_s,\n",
        "             num_waveforms_per_prompt=1,\n",
        "             generator=generator,\n",
        "             ).audios\n",
        "\n",
        "\n",
        "os.makedirs(\"/content/audio\",exist_ok=True)\n",
        "save_path=f\"/content/audio/audio_{numa}_{seed}.wav\"\n",
        "\n",
        "\n",
        "scipy.io.wavfile.write(save_path, rate=16000, data=audio[0])\n",
        "print(f\"\\033[38;2;0;255;255mseed: {seed}\")\n",
        "print(f\"save_path: {save_path}\\n\\033[0m\")\n",
        "Audio(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRB6MLjGbrof"
      },
      "outputs": [],
      "source": [
        "#@title Youtube_download {display-mode: \"form\"}\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    import pytube\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q pytube\n",
        "\n",
        "from pytube import (Playlist, YouTube)\n",
        "from requests import HTTPError\n",
        "Youtube_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "Download_to_local = False # @param {type:\"boolean\"}\n",
        "\n",
        "def Youtube_download(Youtube_path,local_download):\n",
        "    Not_download_list=[]\n",
        "    mkdir_list=[\"/content/Youtube/File\",\"/content/Youtube/List\"]\n",
        "    for mk_path in mkdir_list:\n",
        "        os.makedirs(mk_path, exist_ok=True)\n",
        "    os.chdir(\"/content/Youtube\")\n",
        "    if Youtube_path:\n",
        "        if Youtube_path.startswith(\"https://www.youtube.com/playlist?list=\"):\n",
        "            try:\n",
        "                nu+=1\n",
        "            except:\n",
        "                nu=1\n",
        "            list_path=f\"/content/Youtube/Yotube_list_{nu}\"\n",
        "            os.makedirs(list_path,exist_ok=True)\n",
        "            os.chdir(list_path)\n",
        "            Y_list = Playlist(Youtube_path)\n",
        "            for video, path in zip(Y_list.videos, Y_list.video_urls[:3]):\n",
        "                try:\n",
        "                    video.streams.first().download()\n",
        "                except:\n",
        "                    Not_download_list.append(path)\n",
        "            if Not_download_list:\n",
        "                print(\"Failed download path\")\n",
        "                for ndl in Not_download_list:\n",
        "                    print(ndl)\n",
        "            if local_download:\n",
        "                zip_path=f\"/content/Youtube/zip-No_{zip_number}.zip\"\n",
        "                shutil.make_archive(zip_path, \"zip\", list_path)\n",
        "                files.download(zip_path)\n",
        "\n",
        "        elif Youtube_path.startswith(\"https://www.youtube.com/watch?v=\"):\n",
        "            os.chdir(\"/content/Youtube/File\")\n",
        "            try:\n",
        "                yt=YouTube(Youtube_path)\n",
        "                yt.streams.first().download()\n",
        "                yt_save_path=os.path.join(\"/content/Youtube/File\" , (yt.title+\".mp4\"))\n",
        "            except:\n",
        "                raise HTTPError(\"Invalid URL\")\n",
        "            if local_download:\n",
        "                try:\n",
        "                    files.download(yt_save_path)\n",
        "                except FileNotFoundError:\n",
        "                    print(f\"File download failed\")\n",
        "\n",
        "        else:\n",
        "            raise HTTPError(\"Invalid URL\")\n",
        "    else:\n",
        "        raise HTTPError(\"Please enter the URL\")\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "    print(\"The process has been completed.\")\n",
        "    print(f\"save_path: {os.path.basename(yt_save_path)}\")\n",
        "\n",
        "Youtube_download(Youtube_path,Download_to_local)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "#@title  Split Grid Image {display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "\n",
        "input_img_path = \"\" # @param {type:\"string\"}\n",
        "output_dir = \"\" # @param {type:\"string\"}\n",
        "Vertical_Image_Count = 2 # @param {type:\"number\"}\n",
        "Horizontal_Image_Count = 2 # @param {type:\"number\"}\n",
        "\n",
        "if (not input_img_path) or (not output_dir):\n",
        "    raise ValueError(\"Required path is missing\")\n",
        "\n",
        "if Vertical_Image_Count < 1 or Horizontal_Image_Count < 1:\n",
        "    raise ValueError(\"The number of installments must be greater than or equal to 1\")\n",
        "\n",
        "if os.path.isfile(output_dir):\n",
        "   output_dir = os.path.dirname(output_dir)\n",
        "\n",
        "\n",
        "def ImgSplit(\n",
        "        im,\n",
        "        width,\n",
        "        height,\n",
        "        Vertical_Image_Count,\n",
        "        Horizontal_Image_Count\n",
        "        ):\n",
        "    HEIGHT = height / Vertical_Image_Count\n",
        "    WIDTH = width / Horizontal_Image_Count\n",
        "    for h1 in range(Vertical_Image_Count):\n",
        "        for w1 in range(Horizontal_Image_Count):\n",
        "            w2 = w1 * WIDTH\n",
        "            h2 = h1 * HEIGHT\n",
        "            yield im.crop((w2, h2, WIDTH + w2, HEIGHT + h2))\n",
        "\n",
        "\n",
        "\n",
        "im = Image.open(input_img_path)\n",
        "w = im.size[0]\n",
        "h = im.size[1]\n",
        "length = math.log10(Vertical_Image_Count * Horizontal_Image_Count) + 1\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "for number, ig in enumerate(ImgSplit(im, w, h, Vertical_Image_Count, Horizontal_Image_Count), 1):\n",
        "    ig.save(output_dir + \"/\" + str(number).zfill(int(length)) + \".PNG\", \"PNG\")\n",
        "\n",
        "print(f\"\\033[34mSplit is complete: {os.path.abspath(output_dir)}\\033[0m\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ldFCpUIAg5Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3al9BGGP7DIR"
      },
      "outputs": [],
      "source": [
        "#@title  Move files containing the specified words {display-mode: \"form\"}\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_files_with_keyword(source_dir, destination_dir, keyword):\n",
        "    if not os.path.exists(destination_dir):\n",
        "        os.makedirs(destination_dir)\n",
        "\n",
        "    for root, dirs, files in os.walk(source_dir):\n",
        "        for _file in files:\n",
        "            if keyword in _file:\n",
        "                source_file = os.path.join(root, _file)\n",
        "                destination_file = os.path.join(destination_dir, _file)\n",
        "                shutil.move(source_file, destination_file)\n",
        "                print(f\"Moved: {source_file} -> {destination_file}\")\n",
        "\n",
        "\n",
        "search_directory = \"\"  # @param {type:\"string\"}\n",
        "destination_directory = \"\"  # @param {type:\"string\"}\n",
        "keyword_to_search = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "if not search_directory:\n",
        "    search_directory = \"/\"\n",
        "\n",
        "\n",
        "if not os.path.exists(destination_directory):\n",
        "    raise ValueError(f\"Destination directory does not exist: {destination_directory}\")\n",
        "\n",
        "\n",
        "move_files_with_keyword(search_directory, destination_directory, keyword_to_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuI2OK7YI2pE"
      },
      "outputs": [],
      "source": [
        "#@title Directory or File size Counter {display-mode: \"form\"}\n",
        "\n",
        "import os\n",
        "\n",
        "def get_folder_size(folder_path):\n",
        "    total_size = 0\n",
        "    if os.path.isfile(folder_path):\n",
        "        total_size = os.path.getsize(folder_path)\n",
        "    else:\n",
        "        for path, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(path, file)\n",
        "                total_size += os.path.getsize(file_path)\n",
        "\n",
        "    return total_size\n",
        "\n",
        "path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    raise FileNotFoundError(\"Invalid path\")\n",
        "\n",
        "size_in_bytes = get_folder_size(path)\n",
        "\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "size_in_gb = size_in_mb / 1024\n",
        "\n",
        "print(f\"Folder Size: {size_in_bytes:.2f} B\")\n",
        "print(f\"Folder Size: {size_in_kb:.2f} KB\")\n",
        "print(f\"Folder Size: {size_in_mb:.2f} MB\")\n",
        "print(f\"Folder Size: {size_in_gb:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change image format {display-mode: \"form\"}\n",
        "\n",
        "\"\"\"\n",
        "後で修正必要。\n",
        "83行ら辺を修正\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_path = \".\" #@param {type:\"string\"}\n",
        "output_dir=\"\" #@param {type:\"string\"}\n",
        "output_format = \"jpg\" # @param [\"png\", \"jpg\"]\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "class Image_Format_Converter:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        NOTE:\n",
        "        When there are a very large number of files,\n",
        "        the maximum value at that time is stored to lighten the processing as much as possible.\n",
        "\n",
        "        About exc_dict:\n",
        "            key : value = Target extension to format : (output file exc , Save format)\n",
        "        \"\"\"\n",
        "\n",
        "        self.max_exc_number = 0\n",
        "        self.exc_dict = {\".png\":(\".jpg\",\"JPEG\"),\n",
        "                         \".jpg\":(\".png\",\"PNG\")}\n",
        "\n",
        "\n",
        "    def file_name_set(self,path):\n",
        "        if os.path.isfile(path):\n",
        "            base_file_path, exc = os.path.splitext(path)\n",
        "            dir_path = os.path.dirname(base_file_path)\n",
        "            os.makedirs(dir_path,exist_ok=True)\n",
        "            sp_file_number = 1\n",
        "            while True:\n",
        "                _try_file_path = f\"{base_file_path}({sp_file_number}){exc}\"\n",
        "                if not os.path.isfile(_try_file_path):\n",
        "                    return _try_file_path\n",
        "                else:\n",
        "                    sp_file_number += 1\n",
        "        else:\n",
        "            return path\n",
        "\n",
        "\n",
        "    def dir_name_set(self,path):\n",
        "        if os.path.isdir(path):\n",
        "            dir_sp_number = 1\n",
        "            while True:\n",
        "                _try_dir_path = f\"{path}({dir_sp_number})\"\n",
        "                if not os.path.isdir(_try_dir_path):\n",
        "                    return _try_dir_path\n",
        "                else:\n",
        "                    dir_sp_number += 1\n",
        "        else:\n",
        "            return path\n",
        "\n",
        "\n",
        "    def image_format_converter(\n",
        "            self,\n",
        "            input_path,\n",
        "            output_path,\n",
        "            return_format\n",
        "            ):\n",
        "        \"\"\"\n",
        "        NOTE:\n",
        "        If output_path is not entered,\n",
        "        create a folder to store the images to be input in the directory where they are located.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(input_path):\n",
        "            print('\\033[31mPlease enter the directory or file path\\033[0m')\n",
        "            return\n",
        "\n",
        "        elif os.path.isdir(input_path):\n",
        "            if not output_path:\n",
        "                base_dir_name = os.path.dirname(input_path)\n",
        "                output_path = self.dir_name_set(base_dir_name)\n",
        "\n",
        "            for File_path in os.listdir(input_path):\n",
        "                if os.path.splis\n",
        "                #後でやる\n",
        "\n",
        "\n",
        "    def img_conver_func(\n",
        "            self,\n",
        "            input_path,\n",
        "            output_path,\n",
        "            return_format\n",
        "            ):\n",
        "        base_save_path, input_file_exc = os.path.splitext(File_path)\n",
        "        if input_file_exc in self.exc_dict:\n",
        "            target_save_exc, save_format = self.exc_dict[input_file_exc]\n",
        "            try:\n",
        "                target_image = Image.open(File_path)\n",
        "            except Exception as err:\n",
        "                if not isinstance(err, KeyboardInterrupt):\n",
        "                    print(f\"\\033[31mFailed to load image: {os.path.abspath(File_path)}\\033[0m\")\n",
        "                else:\n",
        "                    raise err\n",
        "            else:\n",
        "                save_file_path = self.file_name_set(f\"{base_save_path}{target_save_exc}\")\n",
        "                target_image.save(save_file_path, format=save_format)\n",
        "                print(f\"\\033[34mFormatted image path: {save_file_path}\\033[0m\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Img_Format_cls = Image_Format_Converter()\n",
        "    Img_Format_cls.image_format_converter(\n",
        "        input_path=input_path,\n",
        "        output_path=output_dir,\n",
        "        return_format=output_format)\n"
      ],
      "metadata": {
        "id": "svvD5rfHfPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyeuVK1DeJEv"
      },
      "outputs": [],
      "source": [
        "#@title Play mp4  {display-mode: \"form\"}\n",
        "\n",
        "Path_of_mp4_file = \"\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "class Show_video:\n",
        "    def play_mp4(self,path):\n",
        "        if os.path.isfile(path):\n",
        "            self.show_func(path)\n",
        "        elif os.path.isdir(path):\n",
        "            mp4_list = []\n",
        "            for mp4_path in os.listdir(path):\n",
        "                if os.path.splitext(mp4_path)[1] == \".mp4\":\n",
        "                    mp4_list.append(os.path.abspath(mp4_path))\n",
        "\n",
        "            if not mo4_list:\n",
        "                raise FileNotFoundError(\"No mp4 file exists in the specified directory\")\n",
        "            else:\n",
        "                for mp4_file_path in mp4_list:\n",
        "                    self.show_func(mp4_file_path)\n",
        "        else:\n",
        "            if not path:\n",
        "                raise ValueError(\"Please enter the path to the file or directory\")\n",
        "            else:\n",
        "                raise FileNotFoundError(\"Invalid path\")\n",
        "\n",
        "\n",
        "    def show_func(self,mp4_file):\n",
        "        mp4 = open(mp4_file, 'rb').read()\n",
        "        data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "        HTML(f\"\"\"\n",
        "        <video width=\"100%\" height=\"100%\" controls>\n",
        "              <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\")\n",
        "\n",
        "Show_video().play_mp4(Path_of_mp4_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT_pKvlmJXIq"
      },
      "outputs": [],
      "source": [
        "#@title  String token counter{display-mode: \"form\"}\n",
        "import pprint\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "prompt = \"\"  #@param {type:\"string\"}\n",
        "try:\n",
        "  tokens = tokenizer.tokenize(prompt)\n",
        "except:\n",
        "    text_model_id = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(text_model_id)\n",
        "    tokens = tokenizer.tokenize(prompt)\n",
        "print(len(tokens))\n",
        "pprint.pprint(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-5Gh7XWLwcr"
      },
      "outputs": [],
      "source": [
        "#@title Higher image quality{display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from diffusers import StableDiffusionUpscalePipeline\n",
        "import torch\n",
        "\n",
        "# load model and scheduler\n",
        "Prompt = \"\" #@param {type:\"string\"}\n",
        "prompt=\"masterpiece:2.0,best quality,high quality,\"+Prompt\n",
        "low_res_img_path = \"\" #@param {type:\"string\"}\n",
        "encoded_text = codecs.encode(low_res_img_path, 'utf-8')\n",
        "low_res_img_path = codecs.decode(encoded_text, 'utf-8')\n",
        "\n",
        "if \"pipeline2\" not in locals()  and \"pipeline2\" not in globals():\n",
        "  model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "  pipeline2 = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "    model_id, revision=\"fp16\", torch_dtype=torch.float16\n",
        "  )\n",
        "  pipeline2 = pipeline2.to(\"cuda\")\n",
        "if not os.path.exists(low_res_img_path):\n",
        "  raise FileNotFoundError(\"File not found\")\n",
        "try:\n",
        "  low_res_img = Image.open(low_res_img_path)\n",
        "except:\n",
        "  raise FileNotFoundError(\"Image could not be loaded.\")\n",
        "low_res_img = low_res_img.resize((128, 128))\n",
        "\n",
        "negative_prompt=\"low quality:2.0\"\n",
        "\n",
        "upscaled_image = pipeline2(prompt=prompt, image=low_res_img,negative_prompt=negative_prompt).images[0]\n",
        "\n",
        "try:\n",
        "  L+=1\n",
        "except:\n",
        "  L=1\n",
        "os.makedirs(\"/content/low_res_imgs\",exist_ok=True)\n",
        "path1=(f\"/content/low_res_imgs/No{L}.png\")\n",
        "upscaled_image.save(path1)\n",
        "print(f\"img save path: ({path1})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4kpwhy30ePA"
      },
      "outputs": [],
      "source": [
        "#@title Delete folder{display-mode: \"form\"}\n",
        "\n",
        "del_path = \"\" #@param {type:\"string\"}\n",
        "if del_path ==\"\":\n",
        "  del_path=\"/content/Generated\"\n",
        "import shutil\n",
        "if not os.path.isdir(del_path):\n",
        "  raise TypeError(\"Only directories can be deleted\")\n",
        "\n",
        "\n",
        "YorS=input(\"Are you sure you want to delete it? [yes/no]: \")\n",
        "if YorS.lower() in (\"yes\", \"y\"):\n",
        "    try:\n",
        "        shutil.rmtree(del_path)\n",
        "        print(\"Deleted.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\033[31mNot Found dir: {del_path}\\033[0m\")\n",
        "elif YorS.lower() in (\"no\", \"n\"):\n",
        "    print(\"Deletion of the folder has been aborted.\")\n",
        "else:\n",
        "    print(\"Please enter only yes/no.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t-Qqqp6la4WJ"
      },
      "outputs": [],
      "source": [
        "#@title url_Download\n",
        "import urllib.request , os\n",
        "import datetime\n",
        "def download_file(url, save_path):\n",
        "  other_url,split=os.path.splitext(url)\n",
        "  if save_path==\"\":\n",
        "    save_path=\"/content/download\"\n",
        "    choice_name=input(\"ファイル名(拡張子無し): \")\n",
        "    choice_name+=split\n",
        "    test_path=os.path.join(save_path,choice_name)\n",
        "    if os.path.exists(test_path):\n",
        "      now=datetime.now()\n",
        "      save_path=test_path+now\n",
        "  save_dir=os.path.dirname(save_path)\n",
        "  os.makedirs(save_dir,exist_ok=True)\n",
        "  if not url.endswith(split):\n",
        "    save_path+=split\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "  except HTTPError:\n",
        "    raise SystemError(\"URLからファイルを習得できませんでした\")\n",
        "  print(f\"保存先のパス: {save_path}\")\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "save_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1QPxPSzF_aP"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH1aO3M-zk5x"
      },
      "outputs": [],
      "source": [
        "#@title Training Lora {display-mode: \"form\"}\n",
        "\n",
        "instance_prompt = \"Cat ears girl\" # @param {type:\"string\"}\n",
        "\n",
        "max_train_steps = 20   # @param {type:\"number\"}\n",
        "\n",
        "input_img_dir = \"\" # @param {type:\"string\"}\n",
        "output_dir = \"/content/drive/MyDrive\" # @param {type:\"string\"}\n",
        "\n",
        "model_name_or_path = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "\n",
        "output_filename = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Disconnect_runtime_when_finished = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#driveに接続 = True # @param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "\n",
        "try:\n",
        "    import ftfy\n",
        "except:\n",
        "    !pip install ftfy -q\n",
        "    import ftfy\n",
        "    #!pip install -q accelerate>=0.16.0 transformers>=4.25.1 ftfy Jinja2 bitsandbytes\n",
        "  #import bitsandbytes,accelerate,transformers,ftfy\n",
        "#import accelerate,torchvision,transformers,ftfy ,diffusers,bitsandbytes\n",
        "\n",
        "size=512\n",
        "#if model_name_or_path==\"runwayml/stable-diffusion-v1-5\":\n",
        "#  size=512\n",
        "\n",
        "#Can not use export\n",
        "%env pretrained_model_name_or_path=$model_name_or_path\n",
        "%env train_data_dir=$input_img_dir\n",
        "\n",
        "%env resolution=$size\n",
        "%env output_dir=$output_dir\n",
        "%env max_train_steps = $max_train_steps\n",
        "\n",
        "\n",
        "%cd /content/script/diffusers/examples/textual_inversion\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path  \\\n",
        "  --instance_data_dir=$train_data_dir \\\n",
        "  --output_dir=$output_dir \\\n",
        "  --instance_prompt=$placeholder_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=1 \\\n",
        "  --learning_rate=1 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "\n",
        "base=os.path.join(output_dir,\"learned_embeds.safetensors\")\n",
        "if output_filename:\n",
        "    after_name = output_filename + \".safetensors\"\n",
        "    after = os.path.join(output_dir,after_name)\n",
        "\n",
        "else:\n",
        "  after=base\n",
        "\n",
        "print(f\"\\033[34mpath: {output_dir}\\033[0m\")\n",
        "\n",
        "if Disconnect_runtime_when_finished:\n",
        "  from google.colab import runtime\n",
        "  print(\"Disconnect runtime...\")\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-PpdeFgFjwa"
      },
      "outputs": [],
      "source": [
        "#@title Training textual inversion {display-mode: \"form\"}\n",
        "\n",
        "model_name_or_path = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "placeholder_token = \"\" # @param {type:\"string\"}\n",
        "initializer_token = \"\" # @param {type:\"string\"}\n",
        "max_train_steps = 50   # @param {type:\"number\"}\n",
        "\n",
        "input_imgs_dir = \"\" # @param {type:\"string\"}\n",
        "output_dir = \"/content/drive/MyDrive/textual\" # @param {type:\"string\"}\n",
        "input_imgs_dir = \"style\" # @param [\"style\",\"object\"]\n",
        "\n",
        "output_file_name = \"model\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Disconnect_runtime_when_finished = False # @param {type:\"boolean\"}\n",
        "\n",
        "conect_Gdrive = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if conect_Gdrive:\n",
        "  if not drive._os.path.ismount('/content/drive'):\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except:\n",
        "      drive_cn=False\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(output_dir,exist_ok=True)\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/content/script/diffusers\"):\n",
        "  %cd /content/script\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "\n",
        "\n",
        "if \"setup_txt\" not in locals():\n",
        "  %cd /content/script/diffusers/examples/textual_inversion\n",
        "  !pip install -r ./requirements.txt -q\n",
        "  setup_txt=True\n",
        "\n",
        "import accelerate,torchvision,transformers,ftfy ,diffusers\n",
        "\n",
        "\n",
        "%cd /content/diffusers/examples/textual_inversion\n",
        "\n",
        "size=512\n",
        "if model_name_or_path==\"runwayml/stable-diffusion-v1-5\":\n",
        "  size=512\n",
        "else:\n",
        "  size=768\n",
        "\n",
        "#Can not use export\n",
        "%env pretrained_model_name_or_path=$model_name_or_path\n",
        "%env train_data_dir=$input_imgs_dir\n",
        "%env learnable_property=$input_imgs_dir\n",
        "%env placeholder_token=$placeholder_tokenトークン\n",
        "%env initializer_token=$initializer_token\n",
        "%env resolution=$size\n",
        "%env max_train_steps=$max_train_steps\n",
        "%env output_dir=$output_dir\n",
        "\n",
        "#--learning_rate=5  \\\n",
        "#--mixed_precision=\"fp16\" \\\n",
        "#learning_rate is int type.\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path \\\n",
        "  --train_data_dir=$train_data_dir \\\n",
        "  --learnable_property=$learnable_property \\\n",
        "  --placeholder_token=$placeholder_token \\\n",
        "  --initializer_token=$initializer_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --learning_rate=5  \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$output_dir\n",
        "\n",
        "base=os.path.join(output_dir,\"learned_embeds.safetensors\")\n",
        "if output_file_name:\n",
        "    after_name=output_file_name+\".safetensors\"\n",
        "    after=os.path.join(output_dir,after_name)\n",
        "    if os.path.exists(base):\n",
        "        os.rename(base,after)\n",
        "    else:\n",
        "        print(\"Not Found model File\")\n",
        "else:\n",
        "    after=base\n",
        "\n",
        "print(f\"\\033[34mpath: {after}\\033[0m\")\n",
        "\n",
        "if Disconnect_runtime_when_finished:\n",
        "    from google.colab import runtime\n",
        "    print(\"Disconnect runtime...\")\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJteaxBCoPKM"
      },
      "source": [
        "##Description<a name = \"Description\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        ">**Important Functions**\n",
        "\n",
        "\n",
        "* auto<a name = \"auto_help\"></a>\n",
        "    * desc\n",
        "        * Minimize user input by automatically selecting the most highly rated models when searching for models.\n",
        "\n",
        "  * type\n",
        "      * bool\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "* model_select<a name = \"model_select_help\"></a>\n",
        "    * arg\n",
        "        1. url\n",
        "        2. hugface repository\n",
        "        3. Path where the model is\n",
        "        4. Keywords to search\n",
        "\n",
        "    * desc\n",
        "        1. url\n",
        "            * Download the model from the specified URL\n",
        "            * Given the URL of a hugface repository, it will search that repository.\n",
        "              * The same process as in 2. hugface repository is performed.\n",
        "\n",
        "        2. hugface repository\n",
        "            * Use hugface api to receive and select a model file from the repository.\n",
        "            * If there is a model (in the format of diffusers) that can be loaded \"from_pretrained\", add it to the candidates\n",
        "                * If auto is on, this is the preferred choice\n",
        "        \n",
        "        3. Path where the model is stored\n",
        "            * Processes to find files with the extensions safetensors, ckpt, and bin\n",
        "\n",
        "        4. Keywords to search\n",
        "            * After using the hugface api and selecting a repository, do the same process as in 2.\n",
        "\n",
        "            * If the user chooses to search outside of hugface, or if the file is not found in the repository, pass the keyword to the civitai api and process to search the model again.\n",
        "                * The following is how civitai selects models.\n",
        "                  1. Select Repository\n",
        "                  2. Select model version\n",
        "                  3. If more than one file exists in a given version, it processes the selection. If not, skip.\n",
        "                * In all processes, the candidates are sorted in order of popularity.\n",
        "                * In the case of auto, the indentation is 0, i.e., the one judged most popular is selected in all processes.\n",
        "\n",
        "    * type\n",
        "        * string\n",
        "\n",
        "\\\n",
        "\n",
        "* Pipeline class set<a name = \"Pipeline_class_set_help\"></a>\n",
        "    * arg\n",
        "        1. Select from drop-down menus\n",
        "        2. Specify the class of the pipeline for diffusers\n",
        "            * Example\n",
        "                1. StableDiffusionPipeline\n",
        "                2. DiffusionPipeline\n",
        "    \n",
        "    * desc\n",
        "        * The class that corresponds to the pull-down selection\\\n",
        "        ※ subject to change in due course\n",
        "        \n",
        "        1. torch(cpu or GPU)\n",
        "            * txt2img : AutoPipelineForText2Image\n",
        "            * img2img : AutoPipeleForImage2Image\n",
        "            * Inpaint : AutoPipelineForInpainting\n",
        "            * txt2video : TextToVideoZeroPipeline\n",
        "        \n",
        "        2. flax (TPU)\n",
        "            * txt2img : FlaxStableDiffusionPipeline\n",
        "            * img2img : FlaxStableDiffusionImg2ImgPipeline\n",
        "            * Inpaint : FlaxStableDiffusionInpaintPipeline\n",
        "            * txt2video : **None**\n",
        "              - The txt2video is **None** because it does not exist at the time of development.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "> (option)Load lora<a name = \"Load_lora_help\"></a>\n",
        "\n",
        "NOTE : Available after completion of step.3\n",
        "\n",
        "* model_name\n",
        "    * See model_select in Important Functions\n",
        "            \n",
        "    \n",
        "* auto\n",
        "    * See auto in Important Functions\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "> (option) load textual inversion<a name = \"load_textual inversion_help\"></a>\n",
        "\n",
        "NOTE : Available after completion of step.3\n",
        "\n",
        "* model_path\n",
        "    * See model_select in Important Functions\n",
        "\n",
        "    (However, models in diffusers format are ignored (because they cannot be loaded).)\n",
        "\n",
        "* token\n",
        "    * desc\n",
        "        * Specifies a token to invoke textual inversion.\n",
        "        * Duplicate token strings are not allowed. If you want to use it, please unload it.\n",
        "    * type\n",
        "        * string\n",
        "\n"
      ],
      "metadata": {
        "id": "RkzUWWTw1VWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Scheduler_select**<a name = \"Scheduler_select\"></a>\n",
        "* arg\n",
        "    * Specify the class of Scheduler\n",
        "    * Select from pull-down menus\n",
        "\n",
        "* desc\n",
        "    * [Additional settings](#Sonar_config) are available only for EulerA_with_sonar and Euler_with_sonar\n",
        "\n",
        "* The corresponding table is as follows.\n",
        "    * Scheduler\n",
        "        * DDPM : DDPMScheduler\n",
        "        * DDIM : DDIMScheduler\n",
        "        * PNDM : PNDMScheduler\n",
        "        * LMSD : LMSDiscreteScheduler\n",
        "        * DPM : DPMSolverMultistepScheduler\n",
        "        * EulerA : EulerAncestralDiscreteScheduler\n",
        "        * Euler : EulerDiscreteScheduler\n",
        "        * DEISM : DEISMultistepScheduler\n",
        "        * UniPCM : UniPCMultistepScheduler\n",
        "        * K_DPM2D : KDPM2DiscreteScheduler\n",
        "        * DPM_S : DPMSolverSinglestepScheduler\n",
        "        * K_DPM2AD : KDPM2AncestralDiscreteScheduler\n",
        "        * HeunD : HeunDiscreteScheduler\n",
        "            \n",
        "    * other_Scheduler\n",
        "        * Original Repository   \n",
        "            * [modified-euler-samplers-for-sonar-diffusers](https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git)\n",
        "    \n",
        "        * type\n",
        "            * Euler_with_sonar : EulerNew.py -> Euler\n",
        "            * EulerA_with_sonar : EulerANew.py -> EulerA"
      ],
      "metadata": {
        "id": "RXQvZMmAx1ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Vae set**<a name = \"Vae_set\"></a>\n",
        "\n",
        "* Basically, it is the same as [model Select](#model_select_help), but when searching for Civitai, change the type to VAE only in the condition."
      ],
      "metadata": {
        "id": "-CGY75ZUuWwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Parameters**\n",
        "\n",
        "* seed\n",
        "    * If seed is -1, put a random number of 1~10^10"
      ],
      "metadata": {
        "id": "UT2tvZGclkrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Prompt special tokens**<a name = \"Prompt_special_tokens_help\"></a>\n",
        "\n",
        "\n",
        ">Random Words\n",
        "\n",
        "* Description\n",
        " * Randomly select letters separated by { }\n",
        " * if you include spaces, you can choose to ignore words.\n",
        "\n",
        "* Example\n",
        " * { cat, dog }, cute\n",
        "     1. cat, cute\n",
        "     2. dog, cute\n",
        "\n",
        " * color, { blue, red, green }\n",
        "     1. color, blue\n",
        "     2. color, red\n",
        "     3. color, green\n",
        "\n",
        " * man, { boy, girl, \"  \" }\n",
        "     1. **man**  \n",
        "     2. man, boy\n",
        "     3. man, girl"
      ],
      "metadata": {
        "id": "V_Cs8HWTclid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**File name Special tokens**<a name = \"File_name_Special_tokens_help\"></a>\n",
        "* Description\n",
        "  * This function allows you to include parameters and other elements in the name of the file.\n",
        "\n",
        "* Arguments\n",
        "  * {prompt}\n",
        "    * Prompt\n",
        "\n",
        "  * {seed}\n",
        "    * Seed value\n",
        "\n",
        "  * {model_name}\n",
        "    * Path or URL or name of the model\n",
        "\n",
        "  * {g_scale}\n",
        "    * Guidance scale\n",
        "\n",
        "  * {time}\n",
        "    * Current time\n",
        "\n",
        "  * {number}\n",
        "    * Number of times generation has been performed at this runtime\n",
        "\n",
        "* Example\n",
        "  * Generate_img_{seed}_{time}.png"
      ],
      "metadata": {
        "id": "Spj3qRqyptrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Prompt assistant**<a name = \"Prompt_assistant_help\"></a>\n",
        "* **None**\n",
        "  * Select this if not used.\n",
        "\n",
        "* gpt2-prompt-generator\n",
        "  * Recommended model\n",
        "  * This model uses gpt-2.\n",
        "\n",
        "* anime-anything-promptgen-v2\n",
        "  * Suitable for images such as anime and 2D\n",
        "\n",
        "* MagicPrompt-Stable-Diffusion\n",
        "  * It is a versatile model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I8qvP9WkwTj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**default**\n",
        "\n",
        ">Save path\n",
        "\n",
        "* /content/Generated\n",
        "\n",
        ">File_name\n",
        "\n",
        "* GIMG-{number}\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "**EX**\n",
        "* When saving to Google Drive\n",
        "    * /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "lE4Z4OXONRKC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iIEW0jvHK7I1",
        "a1QPxPSzF_aP"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}