{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suzukimain/diffusers_in_Colab/blob/main/diffusers_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eicnuls7qg7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0a4d20-3a9c-44f5-b707-430007d774a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogleDrive is not mounted\n"
          ]
        }
      ],
      "source": [
        "#@title   (option) Mount GoogleDrive { run: \"auto\", display-mode: \"form\"}\n",
        "Conect_GoogleDrive = True  # @param {type:\"boolean\"}\n",
        "\n",
        "conect_drive=False\n",
        "\n",
        "from google.colab import drive\n",
        "if Conect_GoogleDrive:\n",
        "    if not drive._os.path.ismount('/content/drive'):\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            conect_drive=True\n",
        "        except:\n",
        "            print(\"GoogleDrive is not mounted\")\n",
        "            conect_drive=False\n",
        "else:\n",
        "    if drive._os.path.ismount('/content/drive'):\n",
        "        drive.flush_and_unmount()\n",
        "        conect_drive=False\n",
        "        print(\"GoogleDrive unmounted\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4UJqC_WpaGw"
      },
      "outputs": [],
      "source": [
        "#@title   #Step.1 Setup {display-mode: \"form\"}\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "import os\n",
        "import queue\n",
        "import subprocess\n",
        "import sys\n",
        "import threading\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import codecs\n",
        "import datetime\n",
        "import difflib\n",
        "import gc\n",
        "import glob\n",
        "import imageio\n",
        "import importlib\n",
        "import inspect\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pickle\n",
        "import queue\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import sys\n",
        "import time\n",
        "import urllib.request\n",
        "import warnings\n",
        "from base64 import b64encode\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import jax\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "if DEBUG:\n",
        "    warnings.filterwarnings(\"always\",category=DeprecationWarning)\n",
        "else:\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class config_check:\n",
        "    base_config_json = \"/tmp/diffusers_in_colab_config.json\"\n",
        "\n",
        "    def get_json_dict(self):\n",
        "        \"\"\"Retrieve the JSON dictionary from the config file.\"\"\"\n",
        "        config_dict = {}\n",
        "        if os.path.isfile(self.base_config_json):\n",
        "            try:\n",
        "                with open(self.base_config_json, \"r\") as basic_json:\n",
        "                    config_dict = json.load(basic_json)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "        return config_dict\n",
        "\n",
        "    def update_json_dict(self, key, value):\n",
        "        \"\"\"Update the JSON dictionary with a new key-value pair.\"\"\"\n",
        "        basic_json_dict = self.get_json_dict()\n",
        "        basic_json_dict[key] = value\n",
        "        with open(self.base_config_json, \"w\") as json_file:\n",
        "            json.dump(basic_json_dict, json_file, indent=4)\n",
        "\n",
        "    def check_func_hist(self, *element_to_get_history, **kwargs):\n",
        "        \"\"\"\n",
        "        Check and optionally update the history of a given element.\n",
        "\n",
        "        Args:\n",
        "            *element_to_get_history (str): Variable for which to get the history.\n",
        "            **kwargs: Keyword arguments for additional options.\n",
        "                - update (bool): Whether to update the dictionary. Default is True.\n",
        "                - return_value (bool): Whether to return the element value. Default is False.\n",
        "                - key (str): Specific key to look up in the dictionary.\n",
        "                - value (Any): Value to be matched or updated in the dictionary.\n",
        "\n",
        "        Returns:\n",
        "            Any: The historical value if `return_value` is True, or a boolean indicating\n",
        "                 if the value matches the historical value.\n",
        "        \"\"\"\n",
        "        update = kwargs.pop(\"update\", True)\n",
        "        return_value = kwargs.pop(\"return_value\", False)\n",
        "        key = kwargs.pop(\"key\", None)\n",
        "        value = kwargs.pop(\"value\", None)\n",
        "\n",
        "        if key and value:\n",
        "            pass\n",
        "        elif key:\n",
        "            update = False\n",
        "        elif kwargs:\n",
        "            key,value = next(iter(kwargs.items()))\n",
        "        elif element_to_get_history:\n",
        "            key = element_to_get_history[0]\n",
        "            update = False\n",
        "            return_value = True\n",
        "        else:\n",
        "            raise TypeError(\"Missing 'key' argument.\")\n",
        "\n",
        "        basic_json_dict = self.get_json_dict()\n",
        "        hist_value = basic_json_dict.get(key)\n",
        "\n",
        "        if value is not None and hist_value == value:\n",
        "            value_match = True\n",
        "        else:\n",
        "            value_match = False\n",
        "\n",
        "        if update and value is not None:\n",
        "            self.update_json_dict(key, value)\n",
        "\n",
        "        if return_value:\n",
        "            return hist_value\n",
        "\n",
        "        return value_match\n",
        "\n",
        "    '''\n",
        "    #Temporarily removed for possible future use\n",
        "    def get_func_name(self,keyword):\n",
        "        \"\"\"\n",
        "        example:\n",
        "            TEST_JP = 123\n",
        "            check_func_hist(TEST_JP)\n",
        "            return:\n",
        "                ('TEST_JP', 123)\n",
        "        example2:\n",
        "            arg = 'good'\n",
        "            check_func_hist(arg)\n",
        "            return:\n",
        "                ('arg', 'good')\n",
        "\n",
        "        \"\"\"\n",
        "        frame = inspect.currentframe().f_back\n",
        "        caller_locals = frame.f_locals\n",
        "        arg_name = [name for name, value in caller_locals.items() if value is keyword][0]\n",
        "        return arg_name, keyword\n",
        "    '''\n",
        "\n",
        "\n",
        "class ProcessBarRun(config_check):\n",
        "    \"\"\"\n",
        "    Example:\n",
        "    if __name__ == \"__main__\":\n",
        "    bar = ProcessBarRun(total=11)\n",
        "\n",
        "    for s in range(4):\n",
        "        bar.bar_update(3)\n",
        "        time.sleep(1)\n",
        "\n",
        "    bar.bar_update(exit=True)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 total:int,\n",
        "                 default_desc:str = \"Running\",\n",
        "                 default_pofix:str = \"\",\n",
        "                 fin_desc = \"\",\n",
        "                 fin_pofix = \"Finish!\",\n",
        "                 desc_dot:bool = False,\n",
        "                 pofix_dot:bool = False):\n",
        "        self.total = total\n",
        "        self.default_desc = default_desc\n",
        "        self.default_pofix = default_pofix\n",
        "        self.fin_desc = fin_desc\n",
        "        self.fin_pofix = fin_pofix\n",
        "        self.desc_dot = desc_dot\n",
        "        self.pofix_dot = pofix_dot\n",
        "        self.queue_obj = queue.Queue()\n",
        "        self._count = 0\n",
        "        self._run_count = 0\n",
        "        self.dot_count = 0\n",
        "        self.max_dots = 5\n",
        "        self.desc = \"\"\n",
        "        self.pofix = \"\"\n",
        "        self.base_desc_txt = \"\"\n",
        "        self.base_pofix_txt = \"\"\n",
        "        self.tqdm_obj = tqdm(total=total)\n",
        "        self.stop_event = threading.Event()\n",
        "        self.stop_dot = threading.Event()\n",
        "        self.process_bar()\n",
        "\n",
        "    def __del__(self):\n",
        "        self.stop_event.set()\n",
        "        self.thread.join(timeout=0)\n",
        "\n",
        "    def convert_bar_args(self, arg, number, dot=False):\n",
        "        if isinstance(arg, (list, tuple)):\n",
        "            del_num, index = divmod(number, len(arg))\n",
        "            if len(arg) > self.total:\n",
        "                print(f\"The following elements are ignored: {arg[self.total:]}\")\n",
        "            return_arg = arg[index - 1]\n",
        "        else:\n",
        "            return_arg = str(arg)\n",
        "        return return_arg\n",
        "\n",
        "        #途中\n",
        "    def prosess_dot(self):\n",
        "        self.dot_count = 0\n",
        "        chenge_check=False\n",
        "        while not (self.stop_dot.is_set()) and (self.tqdm_obj.disable is False):\n",
        "            for num in range(self.max_dots):\n",
        "                self.base_desc_txt = self.convert_bar_args(arg=self.desc, number=num, dot=self.desc_dot)\n",
        "                self.base_pofix_txt = self.convert_bar_args(arg=self.pofix, number=num, dot=self.pofix_dot)\n",
        "                dot_txt = \".\" * num\n",
        "                desc_dot_txt = dot_txt if self.desc_dot else \"\"\n",
        "                pofix_dot_txt = dot_txt if self.pofix_dot else \"\"\n",
        "                self.tqdm_obj.set_description_str(self.base_desc_txt + desc_dot_txt)\n",
        "                self.tqdm_obj.set_postfix_str(self.base_pofix_txt + pofix_dot_txt)\n",
        "                self.tqdm_obj.refresh()\n",
        "                if self.stop_dot.is_set():\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.5)\n",
        "\n",
        "\n",
        "    def process_bar(self):\n",
        "        self.thread = threading.Thread(target=self.process_bar_func)\n",
        "        self.dot_thread = threading.Thread(target=self.prosess_dot)\n",
        "        self.dot_thread.start()\n",
        "        self.thread.start()\n",
        "\n",
        "    def process_bar_func(self):\n",
        "        max_dots = 4\n",
        "        get_num = \"\"\n",
        "        queue_dict = {}\n",
        "        with self.tqdm_obj:\n",
        "            desc = self.default_desc\n",
        "            pofix = self.default_pofix\n",
        "            for num in range(1, self.total + 1):\n",
        "                        num_found = False\n",
        "                        get_num, queue_dict = self.queue_obj.get()\n",
        "                        self.desc = queue_dict.get(\"desc\", desc)\n",
        "                        self.pofix = queue_dict.get(\"pofix\", pofix)\n",
        "\n",
        "                        if self.stop_event.is_set() or get_num is None:\n",
        "                            self.tqdm_obj.n = self.total\n",
        "                            break\n",
        "                        elif isinstance(get_num, int):\n",
        "                            self.tqdm_obj.update(get_num)\n",
        "                        else:\n",
        "                            raise TypeError(get_num)\n",
        "            self.tqdm_obj.n = self.total\n",
        "\n",
        "\n",
        "    def bar_update(self,\n",
        "                   update_rate: int = 1,\n",
        "                   exit: bool = False,\n",
        "                   desc = None,\n",
        "                   pofix = None,\n",
        "                   desc_dot = None,\n",
        "                   pofix_dot= None):\n",
        "        \"\"\"\n",
        "        args:\n",
        "        desc : str\n",
        "        pofix : str\n",
        "        desc_dot : bool\n",
        "        pofix_dot : bool\n",
        "        \"\"\"\n",
        "        if desc_dot is not None:\n",
        "            self.desc_dot = desc_dot\n",
        "        if pofix_dot is not None:\n",
        "            self.pofix_dot = pofix_dot\n",
        "        self._run_count += 1\n",
        "        queue_dict = {}\n",
        "        if desc is None:\n",
        "            queue_dict[\"desc\"] = self.default_desc\n",
        "        else:\n",
        "            queue_dict[\"desc\"] = desc\n",
        "        if pofix is None:\n",
        "            queue_dict[\"pofix\"] = self.default_pofix\n",
        "        else:\n",
        "            queue_dict[\"pofix\"] = pofix\n",
        "        if exit:\n",
        "            self.queue_obj.put((None, queue_dict))\n",
        "            self.stop()\n",
        "        elif isinstance(update_rate, int):\n",
        "            self.queue_obj.put((update_rate, queue_dict))\n",
        "        else:\n",
        "            raise TypeError(\"Only natural numbers or 'exit' are valid\")\n",
        "\n",
        "    def stop(self):\n",
        "        self.stop_event.set()\n",
        "        self.stop_dot.set()\n",
        "        self.thread.join(timeout=0)\n",
        "        self.tqdm_obj.n = self.total\n",
        "        self.tqdm_obj.refresh()\n",
        "        if self.fin_desc:\n",
        "            self.tqdm_obj.set_description_str(self.fin_desc)\n",
        "        if self.fin_pofix:\n",
        "            self.tqdm_obj.set_postfix_str(self.fin_pofix)\n",
        "        self.tqdm_obj.close()\n",
        "\n",
        "    def run_count(self):\n",
        "        return self._run_count\n",
        "\n",
        "\n",
        "def module_version(module_name):\n",
        "    try:\n",
        "        version = importlib.metadata.version(module_name)\n",
        "        return re.match(r\"^\\d+\\.\\d+\\.\\d+\", version).group(0)\n",
        "\n",
        "    except importlib.metadata.PackageNotFoundError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def device_type_check():\n",
        "    _device_type = jax.devices()[0].device_kind\n",
        "    if \"TPU\" in _device_type:\n",
        "        return \"TPU\"\n",
        "    elif \"cpu\" in _device_type:\n",
        "        return \"cpu\"\n",
        "    else:\n",
        "        return \"cuda\"\n",
        "\n",
        "device_type = device_type_check()\n",
        "\n",
        "Step1 = ProcessBarRun(total=6,\n",
        "                      default_desc = f\"{device_type} runtime setting\",\n",
        "                      pofix_dot = True)\n",
        "\n",
        "\n",
        "\n",
        "def uninstall_package(package_name):\n",
        "    #log redirect\n",
        "    subprocess.run(['pip', 'uninstall', '-q', '-y', package_name],\n",
        "                   stderr=subprocess.DEVNULL,\n",
        "                   stdout=subprocess.PIPE)\n",
        "\n",
        "#bar_update\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Step1.bar_update(pofix=\"Installing torch\")\n",
        "torch_version = module_version(\"torch\")\n",
        "#if \"2.3.0\"<= module_version(\"torch\") <= \"2.3.2\":\n",
        "#    !pip install -q -U torch==2.1.2 torchaudio torchtext torchvision\n",
        "Step1.bar_update(pofix=\"Installing transfomers\")\n",
        "\n",
        "#!pip install -q -U transformers>=4.40.1 --extra-index-url https://github.com/huggingface/transformers.git\n",
        "\n",
        "#bar_update\n",
        "Step1.bar_update(pofix=\"Installing diffusers\")\n",
        "def single_file_loading_error_quick_fix():\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"pip\", \"install\", \"git+https://github.com/suzukimain/diffusers.git\"],\n",
        "            check=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE\n",
        "        )\n",
        "    except subprocess.CalledProcessError:\n",
        "        result = subprocess.run([\"pip\", \"install\", \"git+https://github.com/huggingface/diffusers.git\"])\n",
        "\n",
        "single_file_loading_error_quick_fix()\n",
        "#!pip install -q -U diffusers>=0.28.0 --extra-index-url https://github.com/huggingface/diffusers.git\n",
        "\n",
        "import torch\n",
        "\n",
        "from PIL import Image, PngImagePlugin\n",
        "from google.colab import drive\n",
        "from huggingface_hub import hf_hub_download\n",
        "from natsort import natsorted\n",
        "from requests import HTTPError\n",
        "from torch import Generator\n",
        "from typing import Any, Dict, List, Literal, Optional, Union\n",
        "import yaml\n",
        "\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "import diffusers\n",
        "from diffusers import (\n",
        "    DiffusionPipeline,\n",
        "    FlaxAutoencoderKL,\n",
        "    FlaxDiffusionPipeline,\n",
        "    FlaxStableDiffusionPipeline,\n",
        "    StableDiffusionPipeline,\n",
        "    AutoencoderKL,\n",
        "    schedulers\n",
        ")\n",
        "from diffusers import logging as df_logging\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    AutoModelForCausalLM,\n",
        "    CLIPTokenizer,\n",
        "    AutoTokenizer,\n",
        "    FlaxAutoModelForCausalLM\n",
        ")\n",
        "from transformers import logging as tf_logging\n",
        "\n",
        "if device_type == \"TPU\":\n",
        "    # For hiding WARNING: Skipping tensorflow as it is not installed.\n",
        "    uninstall_package('tensorflow')\n",
        "    Step1.bar_update(update_rate=1, pofix=\"Installing tensorflow-cpu\")\n",
        "\n",
        "    !pip install -q -U tensorflow-cpu\n",
        "\n",
        "    from flax.jax_utils import replicate\n",
        "    from flax.training.common_utils import shard\n",
        "\n",
        "else:\n",
        "    Step1.bar_update(update_rate=1, pofix=\"Installing accelerate\")\n",
        "\n",
        "    !pip install -q -U accelerate\n",
        "\n",
        "    import accelerate\n",
        "    from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "import inspect\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "from typing import get_origin, get_args, Union\n",
        "import typing\n",
        "\n",
        "\n",
        "def custom_logger():\n",
        "    format = '%(levelname)s:<cell line: %(lineno)d> <funcName: %(funcName)s>: %(message)s'\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.propagate = False\n",
        "    if not logger.handlers:\n",
        "        formatter = logging.Formatter(format)\n",
        "        handler = logging.StreamHandler()\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "    return logger\n",
        "\n",
        "logger = custom_logger()\n",
        "\n",
        "\n",
        "\n",
        "if DEBUG:\n",
        "    df_logging.set_verbosity_warning()\n",
        "    tf_logging.set_verbosity_warning()\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "else:\n",
        "    df_logging.set_verbosity_error()\n",
        "    tf_logging.set_verbosity_error()\n",
        "    logger.setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "about: unexplained crash\n",
        "\n",
        "If you get an unexplained crash in transfomers or diffusers while using TPUv2, try the following\n",
        "\n",
        "----do----\n",
        "pip uninstall tensorflow\n",
        "pip install tensorflow-cpu\n",
        "----------\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class data_config:\n",
        "    Config_file=\"model_index.json\"\n",
        "\n",
        "    VALID_URL_PREFIXES = [\"https://huggingface.co/\", \"huggingface.co/\", \"hf.co/\", \"https://hf.co/\"]\n",
        "    exts =  [\".safetensors\", \".ckpt\",\".bin\"]\n",
        "\n",
        "    model_dict = {\n",
        "            \"stable diffusion-v2.1\" : \"stabilityai/stable-diffusion-2-1\",\n",
        "            \"waifu diffusion-v1.4\": \"hakurei/waifu-diffusion\",\n",
        "            \"Anything-v3.0\": \"Linaqruf/anything-v3.0\",\n",
        "            \"anything-midjourney-v-4-1\": \"Joeythemonster/anything-midjourney-v-4-1\",\n",
        "            \"Anything-v4.5\": \"shibal1/anything-v4.5-clone\",\n",
        "            \"AB4.5_AC0.2\": \"aioe/AB4.5_AC0.2\",\n",
        "            \"basil_mix\": \"nuigurumi/basil_mix\",\n",
        "            \"Waifu-Diffusers\": \"Nilaier/Waifu-Diffusers\",\n",
        "            \"Double-Exposure-Diffusion\": \"joachimsallstrom/Double-Exposure-Diffusion\",\n",
        "            \"openjourney-v4\": \"prompthero/openjourney-v4\",\n",
        "            \"ACertainThing\": \"JosephusCheung/ACertainThing\",\n",
        "            \"Counterfeit-V2.0\": \"gsdf/Counterfeit-V2.0\",\n",
        "            \"Counterfeit-V2.5\": \"gsdf/Counterfeit-V2.5\",\n",
        "            \"chilled_remix\":\"chilled_remix\",\n",
        "            \"chilled_reversemix\":\"chilled_reversemix\",\n",
        "            \"7th_Layer\": \"syaimu/7th_test\",\n",
        "            \"EimisAnimeDiffusion_1.0v\": \"eimiss/EimisAnimeDiffusion_1.0v\",\n",
        "            \"JWST-Deep-Space-diffusion\" : \"dallinmackay/JWST-Deep-Space-diffusion\",\n",
        "            \"Riga_Collection\": \"natsusakiyomi/Riga_Collection\",\n",
        "            \"sd-db-epic-space-machine\" : \"rabidgremlin/sd-db-epic-space-machine\",\n",
        "            \"spacemidj\" : \"Falah/spacemidj\",\n",
        "            \"anime-kawai-diffusion\": \"Ojimi/anime-kawai-diffusion\",\n",
        "            \"Realistic_Vision_V2.0\": \"SG161222/Realistic_Vision_V2.0\",\n",
        "            \"nasa-space-v2\" : \"sd-dreambooth-library/nasa-space-v2-768\",\n",
        "            \"meinamix_meinaV10\": \"namvuong96/civit_meinamix_meinaV10\",\n",
        "            \"loliDiffusion\": \"JosefJilek/loliDiffusion\",\n",
        "            }\n",
        "    exclude =  [\"safety_checker/model.safetensors\",\n",
        "                \"unet/diffusion_pytorch_model.safetensors\",\n",
        "                \"vae/diffusion_pytorch_model.safetensors\",\n",
        "                \"text_encoder/model.safetensors\",\n",
        "                \"unet/diffusion_pytorch_model.fp16.safetensors\",\n",
        "                \"text_encoder/model.fp16.safetensors\",\n",
        "                \"vae/diffusion_pytorch_model.fp16.safetensors\",\n",
        "                \"safety_checker/model.fp16.safetensors\",\n",
        "\n",
        "                \"safety_checker/model.ckpt\",\n",
        "                \"unet/diffusion_pytorch_model.ckpt\",\n",
        "                \"vae/diffusion_pytorch_model.ckpt\",\n",
        "                \"text_encoder/model.ckpt\",\n",
        "                \"text_encoder/model.fp16.ckpt\",\n",
        "                \"safety_checker/model.fp16.ckpt\",\n",
        "                \"unet/diffusion_pytorch_model.fp16.ckpt\",\n",
        "                \"vae/diffusion_pytorch_model.fp16.ckpt\"]\n",
        "\n",
        "    Auto_pipe_class=[\n",
        "            \"AutoPipelineForText2Image\",\n",
        "            \"AutoPipelineForImage2Image\",\n",
        "            \"AutoPipelineForInpainting\",\n",
        "     ]\n",
        "\n",
        "    Error_M1 = (\n",
        "        '''\n",
        "        Could not load URL.\n",
        "        Format:\"https://huggingface.co/<repo_name>/<model_name>/blob/main/<path_to_file>\"\n",
        "        EX1: \"https://huggingface.co/gsdf/Counterfeit-V3.0/blob/main/Counterfeit-V3.0.safetensors\"\n",
        "        EX2: \"https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.ckpt\"\n",
        "        '''\n",
        "        )\n",
        "\n",
        "    Error_M2= (\n",
        "        '''\n",
        "        Could not load hugface_path.\n",
        "        Format: <repo_name>/<model_name>\"\n",
        "        EX1: \"Linaqruf/anything-v3.0\"\n",
        "        EX2: \"stabilityai/stable-diffusion-2-1\"\n",
        "\n",
        "        Suport_model:\n",
        "\n",
        "                \"stable diffusion-v2.1\"\n",
        "                \"waifu diffusion-v1.4\"\n",
        "                \"Anything-v3.0\"\n",
        "                \"anything-midjourney-v-4-1\"\n",
        "                \"Anything-v4.5\"\n",
        "                \"AB4.5_AC0.2\"\n",
        "                \"basil_mix\"\n",
        "                \"Waifu-Diffusers\"\n",
        "                \"Double-Exposure-Diffusion\"\n",
        "                \"openjourney-v4\"\n",
        "                \"ACertainThing\"\n",
        "                \"Counterfeit-V2.0\"\n",
        "                \"Counterfeit-V2.5\"\n",
        "                \"7th_Layer\"\n",
        "                \"EimisAnimeDiffusion_1.0v\"\n",
        "                \"Riga_Collection\"\n",
        "                \"anime-kawai-diffusion\"\n",
        "                \"Realistic_Vision_V2.0\"\n",
        "                \"meinamix_meinaV10\"\n",
        "                \"loliDiffusion\"\n",
        "                ''')\n",
        "\n",
        "    Error_M3 = ('''\n",
        "                The specified path could not be recognized. Please try the following\n",
        "                ・Check that the path to the file exists.\n",
        "                ・Check that there is no whitespace in the path.\n",
        "                ・Check if there are any special symbols such as \"\\\" or \".\" and other special symbols (may not be recognized).\n",
        "                ''')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class basic_config(data_config,config_check):\n",
        "\n",
        "    def __init__(self):\n",
        "        #super().__init__()\n",
        "        self.device_count = self.count_device()\n",
        "        self.device_type = device_type_check()\n",
        "        self.device = self.device_set(self.device_type)\n",
        "        self.use_TPU = True if self.device_type==\"TPU\" else False\n",
        "        self.conect_gdrive = True if drive._os.path.ismount(\"/content/drive\") else False\n",
        "\n",
        "    @classmethod\n",
        "    def get_inherited_class(cls,class_name) -> list:\n",
        "        inherited_class = inspect.getmro(class_name)\n",
        "        return [cls_method.__name__ for cls_method in inherited_class]\n",
        "\n",
        "    @classmethod\n",
        "    def check_url(cls,url) -> bool:\n",
        "        try:\n",
        "            result = requests.get(url, timeout=6.0).raise_for_status()\n",
        "        except:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    @classmethod\n",
        "    def device_set(cls,device_type):\n",
        "        if device_type == \"TPU\":\n",
        "            #import torch_xla.core.xla_model as xm\n",
        "            #device = xm.xla_device()\n",
        "            device = device_type\n",
        "        else:\n",
        "            logger.debug(f\"device_type: {device_type}\")\n",
        "            device = device_type\n",
        "        return device\n",
        "\n",
        "\n",
        "    def is_TPU(self):\n",
        "        if device_type_check() == \"TPU\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def is_safetensors(self,path):\n",
        "        path = os.path.basename(path)\n",
        "        if \"safetensors\" == path.split(\".\")[-1]:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def count_device(self):\n",
        "        return jax.device_count()\n",
        "\n",
        "    def get_item(self,dict_obj):\n",
        "        \"\"\"\n",
        "        Returns the first element of the dictionary\n",
        "        \"\"\"\n",
        "        return next(iter(dict_obj.items()))[1]\n",
        "\n",
        "\n",
        "    def pipeline_metod_type(self,Target_class) -> str:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        Target_class : class\n",
        "\n",
        "        Returns:\n",
        "        Literal['torch','flax','onnx']\n",
        "        \"\"\"\n",
        "        torch_list=[\"DiffusionPipeline\",\n",
        "                    \"AutoPipelineForText2Image\",\n",
        "                    \"AutoPipelineForImage2Image\",\n",
        "                    \"AutoPipelineForInpainting\",]\n",
        "\n",
        "        flax_list = [\"FlaxDiffusionPipeline\",]\n",
        "\n",
        "        #assert not isinstance(Target_class, str),f\"Target_class can not use str\"\n",
        "\n",
        "        cls_method= self.get_inherited_class(Target_class)\n",
        "\n",
        "        if any(method in torch_list for method in cls_method):\n",
        "            class_type= \"torch\"\n",
        "        elif any(method in flax_list for method in cls_method):\n",
        "            class_type= \"flax\"\n",
        "        else:\n",
        "            class_type= \"onnx\"\n",
        "        return class_type\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def sort_v(self,sorted_list) -> list:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "        Sorted by version in order of newest to oldest\n",
        "        \"\"\"\n",
        "        return natsorted(sorted_list,reverse = True)\n",
        "\n",
        "\n",
        "    def key_check(self,keyword) -> bool:\n",
        "        global key_dict\n",
        "        if \"key_dict\" not in globals():\n",
        "            key_dict = {}\n",
        "        key = str(keyword)\n",
        "        key_in = False\n",
        "        if key in key_dict:\n",
        "            if keyword == key_dict[key]:\n",
        "                key_in = True\n",
        "        key_dict[key] = keyword\n",
        "        return key_in\n",
        "\n",
        "    def get_call_method(self,\n",
        "                        class_name,\n",
        "                        method_name : str = '__call__') ->list:\n",
        "        \"\"\"\n",
        "        Acquire the arguments of the function specified by 'method_name'\n",
        "        for the class specified by 'class_name'\n",
        "        \"\"\"\n",
        "        if isinstance(class_name,str):\n",
        "            class_name = getattr(getattr(diffusers, class_name),method_name)\n",
        "        parameters = inspect.signature(class_name).parameters\n",
        "        arg_names = []\n",
        "        for param in parameters.values():\n",
        "            arg_names.append(param.name)\n",
        "        return arg_names\n",
        "\n",
        "    def get_class_elements(self,search):\n",
        "        return list(search.__class__.__annotations__.keys())\n",
        "\n",
        "    def check_for_safetensors(self,path):\n",
        "        _ext = os.path.basename(path).split(\".\")[-1]\n",
        "        if _ext == \"safetensors\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def pipe_class_type(self,class_name):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        class_name : class\n",
        "\n",
        "        Returns:\n",
        "        Literal['txt2img','img2img','txt2video']\n",
        "        \"\"\"\n",
        "        _txt2img_method_list = []#else\n",
        "        _img2img_method_list = [\"image\"]\n",
        "        _img2video_method_list = [\"video_length\",\"fps\"]\n",
        "\n",
        "        call_method = self.get_call_method(class_name,method_name = '__call__')\n",
        "\n",
        "        if any(method in call_method for method in _img2video_method_list):\n",
        "            pipeline_type = \"txt2video\"\n",
        "        elif any(method in call_method for method in _img2img_method_list):\n",
        "            pipeline_type = \"img2img\"\n",
        "        else:\n",
        "            pipeline_type = \"txt2img\"\n",
        "        return pipeline_type\n",
        "\n",
        "\n",
        "    def yes_or_no(self,\n",
        "                  text,\n",
        "                  default_return=False,\n",
        "                  num=3):\n",
        "        for i in range(num):\n",
        "            choice=input(text).lower()\n",
        "            if choice in [\"y\",\"yes\"]:\n",
        "                default_return=True\n",
        "            elif choice in [\"n\",\"no\"]:\n",
        "                default_return=False\n",
        "            else:\n",
        "                print(f\"[y/n]のみ有効です(退出まで残り{num-(i+1)})\")\n",
        "        return default_return\n",
        "\n",
        "\n",
        "\n",
        "    def import_on_str(self,\n",
        "                      desired_function_or_class,\n",
        "                      module_name = \"\"):\n",
        "        if not module_name:\n",
        "            import_object = __import__(desired_function_or_class)\n",
        "        else:\n",
        "            import_object = getattr(__import__(module_name), desired_function_or_class)\n",
        "        return import_object\n",
        "\n",
        "    def max_temper(self,search_word, search_list):\n",
        "        return difflib.get_close_matches(search_word, search_list,cutoff=0, n=1)\n",
        "\n",
        "    def sort_list_obj(self,list_obj,need_txt):\n",
        "        sorted_list=[]\n",
        "        for module_obj in list_obj:\n",
        "            if need_txt.lower() in module_obj.lower():\n",
        "                sorted_list.append(module_obj)\n",
        "        return sorted_list\n",
        "\n",
        "    def checkpoint_type_get(\n",
        "            self,\n",
        "            checkpoint_path_or_dict ,\n",
        "            config_files= None,\n",
        "            original_config_file= None,\n",
        "            model_type = None,\n",
        "            is_upscale = False\n",
        "            ):\n",
        "        \"\"\"\n",
        "        About model_type:\n",
        "        The model_type itself will be left for possible use at some point.\n",
        "        \"\"\"\n",
        "\n",
        "        from_safetensors = False\n",
        "        checkpoint = None\n",
        "        if isinstance(checkpoint_path_or_dict, str):\n",
        "            if os.path.isfile(checkpoint_path_or_dict):\n",
        "                from_safetensors: bool = self.check_for_safetensors(checkpoint_path_or_dict)\n",
        "                if from_safetensors:\n",
        "                    from safetensors.torch import load_file as safe_load\n",
        "                    checkpoint = safe_load(checkpoint_path_or_dict, device=self.device)\n",
        "                else:\n",
        "                    checkpoint = torch.load(checkpoint_path_or_dict, map_location=self.device)\n",
        "            elif os.path.isdir(checkpoint_path_or_dict):\n",
        "                model_index_path = os.path.join(checkpoint_path_or_dict,\"model_index.json\")\n",
        "                if os.path.isfile(model_index_path):\n",
        "                    with open(model_index_path,\"r\") as loaded_model_index:\n",
        "                        cls_name = loaded_model_index[\"_class_name\"]\n",
        "                        #Fixed in due course.\n",
        "                        if \"XL\" in cls_name:\n",
        "                            return \"SDXL\"\n",
        "                        else:\n",
        "                            return \"SD\"\n",
        "\n",
        "\n",
        "\n",
        "        elif isinstance(checkpoint_path_or_dict, dict):\n",
        "            checkpoint = checkpoint_path_or_dict\n",
        "        else:\n",
        "            raise TypeError(f\"checkpoint_path_or_dict: {checkpoint_path_or_dict}\")\n",
        "        if \"global_step\" in checkpoint:\n",
        "            global_step = checkpoint[\"global_step\"]\n",
        "        else:\n",
        "            global_step = None\n",
        "        while \"state_dict\" in checkpoint:\n",
        "            checkpoint = checkpoint[\"state_dict\"]\n",
        "        if original_config_file is None:\n",
        "            key_name_v2_1 = \"model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight\"\n",
        "            key_name_sd_xl_base = \"conditioner.embedders.1.model.transformer.resblocks.9.mlp.c_proj.bias\"\n",
        "            key_name_sd_xl_refiner = \"conditioner.embedders.0.model.transformer.resblocks.9.mlp.c_proj.bias\"\n",
        "            #is_upscale = pipeline_class == StableDiffusionUpscalePipeline\n",
        "\n",
        "            config_url = None\n",
        "\n",
        "            # model_type = \"v1\"\n",
        "            if config_files is not None and \"v1\" in config_files:\n",
        "                original_config_file = config_files[\"v1\"]\n",
        "            else:\n",
        "                config_url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\"\n",
        "\n",
        "            if key_name_v2_1 in checkpoint and checkpoint[key_name_v2_1].shape[-1] == 1024:\n",
        "                # model_type = \"v2\"\n",
        "                if config_files is not None and \"v2\" in config_files:\n",
        "                    original_config_file = config_files[\"v2\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\"\n",
        "                if global_step == 110000:\n",
        "                    # v2.1 needs to upcast attention\n",
        "                    upcast_attention = True\n",
        "            elif key_name_sd_xl_base in checkpoint:\n",
        "                # only base xl has two text embedders\n",
        "                if config_files is not None and \"xl\" in config_files:\n",
        "                    original_config_file = config_files[\"xl\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_base.yaml\"\n",
        "            elif key_name_sd_xl_refiner in checkpoint:\n",
        "                # only refiner xl has embedder and one text embedders\n",
        "                if config_files is not None and \"xl_refiner\" in config_files:\n",
        "                    original_config_file = config_files[\"xl_refiner\"]\n",
        "                else:\n",
        "                    config_url = \"https://raw.githubusercontent.com/Stability-AI/generative-models/main/configs/inference/sd_xl_refiner.yaml\"\n",
        "\n",
        "            if is_upscale:\n",
        "                config_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/x4-upscaling.yaml\"\n",
        "\n",
        "            if config_url is not None:\n",
        "                try:\n",
        "                    original_config_file = BytesIO(requests.get(config_url).content)\n",
        "                except:\n",
        "                    logger.warning(f\"Could not download the Config_file to find out the model type from the following URL.: {config_url}\")\n",
        "                    return None\n",
        "            else:\n",
        "                with open(original_config_file, \"r\") as f:\n",
        "                    original_config_file = f.read()\n",
        "        else:\n",
        "            with open(original_config_file, \"r\") as f:\n",
        "                original_config_file = f.read()\n",
        "\n",
        "        original_config = yaml.safe_load(original_config_file)\n",
        "\n",
        "        if (\n",
        "            model_type is None\n",
        "            and \"cond_stage_config\" in original_config[\"model\"][\"params\"]\n",
        "            and original_config[\"model\"][\"params\"][\"cond_stage_config\"] is not None\n",
        "        ):\n",
        "\n",
        "            model_type = original_config[\"model\"][\"params\"][\"cond_stage_config\"][\"target\"].split(\".\")[-1]\n",
        "            return \"SD\"\n",
        "\n",
        "        elif model_type is None and original_config[\"model\"][\"params\"][\"network_config\"] is not None:\n",
        "            if original_config[\"model\"][\"params\"][\"network_config\"][\"params\"][\"context_dim\"] == 2048:\n",
        "                model_type = \"SDXL\"\n",
        "            else:\n",
        "                model_type = \"SDXL-Refiner\"\n",
        "            return \"SDXL\"\n",
        "\n",
        "        else:\n",
        "            return model_type\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "init\n",
        "\"\"\"\n",
        "gl_txt_pipe = None\n",
        "strength = 1\n",
        "入力する画像 = \"\"\n",
        "video_length= 8\n",
        "video_fps = 8\n",
        "safety_level = \"MAX\"\n",
        "momentum = 1\n",
        "momentum_hist = -0.1\n",
        "history_d = \"rand_init\"\n",
        "\n",
        "\n",
        "if not drive._os.path.ismount('/content/drive'):\n",
        "    conect_drive = False\n",
        "    Connect_Gdrive=\"\\033[33mNo connection\\033[0m\"\n",
        "else:\n",
        "    conect_drive = True\n",
        "    Connect_Gdrive=\"\\033[34mConnection Successful\\033[0m\"\n",
        "\n",
        "#base dir\n",
        "os.makedirs(\"/content/script\",exist_ok=True)\n",
        "sys.path.append(\"/content/script\")\n",
        "\n",
        "\n",
        "Step1.bar_update(exit=True,pofix=\"Finish!\")\n",
        "\n",
        "print(\"\\n\\033[34m___________________________________________\\n\")\n",
        "print(f\"Devie: {device_type_check()}\\n\")\n",
        "print(f\"Googledrive: {Connect_Gdrive}\")\n",
        "print(\"\\n\\033[32mSetup completed successfully\\033[0m\")\n",
        "\n",
        "step1_finish =True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  #Step.2 Model Selection{display-mode: \"form\"}\n",
        "\n",
        "# @markdown >Selecting the model to use\n",
        "\n",
        "model_select = \"stable diffusion-v2.1(basic)\" # @param [\"stable diffusion-v2.1(basic)\", \"Counterfeit-V2.5(Anime)(better)\", \"loliDiffusion(Anime)\", \"waifu diffusion-v1.4(Anime)\", \"Anything-v3.0(Anime)\", \"Anything-v4.5(Anime)\", \"anything-midjourney-v-4-1(Anime)\", \"ACertainThing(Anime)\", \"anime-kawai-diffusion(Anime)\", \"AB4.5_AC0.2(Anime)\", \"basil_mix(Anime)\", \"Counterfeit(Anime)\", \"Counterfeit-V2.0(Anime)\", \"chilled_remix(Anime)\", \"Double-Exposure-Diffusion(Anime)\", \"EimisAnimeDiffusion_1.0v(Anime)\", \"7th_Layer(Anime)\", \"Riga_Collection(Anime)\", \"Waifu-Diffusers(Anime)\", \"JWST-Deep-Space-diffusion(space)\", \"sd-db-epic-space-machine(space_ship)\", \"spacemidj(space)\", \"nasa-space-v2(space)\", \"openjourney-v4(Reality)\", \"Realistic_Vision_V2.0(Reality)\", \"meinamix_meinaV10(Reality)\", \"search\"] {allow-input: true}\n",
        "del_word_list=[\"(basic)\",\"(Anime)\",\"(Reality)\",\"(space_ship)\",\"(space)\",\"(better)\"]\n",
        "if model_select in [\"stable diffusion-v2.1(basic)\", \"Counterfeit-V2.5(Anime)(better)\", \"loliDiffusion(Anime)\", \"waifu diffusion-v1.4(Anime)\", \"Anything-v3.0(Anime)\", \"Anything-v4.5(Anime)\", \"anything-midjourney-v-4-1(Anime)\", \"ACertainThing(Anime)\", \"anime-kawai-diffusion(Anime)\", \"AB4.5_AC0.2(Anime)\", \"basil_mix(Anime)\", \"Counterfeit(Anime)\", \"Counterfeit-V2.0(Anime)\", \"chilled_remix(Anime)\", \"Double-Exposure-Diffusion(Anime)\", \"EimisAnimeDiffusion_1.0v(Anime)\", \"7th_Layer(Anime)\", \"Riga_Collection(Anime)\", \"Waifu-Diffusers(Anime)\", \"JWST-Deep-Space-diffusion(space)\", \"sd-db-epic-space-machine(space_ship)\", \"spacemidj(space)\", \"nasa-space-v2(space)\", \"openjourney-v4(Reality)\", \"Realistic_Vision_V2.0(Reality)\", \"meinamix_meinaV10(Reality)\"]:\n",
        "    for del_word in del_word_list:\n",
        "        model_select=model_select.replace(del_word, \"\" )\n",
        "\n",
        "#@markdown * Select from the model_select pull-down\n",
        "\n",
        "#@markdown * Enter the name of the model and the path or URL where the model is stored\n",
        "\n",
        "#@markdown *  **search** to search all directories for candidate files or folders.\n",
        "\n",
        "## @markdown >モードの切り替え (mode change)\n",
        "#mode_select = \"fp16\" #@param [\"fp32\",\"fp16\"]\n",
        "\n",
        "\n",
        "#@markdown >Config\n",
        "\n",
        "auto = False  # @param {type:\"boolean\"}\n",
        "# @markdown Automatically select repository & model files (recommended: ON)\n",
        "\n",
        "\n",
        "if \"step1_finish\" not in locals():\n",
        "    raise NameError(\"\\033[33mPlease execute Step.1 first\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "class Huggingface(basic_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.num_prints=20\n",
        "        self.model_id=\"\"\n",
        "        self.model_name=\"\"\n",
        "        self.vae_name=\"\"\n",
        "        self.model_file=\"\"\n",
        "        self.input_url=False\n",
        "        self.diffuser_model=False\n",
        "        self.check_choice_key = \"\"\n",
        "        self.choice_number = -1\n",
        "        self.file_path_dict={}\n",
        "        self.special_file=\"\"\n",
        "        self.hf_repo_id = \"\"\n",
        "        #self.model_select = \"\"\n",
        "\n",
        "\n",
        "\n",
        "    def repo_name_or_path(self,model_name_or_path):\n",
        "        pattern = r\"([^/]+)/([^/]+)/(?:blob/main/)?(.+)\"\n",
        "        weights_name = None\n",
        "        repo_id = None\n",
        "        for prefix in self.VALID_URL_PREFIXES:\n",
        "            model_name_or_path = model_name_or_path.replace(prefix, \"\")\n",
        "        match = re.match(pattern, model_name_or_path)\n",
        "        if not match:\n",
        "            return repo_id, weights_name\n",
        "        repo_id = f\"{match.group(1)}/{match.group(2)}\"\n",
        "        weights_name = match.group(3)\n",
        "        return repo_id, weights_name\n",
        "\n",
        "    def run_hf_download(self,url_or_path):\n",
        "        \"\"\"\n",
        "        retrun:\n",
        "        os.path\n",
        "        \"\"\"\n",
        "        def _hf_repo_download(path):\n",
        "            model_path = DiffusionPipeline.download(path)\n",
        "            return model_path\n",
        "\n",
        "        if any(url_or_path.startswith(checked) for checked in self.VALID_URL_PREFIXES):\n",
        "            if not self.check_url(url_or_path):\n",
        "                raise HTTPError(\"Invalid URL\")\n",
        "            hf_path,file_name =self.repo_name_or_path(url_or_path)\n",
        "            logger.debug(f\"url_or_path:{url_or_path}\")\n",
        "            logger.debug(f\"hf_path: {hf_path} \\nfile_name: {file_name}\")\n",
        "            if hf_path and file_name:\n",
        "                model_file_path = hf_hub_download(hf_path, file_name)\n",
        "            elif hf_path and (not file_name):\n",
        "                if self.diffusers_model_check(hf_path):\n",
        "                    model_file_path = _hf_repo_download(url_or_path)\n",
        "                else:\n",
        "                    raise HTTPError(\"Invalid hf_path\")\n",
        "            else:\n",
        "                raise TypeError(\"Invalid path_or_url\")\n",
        "\n",
        "\n",
        "        #from hf_repo\n",
        "        elif self.diffusers_model_check(url_or_path):\n",
        "            logger.debug(f\"url_or_path: {url_or_path}\")\n",
        "            model_file_path = _hf_repo_download(url_or_path)\n",
        "        else:\n",
        "            logger.debug(f\"url_or_path:{url_or_path}\")\n",
        "            raise TypeError(\"Invalid path_or_url\")\n",
        "        return model_file_path\n",
        "\n",
        "\n",
        "\n",
        "    def model_safe_check(self,model_list) ->str:\n",
        "        if len(model_list)>1:\n",
        "           for check_model in model_list:\n",
        "                match = bool(re.search(r\"(?i)[-＿]sfw\", check_model))\n",
        "                if match:\n",
        "                    return check_model\n",
        "        return model_list[0]\n",
        "\n",
        "    def list_safe_check(self,model_list) -> list:\n",
        "        for check_model in model_list:\n",
        "            if bool(re.search(r\"(?i)[-ー_＿]sfw\", check_model)):\n",
        "                model_list.remove(check_model)\n",
        "                model_list.insert(0, check_model)\n",
        "                break\n",
        "        return model_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def diffusers_model_check(self,checked_model: str) -> bool:\n",
        "        index_url=f\"https://huggingface.co/{checked_model}/blob/main/model_index.json\"\n",
        "        return self.check_url(index_url)\n",
        "\n",
        "    def hf_model_check(self,path) -> bool:\n",
        "        return self.check_url(f\"https://huggingface.co/{path}\")\n",
        "\n",
        "    def data_get(self,path) -> list:\n",
        "        url = f\"https://huggingface.co/api/models/{path}\"\n",
        "        data = requests.get(url).json()\n",
        "        file_value_list = []\n",
        "        df_model_bool=False\n",
        "        #fix error': 'Repo model <repo_id>/<model> is gated. You must be authenticated to access it.\n",
        "        try:\n",
        "            siblings=data[\"siblings\"]\n",
        "        except KeyError:\n",
        "            return []\n",
        "\n",
        "        for item in siblings:\n",
        "            data[\"siblings\"]\n",
        "            file_path=item[\"rfilename\"]\n",
        "            #model_index.json outside the root directory is not recognized\n",
        "            if file_path==\"model_index.json\":\n",
        "                df_model_bool=True\n",
        "            elif (any(file_path.endswith(ext) for ext in self.exts) and\n",
        "                not any(file_path.endswith(ex) for ex in self.exclude)):\n",
        "                file_value_list.append(file_path)\n",
        "        #↓{df_model,file_value_list}\n",
        "        self.file_path_dict.update({path:(df_model_bool,file_value_list)})\n",
        "        return file_value_list\n",
        "\n",
        "    def hf_model_search(self,\n",
        "                        model_path,\n",
        "                        limit_num):\n",
        "        url = f\"https://huggingface.co/api/models\"#?search={model_name}\"\n",
        "        params={\"search\":model_path,\"sort\":\"likes\",\"direction\":-1,\"limit\":limit_num}#\"downloads\",}\n",
        "        return requests.get(url,params=params).json()\n",
        "\n",
        "    def hf_models(self,\n",
        "                  model_name,\n",
        "                  limit):\n",
        "        \"\"\"\n",
        "        return:\n",
        "        repo_model_list,with_like : list\n",
        "        \"\"\"\n",
        "        #logger.debug(f\"model_name: {model_name}\")\n",
        "        data=self.hf_model_search(model_name,limit)\n",
        "        final_list = []\n",
        "        if data:\n",
        "            for item in data:\n",
        "                model_id,like,private_value,tag_value = item[\"modelId\"],item[\"likes\"],item[\"private\"],item[\"tags\"]\n",
        "                if  (\"audio-to-audio\" not in tag_value and\n",
        "                    (not private_value)):\n",
        "                    if self.data_get(model_id):\n",
        "                        model_dict = {\"model_id\":model_id,\n",
        "                                      \"like\":like,}\n",
        "                        final_list.append(model_dict)\n",
        "        else:\n",
        "            print(\"No models matching your criteria were found on huggingface.\")\n",
        "            return []\n",
        "        return final_list\n",
        "\n",
        "\n",
        "\n",
        "    def model_name_search(self,\n",
        "                          model_name: str,\n",
        "                          auto_set: bool,\n",
        "                          Recursive_execution:bool = False):\n",
        "\n",
        "        def find_max_like(model_dict_list:list):\n",
        "            \"\"\"\n",
        "            Finds the dictionary with the highest \"like\" value in a list of dictionaries.\n",
        "\n",
        "            Args:\n",
        "                model_dict_list: A list of dictionaries.\n",
        "\n",
        "            Returns:\n",
        "                The dictionary with the highest \"like\" value, or the first dictionary if none have \"like\".\n",
        "            \"\"\"\n",
        "            max_like = 0\n",
        "            max_like_dict = None\n",
        "            for model_dict in model_dict_list:\n",
        "                if model_dict[\"like\"] > max_like:\n",
        "                    max_like = model_dict[\"like\"]\n",
        "                    max_like_dict = model_dict\n",
        "            return max_like_dict or model_dict_list[0]\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        auto_set: bool\n",
        "        loads the model with the most likes in hugface\n",
        "        \"\"\"\n",
        "        if Recursive_execution:\n",
        "            limit = 1000\n",
        "        else:\n",
        "            limit = 15\n",
        "\n",
        "\n",
        "\n",
        "        repo_model_list = self.hf_models(model_name,limit)\n",
        "        model_history = self.check_func_hist(key=\"hf_model_name\",\n",
        "                                             return_value=True)\n",
        "        if not auto_set:\n",
        "            print(\"\\033[34mThe following model paths were found\")\n",
        "            if model_history is not None:\n",
        "                print(f\"Previous Choice: {model_history}\")\n",
        "            print(\"0.Search civitai\")\n",
        "            for (i,(model_dict)) in enumerate(repo_model_list,1):\n",
        "                model_name = model_dict[\"model_id\"]\n",
        "                like = model_dict[\"like\"]\n",
        "                print(f\"{i}.model path: {model_name}, evaluation: {like}\")\n",
        "\n",
        "            if Recursive_execution:\n",
        "                print(\"16.Other than above\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    choice = int(input(\"Select the model path to use: \"))\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                    continue\n",
        "                if choice == 0:\n",
        "                    return \"_hf_no_model\"\n",
        "                elif (not Recursive_execution) and choice>=16 and choice == len(repo_model_list)+1:\n",
        "                    return self.model_name_search(model_name = model_name,\n",
        "                                                  auto_set = auto_set,\n",
        "                                                  Recursive_execution = True)\n",
        "                elif 1 <= choice <= len(repo_model_list):\n",
        "                    choice_path_dict = repo_model_list[choice-1]\n",
        "                    choice_path = choice_path_dict[\"model_id\"]\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Please enter the numbers 1~{len(repo_model_list)}\")\n",
        "\n",
        "        else:\n",
        "            if repo_model_list:\n",
        "                choice_path = find_max_like(repo_model_list)\n",
        "            else:\n",
        "                choice_path = \"_hf_no_model\"\n",
        "\n",
        "\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "\n",
        "    def file_name_set_sub(self,model_select,file_value,model_type):\n",
        "        check_key = f\"{model_select}_select\"\n",
        "        if not file_value and (not self.diffuser_model):\n",
        "            print(\"\\033[31mNo candidates found at huggingface\\033[0m\")\n",
        "            res = input(\"Searching for civitai?: \")\n",
        "            if res.lower() in [\"y\",\"yes\"]:\n",
        "                return \"_hf_no_model\"\n",
        "            else:\n",
        "                raise ValueError(\"No available files were found in the specified repository\")\n",
        "        elif not file_value:\n",
        "            print(\"\\033[34mOnly models in Diffusers format found\")\n",
        "            while True:\n",
        "                result=input(\"Do you want to use it?[y/n]: \")\n",
        "                if result.lower() in [\"y\",\"yes\"]:\n",
        "                    return \"_DFmodel\"\n",
        "                elif result.lower() in [\"n\",\"no\"]:\n",
        "                    sec_result=input(\"Searching for civitai?[y/n]: \")\n",
        "                    if sec_result.lower() in [\"y\",\"yes\"]:\n",
        "                        return \"_hf_no_model\"\n",
        "                    elif sec_result.lower() in [\"n\",\"no\"]:\n",
        "                        raise ValueError(\"Processing was stopped because no corresponding model was found.\")\n",
        "                else:\n",
        "                    print(\"Please enter only [y,n]\")\n",
        "        file_value=self.list_safe_check(file_value)\n",
        "        if len(file_value)>=self.num_prints: #15\n",
        "            start_number=\"1\"\n",
        "            #previous_select = self.check_func_hist(key=check_key)\n",
        "            #if previous_select:\n",
        "            choice_history = self.check_func_hist(key = check_key,return_value=True)\n",
        "            if choice_history:\n",
        "                if choice_history>self.num_prints+1:\n",
        "                    choice_history = self.num_prints+1\n",
        "                print(f\"\\033[33m＊Previous number: {choice_history}\\033[0m\")\n",
        "\n",
        "            if self.diffuser_model:\n",
        "                start_number=\"0\"\n",
        "                print(\"\\033[34m0.Use Diffusers format model\")\n",
        "            for i in range(self.num_prints):\n",
        "                print(f\"\\033[34m{i+1}.File name: {file_value[i]}\\033[0m\")\n",
        "            print(f\"\\033[34m{self.num_prints+1}.Other than the files listed above (all candidates will be displayed)\\n\")\n",
        "            while True:\n",
        "                choice = input(f\"select the file you want to use({start_number}~21): \")\n",
        "                try:\n",
        "                    choice=int(choice)\n",
        "                except ValueError:\n",
        "                    print(\"\\033[33mOnly natural numbers are valid\\033[34m\")\n",
        "                    continue\n",
        "                if self.diffuser_model and choice==0:\n",
        "                    old_num=None\n",
        "                    self.input_url=False\n",
        "                    self.choice_number = -1\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return \"_DFmodel\"\n",
        "\n",
        "                elif choice==(self.num_prints+1): #other_file\n",
        "                    break\n",
        "                elif 1<=choice<=self.num_prints:\n",
        "                    self.input_url=True\n",
        "                    old_num=choice\n",
        "                    choice_path=file_value[choice-1]\n",
        "                    self.choice_number = choice\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return choice_path\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter numbers from 1~{self.num_prints}\\033[34m\")\n",
        "            print(\"\\033[0m\",end=\"\")\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "        choice_history = self.check_func_hist(key = check_key,return_value=True)\n",
        "        if choice_history:\n",
        "            print(f\"\\033[33m＊Previous number: {choice_history}\\033[0m\")\n",
        "\n",
        "        start_number=\"1\"\n",
        "        if self.diffuser_model:\n",
        "            start_number=\"0\"\n",
        "            print(\"\\033[34m0.Use Diffusers format model\\033[0m\")\n",
        "        for i, file_name in enumerate(file_value, 1):\n",
        "            print(f\"\\033[34m{i}.File name: {file_name}\")\n",
        "        while True:\n",
        "            choice = input(f\"Select the file you want to use({start_number}~{len(file_value)}): \")\n",
        "            try:\n",
        "                choice=int(choice)\n",
        "            except ValueError:\n",
        "                print(\"\\033[33mOnly natural numbers are valid\\033[34m\")\n",
        "            else:\n",
        "                if self.diffuser_model and choice==0:\n",
        "                    self.input_url=False\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    self.choice_number = -1\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return \"_DFmodel\"\n",
        "                if 1<=choice<=len(file_value):\n",
        "                    self.input_url=True\n",
        "                    old_num=choice\n",
        "                    choice_path=file_value[choice-1]\n",
        "                    self.choice_number = choice\n",
        "                    print(\"\\033[0m\",end=\"\")\n",
        "                    choice_history_update = self.check_func_hist(key=check_key,value=choice,update=True)\n",
        "                    return choice_path\n",
        "                else:\n",
        "                    print(f\"\\033[33mPlease enter numbers from 1~{len(file_value)}\\033[34m\")\n",
        "        #print(\"\\033[0m\",end=\"\")\n",
        "\n",
        "\n",
        "    def file_name_set(self,model_select,auto,model_type=\"Checkpoint\",download=False):\n",
        "        logger.debug(f\"model_select: {model_select}\")\n",
        "        if self.diffusers_model_check(model_select) and model_type==\"Checkpoint\":\n",
        "            self.diffuser_model=True\n",
        "        #check_choice_key = f\"model_select_{model_type}\"\n",
        "        url = f\"https://huggingface.co/api/models/{model_select}\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.HTTPError:\n",
        "            raise HTTPError(\"A hugface login or token is required\")\n",
        "        data = response.json()\n",
        "        choice_path=\"\"\n",
        "        file_value = []\n",
        "        logger.debug(data)\n",
        "        logger.debug(element for element in data)\n",
        "        siblings = data[\"siblings\"]\n",
        "        if data:\n",
        "            for item in siblings:\n",
        "                fi_path=item[\"rfilename\"]\n",
        "                if (any(fi_path.endswith(ext) for ext in self.exts) and\n",
        "                    not any(fi_path.endswith(ex) for ex in self.exclude)):\n",
        "                    file_value.append(fi_path)\n",
        "        else:\n",
        "            raise ValueError(\"No available file was found.\\nPlease check the name.\")\n",
        "        if file_value:\n",
        "            file_value=self.sort_v(file_value)\n",
        "            if not auto:\n",
        "                print(\"\\033[34mThe following model files were found\\033[0m\")\n",
        "                choice_path=self.file_name_set_sub(model_select,file_value,model_type)\n",
        "                #if not self.choice_number == -1:\n",
        "                #    choice_key_update = self.check_func_hist(key=check_key,value=self.choice_number)\n",
        "            else:\n",
        "                if self.diffuser_model:\n",
        "                    self.input_url=False\n",
        "                else:\n",
        "                    self.input_url=True\n",
        "                    choice_path=self.model_safe_check(file_value)\n",
        "\n",
        "\n",
        "        elif self.diffuser_model:\n",
        "            print(\"\\033[32mOnly models in Diffusers format found\")\n",
        "            choice_path = \"_DFmodel\"\n",
        "        else:\n",
        "            raise FileNotFoundError(\"No available files found in the specified repository\")\n",
        "        #if model_type!=\"Checkpoint\" and model_type!=\"_DFmodel\":\n",
        "            #self.input_url=False\n",
        "        if download and not choice_path==\"_DFmodel\":\n",
        "            choice_path=hf_hub_download(repo_id=model_select, filename=choice_path)\n",
        "        #if not self.choice_number== -1:\n",
        "        #    choice_key_update = self.check_func_hist(key=check_choice_key,value=self.choice_number)\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "class Civitai(basic_config):\n",
        "    def __init__(self):\n",
        "        self.civitai_dir=\"/root/.cache/Civitai\"\n",
        "        super().__init__()\n",
        "\n",
        "    def public_civiai(self,\n",
        "                      model_select,\n",
        "                      auto,\n",
        "                      model_type):\n",
        "        \"\"\"\n",
        "        retrun:\n",
        "        os.path\n",
        "        \"\"\"\n",
        "        url,filename,model_dir_id=self.civitai_download(model_select,auto,model_type)\n",
        "        filename=filename.replace(\" \", \"_\")\n",
        "\n",
        "        #Need to set model_dir_id to str.\n",
        "        task_main_dir=os.path.join(self.civitai_dir, str(model_dir_id))\n",
        "        self.use_civitai(url,filename,task_main_dir)\n",
        "        return os.path.join(task_main_dir,filename)\n",
        "\n",
        "    def use_civitai(self,\n",
        "                    url,\n",
        "                    save_name,\n",
        "                    task_main_dir):\n",
        "\n",
        "        download_list = self.check_func_hist(\"download_list\")\n",
        "        if not isinstance(download_list,list):\n",
        "            download_list = []\n",
        "\n",
        "        if (not os.path.exists(task_main_dir)) or (not url in download_list):\n",
        "            os.makedirs(task_main_dir,exist_ok=True)\n",
        "            os.chdir(task_main_dir)\n",
        "            os.environ[\"path\"] = url\n",
        "            os.environ[\"save\"] = save_name\n",
        "            #os.environ[\"_dir_path\"]=task_main_dir\n",
        "            !wget -q --show-progress --content-disposition $path  -O$save\n",
        "            download_list.append(url)\n",
        "            os.chdir(\"/content\")\n",
        "        elif url in download_list:\n",
        "            print(\"\\nThe model has already been downloaded.\\n\")\n",
        "\n",
        "        else:\n",
        "            if not url in download_list:\n",
        "                raise HTTPError(\"Invalid URL\")\n",
        "        #update download_list\n",
        "        _download_list = self.check_func_hist(download_list = download_list,\n",
        "                                              update = True)\n",
        "\n",
        "\n",
        "    def civitai_download(self,\n",
        "                         query,\n",
        "                         auto_set,\n",
        "                         model_type):\n",
        "        #global items\n",
        "        state={}\n",
        "        durl_list=[]\n",
        "        files_value=[]\n",
        "        durl=\"\"\n",
        "        filename=\"\"\n",
        "        file_id=None\n",
        "        like=0\n",
        "        choice_path=\"\"\n",
        "        choice_file=\"\"\n",
        "        params = {\"query\": query,\"types\":model_type,\"sort\":\"Most Downloaded\"}\n",
        "        response = requests.get(\"https://civitai.com/api/v1/models\", params=params)\n",
        "        if response.status_code == 200:\n",
        "            data =response.json()\n",
        "            items = data[\"items\"]\n",
        "            if items:\n",
        "                for item in items:\n",
        "\n",
        "                    checked_files=item[\"modelVersions\"]\n",
        "                    for check in checked_files:\n",
        "                        if \"files\" in check:\n",
        "                            files_value=check[\"files\"]\n",
        "                        #items[0][\"id\"]\n",
        "                        repo_name=item[\"name\"]\n",
        "                        stat=item[\"stats\"]\n",
        "                        likes=stat[\"favoriteCount\"]\n",
        "\n",
        "                        for isa in item[\"modelVersions\"]:\n",
        "                            isa_files=isa[\"files\"]\n",
        "                            if isa_files: #important\n",
        "                                for ss in isa_files:\n",
        "                                    if \"downloadUrl\" in ss and \"name\" in ss:\n",
        "                                        durl=ss[\"downloadUrl\"]\n",
        "                                        filename=ss[\"name\"]\n",
        "                                        file_id=ss[\"id\"]\n",
        "                                        break\n",
        "                                    else:\n",
        "                                        durl,filename,file_id=\"\",\"\",None\n",
        "                        if not durl==\"\":\n",
        "                            durl_list.append([durl,filename,file_id])\n",
        "                            state.update({len(state): (repo_name,likes,file_id)})\n",
        "\n",
        "                if state:\n",
        "                    if not auto_set:\n",
        "                        sorted_with_like = sorted(state.items(), key=lambda x: x[1][1], reverse=True)\n",
        "                        print(\"\\n\\nThe following model paths were found\")\n",
        "\n",
        "                        if len(state)>=15:\n",
        "                            for i in range(15):\n",
        "                                model_name,like,file_id=state[i]\n",
        "                                print(f\"\\033[34m{i+1}.model path: {model_name}, evaluation: {like}\")\n",
        "\n",
        "                            print(\"16.Other than above\")\n",
        "                            while True:\n",
        "                                    choice = input(\"Select the model path to use: \")\n",
        "                                    try:\n",
        "                                        choice=int(choice)\n",
        "                                    except ValueError:\n",
        "                                        print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                                        continue\n",
        "                                    if choice==16:\n",
        "                                        break\n",
        "                                    if 1<=choice<=15:\n",
        "                                        choice_path,choice_file,file_id=durl_list[choice-1]\n",
        "                                        return choice_path,choice_file,file_id\n",
        "                                    else:\n",
        "                                        print(f\"\\033[33mPlease enter the numbers 1~{len(durl_list)}\\033[34m\")\n",
        "\n",
        "                        for num_of_key, dict_obj in sorted_with_like:\n",
        "                            model_name, like,file_id= dict_obj\n",
        "                            print(f\"\\033[34m{num_of_key}.model path: {model_name}, evaluation: {like}\")\n",
        "                        while True:\n",
        "                                try:\n",
        "                                    choice=int(input(\"Select the model path to use: \"))\n",
        "                                except ValueError:\n",
        "                                    print(\"\\033[33mOnly natural numbers are valid.\\033[34m\")\n",
        "                                    continue\n",
        "                                if 1<=choice<=len(durl_list):\n",
        "                                    choice_path,choice_file,file_id=durl_list[choice-1]\n",
        "                                    return choice_path,choice_file,file_id\n",
        "                                else:\n",
        "                                    print(f\"\\033[33mPlease enter the numbers 1~{len(durl_list)}\\033[34m\")\n",
        "\n",
        "                    else:\n",
        "                        max_likes = max(state, key=lambda x: state[x][1])\n",
        "                        choice_path,choice_file,file_id = durl_list[max_likes]\n",
        "\n",
        "                else:\n",
        "                    raise ValueError(\"No model candidates found\")\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"No model candidates found\")\n",
        "        else:\n",
        "           raise HTTPError(\"Failed to acquire model information.\")\n",
        "        return choice_path,choice_file,file_id\n",
        "\n",
        "\n",
        "class with_Flax(basic_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def sd_to_flax(self,url_or_path):\n",
        "        hf_path,file_name,model_file_path=\"\",\"\",\"\"\n",
        "        #from_config or from_single_file\n",
        "        if os.path.isfile(url_or_path):\n",
        "            model_file_path=url_or_path\n",
        "\n",
        "        #from_pretrain\n",
        "        elif os.path.isdir(url_or_path):\n",
        "            if os.path.exists(os.path.join(url_or_path, self.Config_file)):\n",
        "                return url_or_path\n",
        "\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"model_index.json not found in '{url_or_path}'\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Invalid dir_path.\")\n",
        "\n",
        "\n",
        "        model_saved_dir=os.path.join(os.path.dirname(model_file_path),\"converted\")\n",
        "        os.makedirs(model_saved_dir,exist_ok=True)\n",
        "        if not os.path.isfile(os.path.join(model_saved_dir,\"model_index.json\")):\n",
        "            print(\"モデルを変換中...\")\n",
        "            #from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "            is_from_safetensors = self.check_for_safetensors(url_or_path)\n",
        "            assert isinstance(is_from_safetensors, bool)\n",
        "            from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "            save_pipeline = download_from_original_stable_diffusion_ckpt(url_or_path, from_safetensors = is_from_safetensors)\n",
        "            #can not use output format :safetensors\n",
        "            save_pipeline.save_pretrained(model_saved_dir, safe_serialization = False)\n",
        "            print(\"モデルの変換終了\")\n",
        "            del save_pipeline\n",
        "        return model_saved_dir\n",
        "\n",
        "    def Flax_pipe_create(self,url_or_path):\n",
        "        model_dir_path=self.sd_to_flax(url_or_path)\n",
        "        model_index_path=os.path.join(model_dir_path,self.Config_file)\n",
        "        with open(model_index_path, \"r\") as f:\n",
        "            pipeline_class_name = json.load(f)[\"_class_name\"]\n",
        "        pipeline_class = getattr(diffusers, pipeline_class_name)\n",
        "        logger.info(f\"Pipeline class imported: {pipeline_class_name}.\")\n",
        "        try:\n",
        "            base_pipe,base_params = FlaxDiffusionPipeline.from_pretrained(model_dir_path,\n",
        "                                                                           dtype=jax.numpy.bfloat16,\n",
        "                                                                           use_safetensors=True)\n",
        "\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Insufficient memory.\")\n",
        "        params = replicate(base_params)\n",
        "        return base_pipe,params\n",
        "\n",
        "\n",
        "class Config_Mix(Huggingface,\n",
        "                 Civitai,\n",
        "                 with_Flax,\n",
        "                 basic_config,\n",
        "                 data_config,\n",
        "                 config_check):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "class pipeline_setup(Config_Mix):\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_select: str,\n",
        "                 auto: bool):\n",
        "        self.model_select=model_select\n",
        "        self.use_TPU = self.is_TPU()\n",
        "        self.auto=auto\n",
        "        super().__init__()\n",
        "        self.model_path = \"\"\n",
        "\n",
        "\n",
        "       # self.device = self.device_set(device_type_check())\n",
        "\n",
        "    def File_search(self):\n",
        "        \"\"\"\n",
        "        only single file\n",
        "        \"\"\"\n",
        "\n",
        "        search_path=\"\"\n",
        "        paths = []\n",
        "        for root, dirs, files in os.walk(\"/\"):\n",
        "            for file in files:\n",
        "                if any(file.endswith(ext) for ext in self.exts):\n",
        "                    path = os.path.join(root, file)\n",
        "                    if path not in self.exclude:\n",
        "                        if not path.startswith(\"/root/.cache\"):\n",
        "                            paths.append(path)\n",
        "        num_path=len(paths)\n",
        "        if not num_path:\n",
        "            raise FileNotFoundError(\"\\033[33mModel File not found\\033[0m\")\n",
        "        else:\n",
        "            print(f\"{num_path} candidate model files found.\")\n",
        "        for s, path in enumerate(paths, 1):\n",
        "            print(f\"{s}: {path}\")\n",
        "        num = int(input(f\"Please enter a number(1〜{num_path}): \"))\n",
        "        if 1 <= num <= len(paths):\n",
        "            search_path=(paths[num-1])\n",
        "            print(f\"Selected model file: {search_path}\\n\")\n",
        "        else:\n",
        "            raise TypeError(f\"\\033[33mOnly natural numbers in the following range are valid : (1〜{len(paths)})\\033[0m\")\n",
        "        return search_path\n",
        "\n",
        "\n",
        "    def model_set(self,\n",
        "                  model_select,\n",
        "                  auto = False,\n",
        "                  model_type = \"Checkpoint\",\n",
        "                  branch = \"main\",\n",
        "                  download: bool = False) -> list:\n",
        "        \"\"\"\n",
        "        return:\n",
        "        [model_path:str, {base_model_path: str,from_single_file: bool}]\n",
        "        \"\"\"\n",
        "\n",
        "        if not model_type  in [\"Checkpoint\", \"TextualInversion\", \"LORA\", \"Hypernetwork\", \"AestheticGradient\", \"Controlnet\", \"Poses\"]:\n",
        "            raise TypeError('Wrong argument. Valid values are \"Checkpoint\", \"TextualInversion\", \"LORA\", \"Hypernetwork\", \"AestheticGradient\", \"Controlnet\", \"Poses\"')\n",
        "        local = True if download else False\n",
        "        return_dict = {\"base_model_path\":model_select,\n",
        "                       \"from_dingle_file\":False,\n",
        "                       \"local\":local,\n",
        "                       }\n",
        "        show_url_or_path = \"\"\n",
        "        from_single_file = False\n",
        "        model_path = \"\"\n",
        "        file_path = \"\"\n",
        "        if model_select in self.model_dict:\n",
        "            model_path_to_check = self.model_dict[model_select]\n",
        "            if self.check_url(f\"https://huggingface.co/{model_path_to_check}\"):\n",
        "                model_select = model_path_to_check\n",
        "\n",
        "        if model_select == \"search\":\n",
        "            #only file\n",
        "            model_path = self.File_search()\n",
        "            return_dict[\"from_single_file\"] = False\n",
        "\n",
        "        elif model_select.startswith(\"https://huggingface.co/\"):\n",
        "            if not self.check_url(model_select):\n",
        "                raise ValueError(self.Error_M1)\n",
        "            else:\n",
        "                if download:\n",
        "                    model_path = self.run_hf_download(model_select)\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "                else:\n",
        "                    model_path = model_select\n",
        "                    return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        elif model_select.startswith(\"https://civitai.com/\"):\n",
        "            #local file\n",
        "            model_path = self.public_civiai(model_select,\n",
        "                                                           auto,\n",
        "                                                           model_type)\n",
        "            return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        elif os.path.isfile(model_select):\n",
        "            model_path = model_select\n",
        "            return_dict[\"from_single_file\"] = True\n",
        "            return_dict[\"local\"] = True\n",
        "\n",
        "        elif os.path.isdir(model_select):\n",
        "            if os.path.exists(os.path.join(model_select,self.Config_file)):\n",
        "                return_dict[\"model_path\"] = model_select\n",
        "                return_dict[\"from_single_file\"] = False\n",
        "                return_dict[\"local\"] = True\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"model_index.json not found in {model_select}\")\n",
        "\n",
        "        elif model_select.count(\"/\") == 1:\n",
        "            if auto and self.diffusers_model_check(model_select):\n",
        "                if download:\n",
        "                    model_path = self.run_hf_download(model_select)\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "                else:\n",
        "                    model_path = model_select\n",
        "                    return_dict[\"from_single_file\"] = False\n",
        "            elif auto and (not self.hf_model_check(model_select)):\n",
        "                raise ValueError(f'The specified repository could not be found, please try turning off \"auto\" (model_select:{model_select})')\n",
        "            else:\n",
        "                file_path=self.file_name_set(model_select,auto,model_type)\n",
        "                if file_path == \"_hf_no_model\":\n",
        "                    raise ValueError(\"Model not found\")\n",
        "                elif file_path == \"_DFmodel\":\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(model_select)\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                    else:\n",
        "                        model_path = model_select\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                else:\n",
        "                    hf_model_path=f\"https://huggingface.co/{model_select}/blob/{branch}/{file_path}\"\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(hf_model_path)\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "                    else:\n",
        "                        model_path = hf_model_path\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        else:\n",
        "            model_name = self.model_name_search(model_select,auto)\n",
        "            #self.hf_repo_id = model_name\n",
        "            #hf->civit\n",
        "            if not model_name == \"_hf_no_model\":\n",
        "                file_path = self.file_name_set(model_name,auto,model_type)\n",
        "                if model_path == \"_DFmodel\":\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(file_path)\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "                    else:\n",
        "                        model_path = model_name #f\"https://huggingface.co/{model_name}\"\n",
        "                        return_dict[\"from_single_file\"] = False\n",
        "\n",
        "\n",
        "\n",
        "                else:\n",
        "                    hf_model_path = f\"https://huggingface.co/{model_name}/blob/{branch}/{file_path}\"\n",
        "                    if download:\n",
        "                        model_path = self.run_hf_download(hf_model_path)\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "                    else:\n",
        "                        model_path = hf_model_path\n",
        "                        return_dict[\"from_single_file\"] = True\n",
        "\n",
        "\n",
        "            else:\n",
        "                model_path = self.public_civiai(model_select,\n",
        "                                                auto,\n",
        "                                                model_type)\n",
        "                return_dict[\"from_single_file\"] = True\n",
        "\n",
        "        return [model_path,return_dict]\n",
        "\n",
        "\n",
        "\n",
        "    def pipe_status_check(self,pipeline):\n",
        "        from diffusers.pipelines.stable_diffusion import (StableDiffusionSafetyChecker,FlaxStableDiffusionSafetyChecker)\n",
        "        from transformers import CLIPImageProcessor\n",
        "        pipe_class_name_ = pipeline.__class__.__name__\n",
        "        pipe_type = self.pipeline_metod_type(self.import_on_str(pipe_class_name_,\"diffusers\"))\n",
        "        if hasattr(pipeline,\"safety_checker\"):\n",
        "            if getattr(pipeline,\"safety_checker\") is None:\n",
        "                if pipe_type == \"flax\":\n",
        "                    pipeline.safety_checker = FlaxStableDiffusionSafetyChecker.from_pretrained(\n",
        "                        \"CompVis/stable-diffusion-safety-checker\", from_pt=True\n",
        "                    )\n",
        "                elif pipe_type in [\"torch\", \"onnx\"]:\n",
        "                    pipeline.safety_checker = StableDiffusionSafetyChecker.from_pretrained(\n",
        "                        \"CompVis/stable-diffusion-safety-checker\"\n",
        "                    )\n",
        "        if hasattr(pipeline,\"feature_extractor\"):\n",
        "            if getattr(pipeline,\"feature_extractor\") is None:\n",
        "                pipeline.feature_extractor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        return pipeline\n",
        "\n",
        "\n",
        "    def pipe_create(self,\n",
        "                    model_path,\n",
        "                    from_single_file):\n",
        "        logger.debug(f\"input_url; {self.input_url}\")\n",
        "        logger.debug(f\"model_path; {self.model_path}\")\n",
        "\n",
        "        if from_single_file:\n",
        "            #not from_confg\n",
        "            base_pipe = StableDiffusionPipeline.from_single_file(\n",
        "                model_path\n",
        "                ).to(self.device)\n",
        "        else:\n",
        "            base_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                model_path\n",
        "                ).to(self.device)\n",
        "\n",
        "        if self.device == \"cuda\":\n",
        "            base_pipe.to(torch_dtype = torch.float16)\n",
        "\n",
        "        return base_pipe\n",
        "\n",
        "    def pipeline_task(self):\n",
        "        logger.debug(f\"auto: {auto}\")\n",
        "        logger.debug(f\"model_select: {model_select}\")\n",
        "        params = None\n",
        "        model_path,model_dict = self.model_set(self.model_select,\n",
        "                                               auto = self.auto,\n",
        "                                               download = False)\n",
        "        #model_path = model_dict[\"base_model_path\"]\n",
        "        from_single_file = model_dict[\"from_single_file\"]\n",
        "\n",
        "        update_model_path = self.check_func_hist(key=\"model_path\",value=model_path)\n",
        "\n",
        "        if self.use_TPU:\n",
        "            try:\n",
        "                base_pipe,params = self.Flax_pipe_create(model_path)\n",
        "            except OSError as a:\n",
        "                logger.debug(a)\n",
        "                raise OSError(\"Check your internet connection\")\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                base_pipe = self.pipe_create(model_path, from_single_file)\n",
        "            except OSError as a:\n",
        "                logger.debug(a)\n",
        "                raise OSError(\"Check your internet connection\")\n",
        "        base_pipe = self.pipe_status_check(base_pipe)\n",
        "        return base_pipe,params, model_path\n",
        "\n",
        "\n",
        "pipe_set = pipeline_setup(model_select = model_select,\n",
        "                          auto = auto\n",
        "                          )\n",
        "base_pipe,parmer,model_path = pipe_set.pipeline_task()\n",
        "\n",
        "if device_type == \"cpu\" and base_pipe.dtype == torch.float16:\n",
        "    if DEBUG:\n",
        "        logger.warning(\"base_pipe.dtype is torch.float16 with cpu\")\n",
        "    else:\n",
        "        raise RuntimeError(\"CPU cannot use base_pipe with half precision (torch.float16)\")\n",
        "\n",
        "\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\033[32m\\n------------------\\n\")\n",
        "print(f\"\\033[32mmodel_path: {model_path}\\033[0m\\n\")\n",
        "print(\"\\033[32mModel set-up has been completed.\\033[0m\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w9YtvPtgOGZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCtR5TwuUvY"
      },
      "outputs": [],
      "source": [
        "#@title  #Step.3  Pipeline Setup{display-mode: \"form\"}\n",
        "\n",
        "# @markdown >Pipeline class set\n",
        "\n",
        "pipe_type = \"txt2img\" # @param [\"txt2img\", \"img2img\", \"Inpaint\", \"txt2video\", \"safe\"] {allow-input: true}\n",
        "\n",
        "##@markdown >テスト機能\n",
        "#Accelerated_inference = True  # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown >Scheduler set\n",
        "\n",
        "Scheduler_select = \"DDIM\" # @param [\"DPM\", \"DDPM\", \"DDIM\", \"DEISM\", \"DPM_S\", \"EulerA\", \"Euler\", \"HeunD\", \"K_DPM2D\", \"K_DPM2AD\", \"LMSD\", \"PNDM\", \"UniPCM\", \"EulerA_with_sonar\", \"Euler_with_sonar\"] {allow-input: true}\n",
        "if not Scheduler_select:\n",
        "    raise TypeError(\"Scheduler_select has not been entered\")\n",
        "\n",
        "#@markdown >Vae set  （Enter only if you want to exchange vae)\n",
        "vae_select = \"\" # @param [\"waifu-diffusion\", \"Counterfeit-V2.5\", \"anything-v3.0\"] {allow-input: true}\n",
        "\n",
        "auto = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown >Eextra parameter\n",
        "\n",
        "set_extra_parameter = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown * If you change them, you can update the parameters by pressing Update Values.\n",
        "\n",
        "# @markdown >Filter switching\n",
        "\n",
        "\n",
        "# @markdown **Caution : Be careful when changing it**\n",
        "\n",
        "Filter_off = True  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#laion/CLIP-ViT-H-14-laion2B-s32B-b79K\n",
        "\n",
        "\n",
        "\n",
        "class vae_set(Config_Mix):\n",
        "    def __init__(self):\n",
        "        self.use_input_url=False\n",
        "        self.vae_path=\"\"\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def vae_load(self,vae_model_name=\"\",auto=False):\n",
        "        #global vae\n",
        "        if vae_model_name:\n",
        "            model_names = self.model_name_search(vae_model_name,auto)\n",
        "            vae_path = self.file_name_set(model_names,auto,download=True)\n",
        "            if vae_path == \"_DFmodel\":\n",
        "                vae_path = model_names\n",
        "                single_file = False\n",
        "\n",
        "            elif os.path.isfile(vae_path):\n",
        "                single_file = True\n",
        "            elif os.path.isdir(vae_path):\n",
        "                single_file = False\n",
        "            else:\n",
        "                single_file = True\n",
        "            #model_names,vae_path = self.vae_name_set(vae_model_name)\n",
        "            #if self.diffusers_model_check(model_names):\n",
        "            #    self.use_input_url = False\n",
        "            #    vae_path = model_names\n",
        "            #else:\n",
        "            #    self.use_input_url=True\n",
        "            #    vae_path = f\"https://huggingface.co/{model_names}/blob/main/{vae_path}\"\n",
        "\n",
        "            #FlaxAutoencoderKL\n",
        "            if self.use_TPU:\n",
        "                if single_file:\n",
        "                    vae = FlaxAutoencoderKL.from_single_file(vae_path)\n",
        "                else:\n",
        "                    try:\n",
        "                        vae = FlaxAutoencoderKL.from_pretrained(vae_path)\n",
        "                    except Exception:\n",
        "                        vae = FlaxAutoencoderKL.from_pretrained(vae_path , subfolder=\"vae\")\n",
        "            else:\n",
        "                if single_file:\n",
        "                    vae = AutoencoderKL.from_single_file(vae_path)\n",
        "                else:\n",
        "                    try:\n",
        "                        vae = AutoencoderKL.from_pretrained(vae_path)\n",
        "                    except Exception:\n",
        "                        vae = AutoencoderKL.from_pretrained(vae_path , subfolder=\"vae\")\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            vae = self.base_pipe.vae\n",
        "            vae_path = \"\"\n",
        "        return vae,vae_path\n",
        "\n",
        "\n",
        "\n",
        "class Scheduler_set(Config_Mix):\n",
        "    Scheduler_dict={\n",
        "            \"DDPM\": \"DDPMScheduler\",\n",
        "            \"DDIM\": \"DDIMScheduler\",\n",
        "            \"PNDM\": \"PNDMScheduler\",\n",
        "            \"LMSD\" : \"LMSDiscreteScheduler\",\n",
        "            \"DPM\":  \"DPMSolverMultistepScheduler\",\n",
        "            \"EulerA\": \"EulerAncestralDiscreteScheduler\",\n",
        "            \"Euler\": \"EulerDiscreteScheduler\",\n",
        "            \"DEISM\":\"DEISMultistepScheduler\",\n",
        "            \"UniPCM\":\"UniPCMultistepScheduler\",\n",
        "            \"K_DPM2D\":\"KDPM2DiscreteScheduler\",\n",
        "            \"DPM_S\":\"DPMSolverSinglestepScheduler\",\n",
        "            \"K_DPM2AD\":\"KDPM2AncestralDiscreteScheduler\",\n",
        "            \"HeunD\":\"HeunDiscreteScheduler\",\n",
        "            }\n",
        "    Special_Scheduler_dict={\n",
        "            \"Euler_with_sonar\":\"Euler_Scheduler_with_sonar\",\n",
        "            \"EulerA_with_sonar\":\"EulerA_Scheduler_with_sonar\",\n",
        "            }\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.scheduler_name = \"\"\n",
        "    \"\"\"\n",
        "    def Euler_sh_set(self,Scheduler_name):\n",
        "        '''\n",
        "        Args:\n",
        "            Scheduler_name: Either \"CustomEuler\" or \"CustomEulerA\".\n",
        "        '''\n",
        "        assert Scheduler_name in [\"CustomEuler\", \"CustomEulerA\"]\n",
        "        if not os.path.exists(\"./script/Euler_mod\"):\n",
        "            os.makedirs(\"./script/Euler_mod\",exist_ok=True)\n",
        "            !git clone https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git ./script/Euler_mod\n",
        "        path_1 = \"./script/Euler_mod/EulerANew.py\"\n",
        "        path_2 = \"./script/Euler_mod/EulerNew.py\"\n",
        "        if path_1 not in sys.path:\n",
        "            sys.path.append(path_1)\n",
        "            sys.path.append(path_2)\n",
        "        os.chdir(\"./script/Euler_mod\")\n",
        "        if Scheduler_name==\"CustomEulerA\":\n",
        "            !python EulerANew.py\n",
        "            Scheduler_object=self.import_on_str(\"EulerA\",module_name=\"EulerANew\")\n",
        "        else:\n",
        "            !python EulerNew.py\n",
        "            Scheduler_object=self.import_on_str(\"Euler\",module_name=\"EulerNew\")\n",
        "        os.chdir(\"../..\")\n",
        "        return Scheduler_object\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def scheduler_setup(self,Scheduler_select):\n",
        "\n",
        "\n",
        "        if Scheduler_select in self.Special_Scheduler_dict:\n",
        "            #Scheduler_class = self.Euler_sh_set(Scheduler_select)\n",
        "            if not os.path.isdir(\"/content/script/Euler_sonar\"):\n",
        "                !git clone -q  https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git /content/script/Euler_sonar\n",
        "            from Euler_sonar.EulerNew import Euler as Euler_Scheduler_with_sonar\n",
        "            from Euler_sonar.EulerANew import EulerA as EulerA_Scheduler_with_sonar\n",
        "            if Scheduler_select == \"Euler_with_sonar\":\n",
        "                Scheduler_class = Euler_Scheduler_with_sonar\n",
        "            else:\n",
        "                Scheduler_class = EulerA_Scheduler_with_sonar\n",
        "        else:\n",
        "            logger.debug(f\"scheduler: {Scheduler_select}\")\n",
        "            if Scheduler_select in self.Scheduler_dict:\n",
        "                Scheduler_select = self.Scheduler_dict[Scheduler_select]\n",
        "            try:\n",
        "                Scheduler_class = getattr(diffusers, Scheduler_select)\n",
        "            except AttributeError:\n",
        "                _error = self.make_Error_message(Scheduler_select,dir(diffusers),need_txt=\"Scheduler\")\n",
        "                raise AttributeError(f'\"{Scheduler_select}\" not found. Maybe \"{_error}\" ?')\n",
        "        return Scheduler_class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class make_main_pipe(Scheduler_set,\n",
        "                     vae_set,\n",
        "                     Config_Mix\n",
        "                     ):\n",
        "    def __init__(self,\n",
        "                 pipe_name,\n",
        "                 Filter_off,\n",
        "                 Scheduler_select,\n",
        "                 vae_select,\n",
        "                 auto,\n",
        "                 base_pipe,\n",
        "                 parmer):\n",
        "        super().__init__()\n",
        "        self.pipeline_name = self.pipeline_name_convert(pipe_name)\n",
        "        self.pipeline_class = self.pipeline_class_set(self.pipeline_name)\n",
        "        self.pipeline_type = self.pipeline_metod_type(self.pipeline_class)\n",
        "        self.Scheduler_class = super().scheduler_setup(Scheduler_select)\n",
        "        self.Filter_off = Filter_off\n",
        "        self.base_pipe = base_pipe\n",
        "        self.parmer = parmer\n",
        "        self.vae,self.vae_path = self.vae_load(vae_select, auto)\n",
        "        self.auto = auto\n",
        "        self.pipe_args_setup = {}\n",
        "        self.stetas = {}\n",
        "        self.from_pipe_args = {}\n",
        "        self.main_name = \"\"\n",
        "        self.pipe_module = None\n",
        "\n",
        "\n",
        "\n",
        "    def make_Error_message(self,\n",
        "                           base_txt,\n",
        "                           list_obj,\n",
        "                           need_txt=\"\"):\n",
        "            \"\"\"\n",
        "            Args:\n",
        "            base_txt : base_txt: Returns the string most similar to the one specified here. Note that if \"need_txt\" is specified, it must be included.\n",
        "            list_obj : Search list for candidate strings\n",
        "            need_txt : Strings that must be included in the candidate list\n",
        "            \"\"\"\n",
        "            if not list_obj:\n",
        "                list_obj = dir(diffusers)\n",
        "\n",
        "            if need_txt:\n",
        "                _diffusers_module = self.sort_list_obj(list_obj,need_txt)\n",
        "            else:\n",
        "                _diffusers_module = (dir(diffusers))\n",
        "            logger.debug(type(_diffusers_module))\n",
        "            pretxt = self.max_temper(base_txt,_diffusers_module)\n",
        "            if pretxt:\n",
        "                return pretxt[0]\n",
        "            else:\n",
        "                raise AttributeError(\"Please try another pipeline\")\n",
        "\n",
        "    def pipeline_name_convert(self,pipeline_name: str):\n",
        "        #\"StableDiffusionPipeline\"\n",
        "        pipe_class_dict={\n",
        "            \"txt2img\":\"AutoPipelineForText2Image\",\n",
        "            \"img2img\":\"AutoPipelineForImage2Image\",\n",
        "            \"Inpaint\":\"AutoPipelineForInpainting\",\n",
        "            \"txt2video\":\"TextToVideoZeroPipeline\",\n",
        "            }\n",
        "        #FlaxStableDiffusionPipeline,FlaxStableDiffusionImg2ImgPipeline\n",
        "        Flax_pipe_class_dict={\n",
        "        \"txt2img\":\"FlaxStableDiffusionPipeline\",\n",
        "        \"img2img\":\"FlaxStableDiffusionImg2ImgPipeline\",\n",
        "        \"Inpaint\":\"FlaxStableDiffusionInpaintPipeline\",\n",
        "        \"txt2video\": \"\",\n",
        "        }\n",
        "        params = None\n",
        "        if self.use_TPU:\n",
        "            if pipeline_name in Flax_pipe_class_dict:\n",
        "                pipeline_name = Flax_pipe_class_dict[pipeline_name]\n",
        "        else:\n",
        "            if pipeline_name in pipe_class_dict:\n",
        "                pipeline_name = pipe_class_dict[pipeline_name]\n",
        "\n",
        "        return pipeline_name\n",
        "\n",
        "\n",
        "    def pipeline_class_set(self,\n",
        "                           pipeline_name : str):\n",
        "        try:\n",
        "            pipe_class = getattr(diffusers, pipeline_name)\n",
        "        except AttributeError:\n",
        "            pretxt = self.make_Error_message(pipeline_name , dir(diffusers),need_txt=\"Pipeline\")\n",
        "            raise AttributeError(f\"'{pipeline_name}' not found. Maybe '{pretxt}' ?\")\n",
        "        return pipe_class\n",
        "\n",
        "\n",
        "    def main_pipe_set(self):\n",
        "        txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe=None,None,None,None,None\n",
        "        textual_inversion_dict ={\n",
        "            \"EasyNegativeV2.safetensors\": \"EasyNegative\",\n",
        "            \"bad-hands-5.pt\": \"bad-hands\",\n",
        "            }\n",
        "        init_method_list = [\n",
        "            \"text_encoder\",\n",
        "            \"tokenizer\",\n",
        "            \"unet\",\n",
        "            \"image_encoder\",\n",
        "            ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        logger.debug(self.Scheduler_class)\n",
        "        self.stetas[\"vae\"] = self.vae\n",
        "        self.stetas[\"scheduler\"] = self.Scheduler_class.from_config(self.base_pipe.scheduler.config)\n",
        "        logger.debug(self.stetas[\"scheduler\"])\n",
        "        stetas_check = self.get_call_method(class_name=self.pipeline_name,method_name='__init__')\n",
        "        for init_method in init_method_list:\n",
        "            if ((init_method in stetas_check) and\n",
        "                (hasattr(self.base_pipe, init_method))):\n",
        "                self.stetas[init_method] = getattr(self.base_pipe, init_method)\n",
        "        if self.Filter_off:\n",
        "            if \"feature_extractor\" in stetas_check:\n",
        "                self.stetas[\"feature_extractor\"] = None\n",
        "                self.from_pipe_args[\"feature_extractor\"] = None\n",
        "\n",
        "            if \"safety_checker\" in stetas_check or (self.pipeline_name in self.Auto_pipe_class):\n",
        "                self.stetas[\"safety_checker\"] = None\n",
        "\n",
        "            elif \"load_safety_checker\" in stetas_check:\n",
        "                self.stetas[\"load_safety_checker\"] = False\n",
        "\n",
        "            elif \"requires_safety_checker\" in stetas_check:\n",
        "                 self.stetas[\"requires_safety_checker\"] = False\n",
        "\n",
        "            else:\n",
        "                print(f'\"{self.pipeline_name}\"ではsatety_checkerの指定が使用できません')\n",
        "        else:\n",
        "            if \"feature_extractor\" in stetas_check:\n",
        "                self.stetas[\"feature_extractor\"] = self.base_pipe.feature_extractor\n",
        "\n",
        "            if \"safety_checker\" in stetas_check or (self.pipeline_name in self.Auto_pipe_class):\n",
        "                self.stetas[\"safety_checker\"] = self.base_pipe.safety_checker\n",
        "\n",
        "            if \"load_safety_checker\" in stetas_check:\n",
        "                self.stetas[\"load_safety_checker\"] = True\n",
        "\n",
        "\n",
        "\n",
        "        logger.debug(f\"steate: {self.stetas.keys()}\")\n",
        "        if \"from_pipe\" in dir(self.pipeline_class):\n",
        "            use_from_pipe = True\n",
        "        else:\n",
        "            use_from_pipe = False\n",
        "        if self.use_TPU:\n",
        "            if use_from_pipe:\n",
        "                if self.Filter_off:\n",
        "                    self.base_pipe.safety_checker = None\n",
        "                self.base_pipe.sheduler = self.stetas[\"scheduler\"]\n",
        "                self.base_pipe.vae = self.vae.to(torch.float16)\n",
        "                main_pipe = self.pipeline_class.from_pipe(self.base_pipe).to(dtype=jax.numpy.bfloat16)\n",
        "                for key,value in self.stetas.items():\n",
        "                    setattr(main_pipe,key,value)\n",
        "\n",
        "            else:\n",
        "                main_pipe = self.pipeline_class(**self.stetas,dtype=jax.numpy.bfloat16)\n",
        "\n",
        "        else:\n",
        "            if use_from_pipe:\n",
        "\n",
        "                if self.Filter_off:\n",
        "                    self.base_pipe.safety_checker = None\n",
        "                main_pipe = self.pipeline_class.from_pipe(self.base_pipe).to(self.device, torch.float16)\n",
        "                for key,value in self.stetas.items():\n",
        "                    setattr(main_pipe,key,value)\n",
        "            else:\n",
        "                main_pipe = self.pipeline_class(**self.stetas).to(self.device, torch.float16)\n",
        "\n",
        "\n",
        "\n",
        "        if hasattr(main_pipe.__class__,\"load_textual_inversion\"):\n",
        "            if \"EasyNegative\" not in main_pipe.tokenizer.get_vocab():\n",
        "                try:\n",
        "                    main_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                except Exception:\n",
        "                    logger.info(\"EasyNegativeの適用に失敗しました\")\n",
        "            if \"bad-hands\" not in main_pipe.tokenizer.get_vocab():\n",
        "                try:\n",
        "                    main_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                except Exception:\n",
        "                    logger.info(\"bad-handsの適用に失敗しました\")\n",
        "\n",
        "\n",
        "        if self.device == \"cpu\" and hasattr(self.pipeline_class,\"enable_model_cpu_offload\"):\n",
        "\n",
        "            main_pipe.enable_model_cpu_offload()\n",
        "\n",
        "        if hasattr(self.pipeline_class,\"fuse_qkv_projections\"):\n",
        "            #torch.compile -> bug\n",
        "            main_pipe.fuse_qkv_projections()\n",
        "\n",
        "        if self.device_type == \"TPU\":\n",
        "            main_pipe.to(dtype=jax.numpy.bfloat16)\n",
        "        else:\n",
        "            main_pipe.to(dtype=torch.float16)\n",
        "\n",
        "        return main_pipe\n",
        "\n",
        "MMP=make_main_pipe(pipe_name = pipe_type,\n",
        "                   Filter_off = Filter_off,\n",
        "                   Scheduler_select = Scheduler_select,\n",
        "                   vae_select = vae_select,\n",
        "                   auto = auto,\n",
        "                   base_pipe = base_pipe,\n",
        "                   parmer = parmer)\n",
        "main_pipe = MMP.main_pipe_set()\n",
        "\n",
        "\n",
        "\n",
        "class PipeSetUI:\n",
        "    def __init__(self):\n",
        "        self.del_key_list = [\n",
        "            \"self\", \"prompt\", \"prompt_ids\", \"negative_prompt\", \"neg_prompt\", \"device\",\n",
        "            \"guidance_scale\", \"num_inference_steps\", \"generator\", \"height\", \"width\", \"image\",\n",
        "            \"strength\", \"t0\", \"t1\", \"video_length\", \"num_frames\", \"prng_seed\", \"params\",\n",
        "            \"return_dict\", \"callback_on_step_end_tensor_inputs\",\"timesteps\", \"sigmas\"\n",
        "        ]\n",
        "        self.widgets_dict = {}\n",
        "\n",
        "    def display(self, pipeline, input_dict):\n",
        "        args_info = self.get_call_args_info(pipeline)\n",
        "        self.display_args(args_info, input_dict)\n",
        "\n",
        "    def get_call_args_info(self, pipeline):\n",
        "        if not hasattr(pipeline.__class__, '__call__'):\n",
        "            raise ValueError(\"pipeline does not have a __call__ method\")\n",
        "        else:\n",
        "            sig = inspect.signature(pipeline.__call__)\n",
        "\n",
        "        args_info = {}\n",
        "        for name, param in sig.parameters.items():\n",
        "            if param.kind in (param.VAR_POSITIONAL, param.VAR_KEYWORD):\n",
        "                continue\n",
        "\n",
        "            arg_info = {\n",
        "                'type': param.annotation if param.annotation != inspect.Parameter.empty else None,\n",
        "                'default': param.default if param.default != inspect.Parameter.empty else None\n",
        "            }\n",
        "            args_info[name] = arg_info\n",
        "        return args_info\n",
        "\n",
        "    def on_button_click(self, _):\n",
        "        for arg, widget in self.widgets_dict.items():\n",
        "            parameter_dict[arg] = widget.value if widget.value != 'None' else None\n",
        "        output.clear(output_tags=\"button_click_txt\")\n",
        "        with output.use_tags(\"button_click_txt\"):\n",
        "            sys.stdout.write(\"\\n\\033[34m----------------------\\n\")\n",
        "            sys.stdout.write(\"Updated parameter \\n\\n\")\n",
        "            for key, value in parameter_dict.items():\n",
        "                sys.stdout.write(f\"{key}: {value}\\n\\n\")\n",
        "                sys.stdout.flush();\n",
        "            sys.stdout.write(\"\\033[0m\")\n",
        "\n",
        "    def extract_union_options(self, union_type):\n",
        "        options = set()\n",
        "        for ut in union_type.__args__:\n",
        "            if hasattr(ut, '__origin__') and ut.__origin__ == Union:\n",
        "                options.update(self.extract_union_options(ut))\n",
        "            elif ut is type(None):\n",
        "                options.add('None')\n",
        "            elif isinstance(ut, type):\n",
        "                options.add(ut.__name__)\n",
        "            else:\n",
        "                options.add(str(ut))\n",
        "        return options\n",
        "\n",
        "    def display_args(self, args_info, input_dict):\n",
        "        widget_list=[]\n",
        "        for checked_key in list(args_info.keys()):\n",
        "            if checked_key in self.del_key_list:\n",
        "                del args_info[checked_key]\n",
        "\n",
        "        for arg, info in args_info.items():\n",
        "            if not isinstance(info[\"type\"], type):\n",
        "                arg_type = tuple(t for t in get_args(info[\"type\"]) if t is not type(None))\n",
        "                if len(arg_type) == 1:\n",
        "                    info[\"type\"] = arg_type[0]\n",
        "                else:\n",
        "                    info[\"type\"] = arg_type\n",
        "\n",
        "            if info['type'] == int:\n",
        "                widget = widgets.IntText(\n",
        "                    value=info['default'],\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == float:\n",
        "                widget = widgets.FloatText(\n",
        "                    value=info['default'],\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == str:\n",
        "                widget = widgets.Text(\n",
        "                    value=str(info['default']),\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            elif info['type'] == bool:\n",
        "                widget = widgets.Checkbox(\n",
        "                    value=info['default'] if isinstance(info['default'], bool) else True,\n",
        "                    description=arg,\n",
        "                    disabled=False,\n",
        "                )\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            self.widgets_dict[arg] = widget\n",
        "            widget_list.append(widget)\n",
        "            self.widgets_dict[arg] = widget\n",
        "\n",
        "        for widget in widget_list:\n",
        "            if isinstance(widget, (widgets.Text, widgets.IntText, widgets.FloatText)):\n",
        "                display(widget)\n",
        "\n",
        "        for widget in widget_list:\n",
        "            if isinstance(widget, widgets.Checkbox):\n",
        "                display(widget)\n",
        "\n",
        "        button = widgets.Button(description=\"Update Values\",button_style=\"info\")\n",
        "        button.on_click(self.on_button_click)\n",
        "        display(button)\n",
        "\n",
        "\n",
        "fin=True\n",
        "\n",
        "#\\033[31mが赤、\\033[33mが黄色、\\033[34mが青、\\033[32mが緑、\\033[0mが白\n",
        "# \"\\033[32m\" は緑色に変更するための\"ANSI Escape Code\"であり、\"\\033[0m\"はデフォルトの文字色に戻すためのコード。\n",
        "# \\033[38;2;0;255;255m　水色\n",
        "#\\033[38;2;74;229;110m　黄緑\n",
        "\n",
        "if main_pipe.dtype == torch.float16 and device_type == \"cpu\":\n",
        "    print(\"\\033[31mWarning: float16 pipeline is not available on CPU\\033[0m\")\n",
        "\n",
        "if Scheduler_select not in Scheduler_set().Special_Scheduler_dict:\n",
        "    warning_txt = \" or \".join(Scheduler_set().Special_Scheduler_dict.keys())\n",
        "    print(f'\\n\\nMoment is only valid if Scheduler_select is either {warning_txt}.\\n')\n",
        "\n",
        "if Filter_off == False:\n",
        "    filter_level = \"Filter: Enabled\"\n",
        "else:\n",
        "    filter_level = \"\\033[33mFilter: Disabled\\033[0m\"\n",
        "\n",
        "print(\"\\033[34m____________________________________________________________________________\\n\\n\")\n",
        "\n",
        "print(f\"model_path: {model_path}\"+\"\\n\\n\")\n",
        "\n",
        "print(f\"scheduler: {main_pipe.scheduler.__class__.__name__}\\n\\n\")\n",
        "\n",
        "if vae_select:\n",
        "    print(f\"vae_path: {MMP.vae_path}\\n\\n\")\n",
        "\n",
        "print(f\"pipeline_class: {main_pipe.__class__.__name__}\\n\\n\")\n",
        "\n",
        "print(filter_level+\"\\n\\n\")\n",
        "\n",
        "print(\"\\033[32mReady for generation\\033[0m\")\n",
        "\n",
        "\n",
        "parameter_dict = {}\n",
        "if set_extra_parameter:\n",
        "    print(\"\\n\\033[34m____________________________________________________________________________\\n\")\n",
        "    print(\"Extra parameter\\033[0m\")\n",
        "    PipeSetUI().display(main_pipe.__class__, parameter_dict)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONEtEJyRGYSL"
      },
      "source": [
        "#Option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmpMRkz2QOyP"
      },
      "outputs": [],
      "source": [
        "#@title  (option) Load Lora{display-mode: \"form\"}\n",
        "\n",
        "model_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "# #@param [\"hugface\",\"civitai\"]\n",
        "\n",
        "auto = False # @param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "    import peft\n",
        "except ImportError:\n",
        "    !pip install -q peft\n",
        "    import peft\n",
        "\n",
        "LORA_dict=pipe_set.model_set(model_select=model_name,\n",
        "                             auto=auto,\n",
        "                             model_type=\"LORA\",\n",
        "                             download=True)\n",
        "LORA_PATH = LORA_dict[\"model_path\"]\n",
        "try:\n",
        "    main_pipe.load_lora_weights(LORA_PATH)\n",
        "except:\n",
        "    raise ValueError(\"Failed to load LORA\")\n",
        "\n",
        "print(\"\\033[32mLoraのロードに成功しました\\033[0m\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KBSJk1kqN3Z"
      },
      "outputs": [],
      "source": [
        "#@title   (option)埋め込みを適用 {display-mode: \"form\"}\n",
        "#@markdown >埋め込みを適用\n",
        "Repo_id_or_path = \"/root/.cache/huggingface/hub/models--JosefJilek--loliDiffusion/snapshots/806b8476aa4411058400500a8bd028a83221854a/loliDiffusionV0.14.0_AOM2-SFW_1.0M6-CLIP_VAE_FP16.safetensors\" # @param {type:\"string\"}\n",
        "weight_name= \"\" # @param {type:\"string\"}\n",
        "token = \"flanses\" # @param {type:\"string\"}\n",
        "\n",
        "#NEW\n",
        "\n",
        "Loaded_from = \"local\" # @param [\"hugface\", \"civitai\", \"local\"]\n",
        "\n",
        "class textual(pipeline_setup):\n",
        "    def __init__(self,\n",
        "                 pretrained_path,\n",
        "                 weight_name,\n",
        "                 token,\n",
        "                 main_pipe):\n",
        "        self.pretrained_path = pretrained_path\n",
        "        self.weight_name = weight_name\n",
        "        self.token = token\n",
        "        self.main_pipe = main_pipe\n",
        "\n",
        "    def load_textual(self):\n",
        "        state={\"pretrained_model_name_or_path\": self.pretrained_path,\n",
        "               \"token\": self.token}\n",
        "        if self.token in self.main_pipe.tokenizer.get_vocab():\n",
        "            raise ValueError(\"適用済みのトークンの為、別のトークンの入力をお願いします\")\n",
        "        elif os.path.isfile(self.pretrained_path):\n",
        "            pass\n",
        "            #state[\"weight_name\"]=weight_name\n",
        "        else:\n",
        "            embed_path = self.model_set(self.pretrained_path,\"TextualInversion\",auto=False)\n",
        "            #state[\"weight_name\"] = self.weight_name\n",
        "\n",
        "        self.main_pipe.load_textual_inversion(**state)\n",
        "        print(f\"カスタムトークン: {','.join(token_list)}\\n\")\n",
        "\n",
        "text_c=textual(Repo_id_or_path,weight_name,token,main_pipe,loaded_textual_list)\n",
        "#ct=text_cadd_textual(Repo_id_or_path,weight_name,token,main_pipe)\n",
        "text_c.load_textual(Repo_id_or_path,weight_name,token,main_pipe,loaded_textual_list)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIH-0uIGiw7"
      },
      "source": [
        "#main step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXSW3nl8UT7x",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title  #Step.4  Generation_Step{display-mode: \"form\"}\n",
        "\n",
        "##@markdown ># Basic Config\n",
        "\n",
        "# @markdown >Basic Status\n",
        "\n",
        "\n",
        "prompt = \"smail,girl, white hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\" # @param [\"smail,girl, white hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\", \"smail,1girl, {white,blue,red,purple} hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress,loli\", \"Please draw a beautiful Mount Fuji with the sun rising from the summit\", \"Earth, space, high resolution\"] {allow-input: true}\n",
        "\n",
        "negative_prompt = \"logo,text\"  # @param {type:\"string\"}\n",
        "\n",
        "seed = -1 # @param {type:\"number\"}\n",
        "\n",
        "num_imgs = 3 # @param {type:\"integer\"}\n",
        "\n",
        "input_image_path_or_dir = \"\" # @param {type:\"string\"}\n",
        "\n",
        "guidance_scale = 6.5 # @param {type:\"slider\", min:5, max:15, step:0.5}\n",
        "\n",
        "\n",
        "# @markdown >Special Status\n",
        "\n",
        "\n",
        "num_inference_steps = 30  # @param {type:\"integer\"}\n",
        "height = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\",\"1920\", \"3840\",\"4000\",\"7680\"] {allow-input: true}\n",
        "width = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\", \"1920\", \"3840\",\"4000\",\"7680\"] {allow-input: true}\n",
        "\n",
        "text_generate_model = \"gpt2-prompt-generator\" #@param [\"None\",\"MagicPrompt-Stable-Diffusion\",\"anime-anything-promptgen-v2\",\"gpt2-prompt-generator\"]\n",
        "\n",
        "\n",
        "grit_image_width = 0 # @param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown * If 0, it will not be created.\n",
        "\n",
        "# @markdown >output config\n",
        "\n",
        "save_dir = \"\" # @param [\"/content/drive/MyDrive/\"] {allow-input: true}\n",
        "#save_path = 保存する先のパス.strip()\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown > video config\n",
        "\n",
        "video_length = 10 # @param {type:\"integer\"}\n",
        "\n",
        "video_fps = 10 # @param {type:\"integer\"}\n",
        "\n",
        "num_frames = 9 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown >Sonar config\n",
        "momentum = 0.9 # @param {type:\"slider\", min:0.8, max:1, step:0.05}\n",
        "\n",
        "momentum_hist = -0.1 # @param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "\n",
        "history_d = \"rand_init\" # @param [\"rand_new\", \"rand_init\"]\n",
        "\n",
        "# @markdown >Option\n",
        "Recommended_setting = True #@param {type:\"boolean\"}\n",
        "\n",
        "show_result = True  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "Hide_warnings = True #@param {type:\"boolean\"}\n",
        "\n",
        "#グリッド画像を表示 = True  # @param {type:\"boolean\"}\n",
        "#画像情報を表示 = True  # @param {type:\"boolean\"}\n",
        "#条件をメタデーターとして追加する = True  # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#NP制限トークン数拡大 = True #@param {type:\"boolean\"}\n",
        "\n",
        "#日本語入力 = False #@param {type:\"boolean\"}\n",
        "#JP_INPUT=日本語入力\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if (Recommended_setting and\n",
        " (momentum-momentum_hist)<=0.3 and\n",
        " (Scheduler_select==\"EulerA+OP\" or Scheduler_select==\"Euler+OP\")):\n",
        "        momentum_hist=momentum-0.3\n",
        "        print(f\"momentum_histとmomentumの差が3以下のためmomentum_histを'{momentum_hist}' に設定しました。\\nこの処理は、'推奨設定'に付属している機能です\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class mod_config:\n",
        "    Hide_warnings = Hide_warnings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if (not Recommended_setting) and (not Hide_warnings):\n",
        "    print('\\033[33mRecommended_setting is off')\n",
        "\n",
        "\n",
        "\n",
        "def run_html_js(path,moji):\n",
        "    import datetime\n",
        "    num=len(path)\n",
        "    now_a = datetime.datetime.now()\n",
        "    datetimes = now_a.strftime(\"%Y%m%d%H%M%S\")\n",
        "    html_dis = f'''\n",
        "    <style>\n",
        "      #clipborad-text-{datetimes} {{\n",
        "        border: none;\n",
        "        color: #0ff;\n",
        "        font-size: 15px;\n",
        "      }}\n",
        "    </style>\n",
        "    <span style=\"color: #4ae56e\" font-size:16px>{moji}</span> <!-- <p>タグを<span>タグに変更 -->\n",
        "    <input type=\"text\" value=\"{path}\" id=\"clipborad-text-{datetimes}\" size=\"{num}\" readonly> <!-- size属性とid属性を追加 -->\n",
        "    <button id=\"copy-button-{datetimes}\" onclick=\"copyToClipboard('{datetimes}')\">Copy</button> <!-- id属性とonclick属性を追加 -->\n",
        "    '''\n",
        "    js_code = '''\n",
        "    function copyToClipboard(datetimes) {\n",
        "      var copyText = document.getElementById(\"clipborad-text-\" + datetimes); // datetimeを結合\n",
        "      var copyButton = document.getElementById(\"copy-button-\" + datetimes); // datetimeを結合\n",
        "      copyText.select();\n",
        "      navigator.clipboard.writeText(copyText.value);\n",
        "      document.execCommand(\"copy\");\n",
        "      copyButton.textContent = \"Copied!\"; // ボタンの文字を変更\n",
        "      setTimeout(function() {\n",
        "        copyButton.textContent = \"Copy\"; // 1秒後に元に戻す\n",
        "        }, 1000);\n",
        "    }\n",
        "    '''\n",
        "    display(HTML(html_dis))\n",
        "    display(HTML('<script>{}</script>'.format(js_code)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Scheduler_setup(make_main_pipe):\n",
        "    def __init__(self,main_pipe):\n",
        "        self.main_pipe=main_pipe\n",
        "\n",
        "    def moment_set(self,Scheduler_select):\n",
        "        if Scheduler_select in self.Special_Scheduler_dict:\n",
        "            self.main_pipe.scheduler.history_d =history_d\n",
        "            self.main_pipe.scheduler.momentum = momentum\n",
        "            self.main_pipe.scheduler.momentum_hist = momentum_hist\n",
        "\n",
        "sc_set=Scheduler_setup(main_pipe)\n",
        "sc_set.moment_set(Scheduler_select)\n",
        "\n",
        "\n",
        "class txt_model_setup(basic_config,\n",
        "                      mod_config):\n",
        "    def __init__(self,\n",
        "                 base_prompt,\n",
        "                 n_prompt,\n",
        "                 num_imgs,\n",
        "                 text_generate_model,\n",
        "                 main_pipe,\n",
        "                 Recommended_setting):\n",
        "        #global Prompt_list , make_images_list\n",
        "        #self.use_TPU=use_TPU\n",
        "        super().__init__()\n",
        "        self.prompt_list=[]\n",
        "        self.num_imgs = num_imgs\n",
        "        self.base_prompt = base_prompt\n",
        "        self.n_prompt = n_prompt\n",
        "        self.text_generate_model = text_generate_model\n",
        "        self.main_pipe = main_pipe\n",
        "        self.Recommended_setting = Recommended_setting\n",
        "\n",
        "        self.good_word = \"masterpiece:2.0,best quality,high quality,\"\n",
        "\n",
        "        self.SP_word_dict = {\"<color>\":[\"Red\",\"Blue\",\"green\",\"yellow\",\"orange\",\"purple\",\"pink\",\"brown\",\"gray\",\"black\",\"white\",]\n",
        "                             }\n",
        "\n",
        "\n",
        "\n",
        "    def txt_pipe(self,text_generate_model):\n",
        "        global gl_txt_pipe\n",
        "        if \"gl_txt_pipe\" not in globals():\n",
        "            raise ValueError(\"Please perform step.1 again\")\n",
        "        else:\n",
        "            gl_txt_pipe = globals()[\"gl_txt_pipe\"]\n",
        "\n",
        "        txt_pipe_dict={\"MagicPrompt-Stable-Diffusion\":\"Gustavosta/MagicPrompt-Stable-Diffusion\",\n",
        "                       \"anime-anything-promptgen-v2\":\"FredZhang7/anime-anything-promptgen-v2\",\n",
        "                       \"gpt2-prompt-generator\":\"Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator\",\n",
        "                       \"None\":\"None\"}\n",
        "\n",
        "        assert text_generate_model in txt_pipe_dict , f\"text_generate_model: {text_generate_model}\"\n",
        "\n",
        "        txt_model_name = txt_pipe_dict[text_generate_model]\n",
        "\n",
        "        logger.debug(f\"gl_txt_pipe: {gl_txt_pipe}\")\n",
        "\n",
        "        if (not txt_model_name == \"None\") and (gl_txt_pipe is None or self.key_check(txt_model_name) == False):\n",
        "            if self.use_TPU:\n",
        "                txt_model = FlaxAutoModelForCausalLM.from_pretrained(txt_model_name)\n",
        "            else:\n",
        "                txt_model = AutoModelForCausalLM.from_pretrained(txt_model_name).to(self.device)\n",
        "            txt_tokenizer = AutoTokenizer.from_pretrained(txt_model_name)\n",
        "            gl_txt_pipe = pipeline('text-generation', model = txt_model, tokenizer = txt_tokenizer, device = self.device, pad_token_id=50256)\n",
        "        return gl_txt_pipe\n",
        "\n",
        "    def sp_word_replace(self,base_prompt):\n",
        "        for sp_key, sp_value in self.SP_word_dict.items():\n",
        "            for co in base_prompt:\n",
        "                if isinstance(sp_value, list):\n",
        "                    sp_value = random.choice(sp_value)\n",
        "                base_prompt = re.sub(sp_key, sp_value, base_prompt, count=1)\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "\n",
        "    def convert_special_word(self,base_prompt):\n",
        "        base_prompt = self.sp_word_replace(base_prompt)\n",
        "        contents = re.findall(\"\\\\{(.*?)\\\\}\", base_prompt)\n",
        "        #count = 0\n",
        "\n",
        "\n",
        "        for count, content in enumerate(contents):\n",
        "            if not content or len(content) == 0:\n",
        "                continue\n",
        "            lst = content.split(\",\")\n",
        "            choice = random.choice(lst)\n",
        "            base_prompt = re.sub(\"\\\\{.*?\\\\}\", choice, base_prompt, count=1)\n",
        "            #count += 1\n",
        "        return base_prompt\n",
        "\n",
        "\n",
        "\n",
        "    def prompt_pipe_convert(self,prompt):\n",
        "        n_word=[\"EasyNegative\",\"bat_hands\",\"white background\",\" simple background\",\"  simple background\",\"Loss of eye highlights\",\"freckles\",\"simple background\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"bad hands\",\"bad legs\",\"worst quality\",\"low quality\",\"Not five fingers\",\"blurred\",\"Missing finger\",\"Simple background\",\"Cat with deformed face\",\"medium quality\",\"purple hair\",\"Loss of eye highlights\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"deleted\",\"lowres\",\"Low quality animals\",\"deformed animals\",\"hands emerging from impossible places\",\"bad anatomy\",\"more than three limbs hands/legs\",\"low resolution\",\"blurry\",\"absurdres\",\"pixelated\",\"sketchy\",\"nonsensical anatomy\",\"unrealistic pose\",\"mosaic\",\"unclear details\",\"distorted colors\",\"unrealistic proportions\",\"poor quality\",\"fuzzy\",\"missing head:1.6\",\"out of focus\",\"hazy\",\"grainy\",\"text\",\"error\",\"missing fingers:0.9\",\"extra digit\",\"fewer digits\",\"cropped\",\"jpeg artifacts\",\"signature\",\"watermark\",\"username\",\"standard quality\",\"bad feet_hand_finger_leg_eye\",\"bad\",\"text font ui\",\"bad shadow\",\"poorly drawn\",\"black-white\",\"ugly\",\"duplicate\",\"mutation\",\"mutilated\",\"malformed mutated:1.1\",\"malformed:1.1\",\"The background is incoherent\",\"simple background\",\"low-quality background\",\"low background\",\"bad body\",\"long body\",\"broken limb\",\"anatomical nonsense\",\"extra limbs\",\"missing limb\",\"incorrect limb\",\"multiple heads\",\"twisted head\",\"poorly drawn face\",\"1 unit with multiple heads:1.3\",\"heads together:1.0\",\"abnormal eye:1.2 proportion\",\"cropped:1.0\",\"bad eyes\",\"fused eyes\",\"poorly drawn eyes\",\"bad mouth\",\"poorly drawn mouth\",\"bad tongue\",\"too long tongue\",\"bad ears\",\"poorly drawn ears\",\"extra ears\",\"heavy ears\",\"long neck\",\"too thick neck\",\"bad neck\",\"bad breasts\",\"missing arms\",\"disappearing arms\",\"extra arms\",\"three arms:2.0\",\"mutated hands and fingers\",\"fused hand\",\"missing fingers\",\"extra digits\",\"huge thighs\",\"disappearing thigh\",\"missing thighs\",\"extra thighs\",\"bad feet\",\"huge calf\",\"disappearing legs\",\"bad gloves\",\"fused gloves\",\"beard\",\"artist name\",\"text watermark\",\"unnatural\",\"obviously wrong\",\"distorted face\",\"floating hair\",\"floating body parts\",\"severed body parts\",\"incorrect leg position\",\"deformed\",\"fused body and hands\",\"disregard of physics\",\"distorted shape\",\"doll-like object not present in the image\",\"body fusion\",\"abnormal fingers\",\"fingers resembling fish fins\",\"dot eyes\",\"unclear background\",\"mosaic\",\"body bending\",\"incorrect leg-to-torso ratio\",\"excessively large breasts\",\"unsettling appearance\",\"eyes filled with solid color\",\"lack of lower body\",\"splitting\",\"creepy doll-like appearance\",\"distorted eyes\",\"lines on the skin\",\"legs bending in unnatural directions\",\"abnormal finger count\",\"missing arms\",\"floating hands\",\"lack of nose or mouth\",\"incorrect body part ratios\",\"bad\",\"longbody\",\"lowres\",\"bad anatomy\",\"bad hands\",\"missing fingers\",\"Distorted eye contour\",\"Missing part from the ankles onward\",\"extra digit\",\"fewer digits\",\"split wings\",\"Vampire wings floating in the air\",\"bad wing\",\"wonder egg priority\",\"egg priority\",\"demon\"]\n",
        "        if self.n_prompt:\n",
        "            words =self.n_prompt.split(\",\")\n",
        "            n_word.extend(words)\n",
        "        if self.Recommended_setting:\n",
        "            max_length=64\n",
        "        else:\n",
        "            max_length=74\n",
        "\n",
        "        gl_txt_pipeline = self.txt_pipe(self.text_generate_model)\n",
        "\n",
        "        converted_prompt = gl_txt_pipeline(prompt,\n",
        "                                           max_length=max_length,\n",
        "                                           truncation=True,\n",
        "                                           num_return_sequences=10,\n",
        "                                           repetition_penalty=1.2,\n",
        "                                           early_stopping=False,\n",
        "                                           do_sample=True,\n",
        "                                           temperature=0.4,\n",
        "                                           top_k=10)\n",
        "\n",
        "        converted_prompt = converted_prompt[0]['generated_text']\n",
        "        return converted_prompt\n",
        "\n",
        "\n",
        "\n",
        "    def prompt_converting(self,base_prompt):\n",
        "        sp_word_converted = self.convert_special_word(base_prompt)\n",
        "\n",
        "        if not self.text_generate_model == \"None\":\n",
        "            sp_word_converted = self.prompt_pipe_convert(sp_word_converted)\n",
        "\n",
        "        return_prompt = re.sub(r\",+\", \",\", sp_word_converted)\n",
        "        return return_prompt\n",
        "\n",
        "\n",
        "    def Flax_prompt(self,prompt):\n",
        "        #print(prompt)\n",
        "        num_samples = jax.device_count()\n",
        "        prompt = num_samples * [prompt]\n",
        "        prompt_ids = self.main_pipe.prepare_inputs(prompt)\n",
        "        prompt_ids = shard(prompt_ids)\n",
        "        return prompt_ids\n",
        "\n",
        "\n",
        "\n",
        "    def prompt_processing(self,base_prompt,output_list):\n",
        "        if self.pipeline_type == \"txt2video\":\n",
        "            logger.debug(\"set num_imgs = 1\")\n",
        "            self.num_imgs = 1\n",
        "\n",
        "        for number in range(self.num_imgs):\n",
        "            converted_prompt = self.prompt_converting(base_prompt)\n",
        "            #ここをどうにかする\n",
        "            if self.Recommended_setting:\n",
        "                converted_prompt = self.good_word + converted_prompt\n",
        "            if self.use_TPU:\n",
        "                #print(\"do\")\n",
        "                #print(converted_prompt)\n",
        "                converted_prompt = self.Flax_prompt(converted_prompt)\n",
        "            output_list.put(converted_prompt)\n",
        "            #logger.debug(f\"run :{converted_prompt}\")\n",
        "\n",
        "\n",
        "    def use_over_token(self,PROMPT,pipe):\n",
        "        max_length = pipe.tokenizer.model_max_length\n",
        "        input_ids = pipe.tokenizer(PROMPT, return_tensors=\"pt\").input_ids\n",
        "        input_ids = input_ids.to(\"cuda\")\n",
        "\n",
        "        negative_ids = pipe.tokenizer(\"\", truncation=False, padding=\"max_length\", max_length=input_ids.shape[-1], return_tensors=\"pt\").input_ids\n",
        "        negative_ids = negative_ids.to(\"cuda\")\n",
        "\n",
        "        concat_embeds = []\n",
        "        neg_embeds = []\n",
        "        for i in range(0, input_ids.shape[-1], max_length):\n",
        "            concat_embeds.append(pipe.text_encoder(input_ids[:, i: i + max_length])[0])\n",
        "            neg_embeds.append(pipe.text_encoder(negative_ids[:, i: i + max_length])[0])\n",
        "\n",
        "        #prompt_embeds = torch.cat(concat_embeds, dim=1)\n",
        "        negative_prompt_embeds = torch.cat(neg_embeds, dim=1)\n",
        "        return negative_prompt_embeds\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class generate_config(basic_config,\n",
        "                      mod_config):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.png_num = 0\n",
        "        self.mp_num = 0\n",
        "\n",
        "    def find_max_num(self,\n",
        "                     base_file_name,\n",
        "                     directory,\n",
        "                     ext):\n",
        "        max_num = 0\n",
        "        pattern = re.compile(f\"{base_file_name}-(\\\\d+)\\\\.{ext}\")\n",
        "        for filename in os.listdir(directory):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            if os.path.isfile(filepath):\n",
        "                match = pattern.match(filename)\n",
        "                if match:\n",
        "                    z = int(match.group(1))\n",
        "                    max_num = max(max_num, z)\n",
        "        return max_num\n",
        "\n",
        "    def image_grid(self,\n",
        "                   imgs :list,\n",
        "                   cols : int):\n",
        "        \"\"\"\n",
        "        cols: width\n",
        "        \"\"\"\n",
        "        all_num=len(imgs)\n",
        "        if all_num<cols:\n",
        "            cols=all_num\n",
        "        if all_num>1:\n",
        "            am=0\n",
        "            w, h = imgs[0].size\n",
        "            rows,b= divmod(all_num,cols)\n",
        "            if b!=0:\n",
        "                rows+=1\n",
        "                am=cols-b\n",
        "                white_img = Image.new(\"RGB\", (w,h), (255, 255, 255))\n",
        "                for x in range(am):\n",
        "                    imgs.append(white_img)\n",
        "            grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "            grid_w, grid_h = grid.size\n",
        "            for i, img in enumerate(imgs):\n",
        "                grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "        elif all_num==1:\n",
        "            grid=None\n",
        "            if self.make_grid:\n",
        "                print(\"画像が1枚のためグリッド画像化できません\")\n",
        "        else:\n",
        "            grid=None\n",
        "            if self.make_grid:\n",
        "                print(\"グリッド画像に使用可能な画像がありません。\")\n",
        "        return grid\n",
        "\n",
        "\n",
        "    def get_save_path(self,\n",
        "                      saved_path,\n",
        "                      result_type=\"image\"):\n",
        "        \"\"\"\n",
        "        args:\n",
        "        result_type = [image,video,music]\n",
        "        \"\"\"\n",
        "        dir_type = {\"image\":\"Images\",\n",
        "                    \"video\":\"Video\",\n",
        "                    \"music\":\"Music\",}\n",
        "        make_dir_name = dir_type[result_type]\n",
        "\n",
        "        if not saved_path:\n",
        "            #あとで直す\n",
        "            saved_path = \"/content/Generated\"\n",
        "            if not self.Hide_warnings:\n",
        "                print(f\"The directory to save to has not been entered yet, so save to the following path: {saved_path}\")\n",
        "        elif not self.conect_gdrive:\n",
        "            if \"/content/drive/MyDrive\" in saved_path:\n",
        "                saved_path = \"/content/Generated\"\n",
        "                if not self.Hide_warnings:\n",
        "                    print(f\"\\033[31mSince Google Drive is not mounted, save to the following path: {saved_path}\\033[0m\")\n",
        "\n",
        "        image_save_dir = os.path.join(saved_path,make_dir_name)\n",
        "        os.makedirs(image_save_dir, exist_ok=True)\n",
        "        if result_type == \"image\":\n",
        "            Grid_save_dir = os.path.join(saved_path,\"Grid\")\n",
        "            os.makedirs(Grid_save_dir, exist_ok=True)\n",
        "            base_file_name =\"genrated_grid\"\n",
        "            grid_num = self.find_max_num(\n",
        "                              base_file_name = base_file_name,\n",
        "                              directory = Grid_save_dir,\n",
        "                              ext=\"png\"\n",
        "                              )\n",
        "            Grid_save_path = os.path.join(Grid_save_dir,f\"{base_file_name}-{grid_num+1}.png\")\n",
        "        else:\n",
        "            Grid_save_path= \"\"\n",
        "\n",
        "\n",
        "        return image_save_dir , Grid_save_path\n",
        "\n",
        "    def seed_set(self,seed_number):\n",
        "        Flax_seed=None\n",
        "        if seed_number==-1 or seed_number is None:\n",
        "            seed = random.randint(1,1000000)\n",
        "        else:\n",
        "            seed=seed_number\n",
        "        if self.use_TPU:\n",
        "            Flax_seed=jax.random.split(jax.random.PRNGKey(seed), jax.device_count())\n",
        "        else:\n",
        "            Flax_seed=None\n",
        "        return seed,Flax_seed\n",
        "\n",
        "    def img_set(self,path,height,width)->list:\n",
        "        #↓counter-measure: AttributeError: 'str' object has no attribute 'seek'\n",
        "        init_image_list=[]\n",
        "        def img_open(path,height,width):\n",
        "            _init_image = Image.open(path)\n",
        "            _init_image = _init_image.resize((height, width))\n",
        "            return _init_image\n",
        "\n",
        "        if os.path.isfile(path):\n",
        "            init_image = img_open(path,height,width)\n",
        "            init_image_list.append(init_image)\n",
        "        else:\n",
        "            _ext = [\".jpg\",\".png\"]\n",
        "            #files = glob.glob(f\"{path}/*\")\n",
        "            files = Path(path)\n",
        "            file_paths = [str(file_path) for file_path in files.iterdir() if file_path.is_file()]\n",
        "            for file_path in file_paths:\n",
        "                if file_path.endswith in _ext:\n",
        "                    init_image = img_open(path,height,width)\n",
        "                    init_image_list.append(init_image)\n",
        "        logger.debug(f\"init_image_list: {init_image_list}\")\n",
        "        if not init_image_list:\n",
        "            raise FileNotFoundError(\"No image\")\n",
        "        return init_image_list\n",
        "\n",
        "    def n_prompt_set(self,base_negative_prompt=\"\"):\n",
        "        add_n_prompt = \"Loss of eye :1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0,bad hands:2.0,bad legs:2.0,EasyNegative,bat_hands:1.3,worst quality:2.0, low quality:2.0,Fused fingers,7 fingers, 6 fingers, 4 fingers, 3 fingers,Not five fingers:2.0,blurred,Simple_background:2.0,Missing finger:1.7,Cat with deformed face:1.3 ,medium quality, purple hair,Loss of eye highlights:1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0 ,deleted:0.5, lowres,Low quality animals, deformed animals ,hands emerging from impossible places:1.7, bad anatomy, more than three limbs hands/legs:1.5, low resolution, blurry, absurdres,pixelated, sketchy, nonsensical anatomy, unrealistic pose, mosaic, unclear details, distorted colors, unrealistic proportions, poor quality, fuzzy, missing head:1.6, out of focus, hazy, grainy, text, error, missing fingers:0.9, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, standard quality, bad feet_hand_finger_leg_eye, bad, text font ui, bad shadow, poorly drawn, black-white, ugly, duplicate, mutation, mutilated, malformed mutated:1.1, malformed:1.1, The background is incoherent, simple background, low-quality background, low background, bad body, long body, broken limb, anatomical nonsense, extra limbs, missing limb, incorrect limb, multiple heads, twisted head, poorly drawn face, 1 unit with multiple heads:1.3, heads together:1.0, abnormal eye:1.2 proportion, cropped:1.0, bad eyes, fused eyes, poorly drawn eyes, bad mouth, poorly drawn mouth, bad tongue, too long tongue, bad ears, poorly drawn ears, extra ears, heavy ears, long neck, too thick neck, bad neck,  bad breasts, missing arms, disappearing arms, extra arms, three arms:2.0, mutated hands and fingers, fused hand, missing fingers, extra digits, huge thighs, disappearing thigh, missing thighs, extra thighs, bad feet, huge calf, disappearing legs, bad gloves, fused gloves, beard, artist name, text watermark, unnatural, obviously wrong, distorted face, floating hair, floating body parts, severed body parts, incorrect leg position, deformed, fused body and hands, disregard of physics, distorted shape, doll-like object not present in the image, body fusion, abnormal fingers, fingers resembling fish fins, dot eyes, unclear background, mosaic, body bending, incorrect leg-to-torso ratio, excessively large breasts, unsettling appearance, eyes filled with solid color, lack of lower body, splitting, creepy doll-like appearance, distorted eyes, lines on the skin, legs bending in unnatural directions, abnormal finger count, missing arms, floating hands, lack of nose or mouth,, incorrect body part ratios, bad, longbody, lowres, bad anatomy, bad hands, missing fingers,  Distorted eye contour, Missing part from the ankles onward, extra digit, fewer digits, split wings, Vampire wings floating in the air, bad wing, comic,chainsaw man,demon, simple background\"\n",
        "        if self.Recommended_setting:\n",
        "            #if base_negativev_prompt.endswith(\",\"):\n",
        "            base_negative_prompt = base_negative_prompt + add_n_prompt\n",
        "        elif not self.Hide_warnings:\n",
        "            print('\\033[33mself.Recommended_setting is off\\033[0m')\n",
        "\n",
        "        return re.sub(r\",+\", \",\", base_negative_prompt)\n",
        "\n",
        "\n",
        "\n",
        "    def play_mp4(self,path_new):\n",
        "        mp4 = open(path_new, 'rb').read()\n",
        "        data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "        HTML_code=(f\"\"\"\n",
        "                   <video width=\"70%\" height=\"70%\" controls>\n",
        "                         <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "                   </video>\"\"\")\n",
        "        try:\n",
        "            display(HTML(HTML_code))\n",
        "        except:\n",
        "            display(HTML('<script>{}</script>'.format(HTML_code)))\n",
        "\n",
        "\n",
        "\n",
        "class generate_class(make_main_pipe,\n",
        "                     txt_model_setup,\n",
        "                     generate_config):\n",
        "    def __init__(self,\n",
        "                 base_prompt,\n",
        "                 base_negative_prompt,\n",
        "                 base_seed,\n",
        "                 num_imgs,\n",
        "                 height,\n",
        "                 width,\n",
        "                 num_inference_steps,\n",
        "                 guidance_scale,\n",
        "                 grit_image_width,\n",
        "                 Recommended_setting,\n",
        "                 image_save_dir,\n",
        "                 save_file_name,\n",
        "                 input_img_dir_or_path,\n",
        "                 model_name,\n",
        "                 main_pipe,\n",
        "                 parmer,\n",
        "                 video_length,\n",
        "                 num_frames,\n",
        "                 video_fps ,\n",
        "                 show_result,\n",
        "                 Hide_warnings,\n",
        "                 extra_parameter_dict):\n",
        "\n",
        "        #basic_config().__init__()\n",
        "\n",
        "        txt_model_setup.__init__(self,\n",
        "                                 base_prompt = base_prompt,\n",
        "                                 n_prompt = base_negative_prompt,\n",
        "                                 num_imgs = num_imgs,\n",
        "                                 text_generate_model = text_generate_model,\n",
        "                                 main_pipe = main_pipe,\n",
        "                                 Recommended_setting = Recommended_setting)\n",
        "\n",
        "\n",
        "        self.base_prompt = base_prompt\n",
        "        self.base_negative_prompt = base_negative_prompt\n",
        "        self.base_seed = base_seed\n",
        "        self.num_imgs = num_imgs\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.guidance_scale = guidance_scale\n",
        "        self.num_inference_steps = num_inference_steps\n",
        "        self.grit_image_width = grit_image_width\n",
        "        self.Recommended_setting = Recommended_setting\n",
        "        self.image_save_dir = image_save_dir\n",
        "        self.save_file_name = save_file_name\n",
        "        self.input_img_dir_or_path = input_img_dir_or_path\n",
        "        self.model_name = model_name\n",
        "        self.main_pipe = main_pipe\n",
        "        self.parmer = parmer\n",
        "        self.video_length = video_length\n",
        "        self.num_frames = num_frames\n",
        "        self.video_fps = video_fps\n",
        "        self.extra_parameter_dict = extra_parameter_dict\n",
        "\n",
        "        self.negative_prompt = self.n_prompt_set(base_negative_prompt)\n",
        "        self.pipeline_name = main_pipe.__class__.__name__\n",
        "        self.pipeline_class = self.pipeline_class_set(self.pipeline_name)\n",
        "        self.pipeline_type = self.pipe_class_type(self.pipeline_name)\n",
        "        self.pipeline_call_method = self.get_call_method(self.pipeline_name,\"__call__\")\n",
        "        if not self.use_TPU:\n",
        "            self.generator = torch.Generator(self.device)\n",
        "        else:\n",
        "            self.generator = None\n",
        "        self.stop_flag = threading.Event()\n",
        "        if self.grit_image_width == 0:\n",
        "            self.make_grid = False\n",
        "        else:\n",
        "            self.make_grid = True\n",
        "\n",
        "        self.pipeline_type = self.pipe_class_type(self.pipeline_name)\n",
        "        if self.pipeline_type == \"txt2video\":\n",
        "            self.make_video = True\n",
        "            self.num_imgs = 1\n",
        "            self.result_type = \"video\"\n",
        "        else:\n",
        "            self.make_video = False\n",
        "            self.result_type = \"image\"\n",
        "\n",
        "        self.prompt_list = queue.Queue()\n",
        "        self.make_images_list = queue.Queue()\n",
        "        self.total_generate_time = 0\n",
        "        self.base_generate_number = 1\n",
        "        self.generation_time_average = 0\n",
        "        self.pipeline_name = main_pipe.__class__.__name__\n",
        "        self.image_save_base_dir = \"\"\n",
        "        self.gird_save_base_dir = \"\"\n",
        "        self.gird_save_path = \"\"\n",
        "        self.prompt_process = None\n",
        "        self.generate_process = None\n",
        "        self.save_and_show_process = None\n",
        "        self.nsfw_detected = None\n",
        "        self.sp_output_module = None\n",
        "        self.grid_imgs=[]\n",
        "        self.call_dict={}\n",
        "\n",
        "        \"---module---\"\n",
        "        self.show_result = show_result\n",
        "        self.Hide_warnings = Hide_warnings\n",
        "\n",
        "    \"\"\"\n",
        "    def __del__(self):\n",
        "        try:\n",
        "            self.prompt_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "        try:\n",
        "            self.generate_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "        try:\n",
        "            self.save_and_show_process.join(timeout=0)\n",
        "        except (RuntimeError,AttributeError):\n",
        "            pass\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save_path_set(self,\n",
        "                      base_file_name,\n",
        "                      image_save_dir,\n",
        "                      is_images : bool,\n",
        "                      Prompt = \"\",\n",
        "                      seed = 0\n",
        "                      ):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        is_images:When true, returns the path to image generation\n",
        "                  when false, returns the path to video generation\n",
        "        Format:\n",
        "        <base_file_name>-<num>.png\n",
        "        \"\"\"\n",
        "        if base_file_name==\"\":\n",
        "            if is_images:\n",
        "                base_file_name = \"GIMG\"\n",
        "            else:\n",
        "                base_file_name = \"Gvideo\"\n",
        "\n",
        "        if is_images:\n",
        "            extension = \"png\"\n",
        "        else:\n",
        "            extension = \"mp4\"\n",
        "\n",
        "        now = datetime.datetime.now()\n",
        "        path_d = {\"{prompt}\": Prompt,\n",
        "                  \"{seed}\": seed,\n",
        "                  \"{model_name}\": self.model_name,\n",
        "                  \"{g_scale}\": self.guidance_scale,\n",
        "                  \"{time}\":now}\n",
        "        for key, value in path_d.items():\n",
        "            base_file_name = base_file_name.replace(key, str(value))\n",
        "        #NOTE: This function returns the maximum number, so the file will be overwritten if 1 is not added.\n",
        "        number = self.find_max_num(base_file_name,image_save_dir,extension)\n",
        "        return os.path.join(image_save_dir,f\"{base_file_name}-{number+1}.{extension}\")\n",
        "\n",
        "\n",
        "    def generate_images_or_video(self,\n",
        "                                 init_image = None):\n",
        "        seed, Flax_seed = self.seed_set(self.base_seed)\n",
        "        self.image_save_base_dir, self.gird_save_path= self.get_save_path(self.image_save_dir,self.result_type)\n",
        "        for g_number in range(1,self.num_imgs+1):\n",
        "                target_prompt = self.prompt_list.get()\n",
        "\n",
        "                if self.Recommended_setting:\n",
        "                    input_prompt = self.good_word + target_prompt\n",
        "                else:\n",
        "                    input_prompt = target_prompt\n",
        "\n",
        "\n",
        "                if self.base_seed == -1:\n",
        "                    seed,Flax_seed = self.seed_set(self.base_seed)\n",
        "\n",
        "                image_save_path = self.save_path_set(base_file_name =self.save_file_name,\n",
        "                                                     image_save_dir = self.image_save_base_dir,\n",
        "                                                     is_images = True if not self.make_video else False,\n",
        "                                                     Prompt = target_prompt,\n",
        "                                                     seed = seed)\n",
        "\n",
        "\n",
        "                save_file_name = os.path.basename(image_save_path)\n",
        "                now = datetime.datetime.now()\n",
        "                date_str = now.strftime(\"%Y-%m-%d_UTC-%H:%M:%S\")\n",
        "                generate_start_time = time.time()\n",
        "                if not self.use_TPU:\n",
        "                    self.generator.manual_seed(seed)\n",
        "                self.input_method_dict = {\n",
        "                    \"prompt\" : input_prompt,\n",
        "                    \"negative_prompt\" : self.negative_prompt,\n",
        "                    \"neg_prompt\" : self.negative_prompt,\n",
        "                    \"guidance_scale\" : self.guidance_scale,\n",
        "                    \"num_inference_steps\" : self.num_inference_steps,\n",
        "                    \"generator\" : self.generator,\n",
        "                    \"height\" : int(self.height),\n",
        "                    \"width\" : int(self.width),\n",
        "                    \"image\" : init_image,\n",
        "                    \"strength\" : 1,\n",
        "                    \"t0\" : self.num_inference_steps - 5,\n",
        "                    \"t1\" : self.num_inference_steps - 3,\n",
        "                    \"video_length\" : self.video_length,\n",
        "                    \"num_frames\":self.num_frames,\n",
        "                    \"prng_seed\" : Flax_seed,\n",
        "                    \"params\" : self.parmer,\n",
        "                    }\n",
        "                for method_name, input_method in self.input_method_dict.items():\n",
        "                    if method_name in self.pipeline_call_method:\n",
        "                        self.call_dict[method_name] = input_method\n",
        "\n",
        "                self.call_dict = self.extra_parameter_dict | self.call_dict\n",
        "\n",
        "                output = self.main_pipe(**self.call_dict)\n",
        "                output_element_names = self.get_class_elements(output)\n",
        "\n",
        "                if \"nsfw_content_detected\" in output_element_names:\n",
        "                    self.nsfw_detected = output.nsfw_content_detected\n",
        "                else:\n",
        "                    self.nsfw_detected = None\n",
        "\n",
        "                if \"images\" in output_element_names:\n",
        "                    if self.make_video:\n",
        "                        maked_result = output.images\n",
        "                    elif not self.use_TPU:\n",
        "                        maked_result = output.images[0]\n",
        "                    else:\n",
        "                        maked_result = self.main_pipe.numpy_to_pil(np.asarray(output.images.reshape((self.device_count,) + output.images.shape[-3:])))\n",
        "                elif \"frames\" in output_element_names:\n",
        "                    if self.make_video:\n",
        "                        maked_result = output.frames\n",
        "                    else:\n",
        "                        maked_result = output.frames[0]\n",
        "                else:\n",
        "                    maked_result = getattr(output, output_element_names[0])\n",
        "\n",
        "                if self.nsfw_detected is None:\n",
        "                    bloke=False\n",
        "                else:\n",
        "                    if False in self.nsfw_detected:\n",
        "                        bloke = False\n",
        "                    else:\n",
        "                        bloke = True\n",
        "\n",
        "\n",
        "                generate_end_time = time.time()\n",
        "                base_generate_time = generate_end_time - generate_start_time\n",
        "                generate_time = round(base_generate_time,2)\n",
        "                self.total_generate_time += generate_time\n",
        "                metadata = {\n",
        "                    \"seed\": seed,\n",
        "                    \"prompt\": input_prompt,\n",
        "                    \"G_scale\":guidance_scale,\n",
        "                    \"D_step\":self.num_inference_steps,\n",
        "                    \"model_path\":self.model_name,\n",
        "                    \"n_prompt\":self.negative_prompt,\n",
        "                    \"pipeline_name\":self.pipeline_name\n",
        "                    }\n",
        "                save_data = {\"base_prompt\": target_prompt,\n",
        "                             \"save_path\": image_save_path,\n",
        "                             \"file_name\": save_file_name,\n",
        "                             \"generate_time\" : generate_time,\n",
        "                             \"generate_number\" : self.base_generate_number,}\n",
        "\n",
        "                status_dict = {\"bloke\" : bloke,\n",
        "                               \"metadata\" : metadata,\n",
        "                               \"save_data\" : save_data}\n",
        "                self.make_images_list.put([maked_result,status_dict])\n",
        "                if not bloke and self.make_grid:\n",
        "                    self.grid_imgs.append(maked_result)\n",
        "\n",
        "                self.base_generate_number += 1\n",
        "\n",
        "    def save_and_show(self):\n",
        "        #あとで修正\n",
        "        for T in range(self.num_imgs):\n",
        "            make_image, status_dict = self.make_images_list.get()\n",
        "            bloke = status_dict[\"bloke\"]\n",
        "            metadata = status_dict[\"metadata\"]\n",
        "            save_data = status_dict[\"save_data\"]\n",
        "            save_path = status_dict[\"save_data\"][\"save_path\"]\n",
        "            file_name = status_dict[\"save_data\"][\"file_name\"]\n",
        "\n",
        "            if not self.make_video:\n",
        "                if not bloke:\n",
        "                    pnginfo = PngImagePlugin.PngInfo()\n",
        "                    info = make_image.info\n",
        "                    for key, value in metadata.items():\n",
        "                        pnginfo.add_text(key, str(value))\n",
        "                    make_image.save(save_path,pnginfo = pnginfo,quality=95)\n",
        "\n",
        "                    print(f'\\033[34m画像生成が完了しました ({save_data[\"generate_number\"]}/{self.num_imgs})  {save_data[\"generate_time\"]}s')\n",
        "                    print(f'seed値:\\033[38;2;0;255;255m {metadata[\"seed\"]}\\033[34m')\n",
        "                    print(f'ファイルの名前: \\033[32m{file_name}\\033[0m')\n",
        "                    run_html_js(save_path,\"保存先のパス: \")\n",
        "                    if self.show_result:\n",
        "                        print()\n",
        "                        #To display including metadata\n",
        "                        with Image.open(save_path) as show_img:\n",
        "                            display(show_img)\n",
        "                    print(f'\\033[92mプロンプト: {save_data[\"base_prompt\"]}\\033[0m')\n",
        "                else:\n",
        "                    print(\"ブロックされました\\n\")\n",
        "\n",
        "            else:\n",
        "                logger.debug(f\"num make_image: {len(make_image)} 1の場合、output.images[0]になっていないか確認。output.imagesが正解\")\n",
        "                from diffusers.utils import export_to_video\n",
        "                export_to_video(make_image, save_path, fps = self.video_fps)\n",
        "                print(f'\\033[34m動画生成が完了しました ({save_data[\"generate_number\"]}/{self.num_imgs})  {save_data[\"generate_time\"]}s')\n",
        "                print(f'seed値:\\033[38;2;0;255;255m {metadata[\"seed\"]}\\033[34m')\n",
        "                print(f'ファイルの名前: \\033[32m{file_name}\\033[0m')\n",
        "                run_html_js(save_path,\"保存先のパス: \")\n",
        "                if self.show_result:\n",
        "                    self.play_mp4(save_path)\n",
        "                    print(f'\\033[92mプロンプト: {save_data[\"base_prompt\"]}\\033[0m')\n",
        "\n",
        "    def grid_task(self):\n",
        "        if num_imgs>1 and self.gird_save_path:\n",
        "            grid = self.image_grid(imgs = self.grid_imgs,\n",
        "                                   cols = self.grit_image_width)\n",
        "            if grid is not None:\n",
        "                grid.save(self.gird_save_path)\n",
        "                if self.show_result:\n",
        "                    with Image.open(self.gird_save_path) as grid_img:\n",
        "                        run_html_js(self.gird_save_path,\"グリッド画像のパス: \")\n",
        "                        display(grid_img)\n",
        "\n",
        "\n",
        "    def generate(self):\n",
        "            #とりあえず\n",
        "            if (not self.make_video) and self.pipeline_type == \"img2img\":\n",
        "                #img2img\n",
        "                self.init_images_list = self.img_set(self.input_img_dir_or_path,\n",
        "                                                     self.height,\n",
        "                                                     self.width)\n",
        "                if len(self.init_images_list)>1:\n",
        "                    total_num = self.num_imgs * len(self.init_images_list)\n",
        "                    print(f\"Since multiple images were passed, generate {self.num_imgs} images per image, for a total of {total_num} images\")\n",
        "                for init_image in self.init_images_list:\n",
        "                    self.generate_images_or_video(init_image = init_image)\n",
        "            else:\n",
        "                self.generate_images_or_video(init_image = None)\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        #prompt_list = []\n",
        "        self.prompt_process = threading.Thread(target=self.prompt_processing, args=(self.base_prompt,self.prompt_list),daemon=True)\n",
        "        self.generate_process = threading.Thread(target=self.generate)\n",
        "        self.save_and_show_process = threading.Thread(target=self.save_and_show)\n",
        "        self.prompt_process.start()\n",
        "        self.generate_process.start()\n",
        "        self.save_and_show_process.start()\n",
        "        self.save_and_show_process.join()\n",
        "        self.generation_time_average = \"{:.2f}\".format(self.total_generate_time/self.base_generate_number)\n",
        "        if not self.make_video:\n",
        "            self.grid_task()\n",
        "        print(f\"\\033[38;2;135;206;235mGeneration time average: {self.generation_time_average}s\\033[0m\")\n",
        "\n",
        "        #print(f\"generation time average: {generation_time_average}\")\n",
        "\n",
        "    def debugs(self):\n",
        "        self.prompt_processing(self.base_prompt,self.prompt_list)\n",
        "        self.generate()\n",
        "        self.save_and_show()\n",
        "\n",
        "\n",
        "generate_cls = generate_class(base_prompt = prompt,\n",
        "                              base_negative_prompt = negative_prompt,\n",
        "                              base_seed = seed,\n",
        "                              num_imgs = num_imgs,\n",
        "                              height = height,\n",
        "                              width = width,\n",
        "                              num_inference_steps = num_inference_steps,\n",
        "                              guidance_scale = guidance_scale,\n",
        "                              grit_image_width = grit_image_width,\n",
        "                              Recommended_setting = Recommended_setting,\n",
        "                              image_save_dir = save_dir,\n",
        "                              save_file_name = file_name,\n",
        "                              input_img_dir_or_path = input_image_path_or_dir,\n",
        "                              model_name = model_path,\n",
        "                              main_pipe = main_pipe,\n",
        "                              parmer = parmer,\n",
        "                              video_length = video_length,\n",
        "                              num_frames = num_frames,\n",
        "                              video_fps = video_fps,\n",
        "                              show_result = show_result,\n",
        "                              Hide_warnings = Hide_warnings,\n",
        "                              extra_parameter_dict = parameter_dict)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    generate_cls.run()\n",
        "    #generate_cls.debugs()\n",
        "\n",
        "    if not device_type == \"TPU\":\n",
        "        gc.collect()\n",
        "    if device_type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIEW0jvHK7I1"
      },
      "source": [
        "#サブ機能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ5y7hyEiCpa"
      },
      "outputs": [],
      "source": [
        "#@title メモリの初期化(Beta) {display-mode: \"form\"}\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "variable_names = [\"base_pipe\",\"txt2img_pipe\",\"img2img_pipe\",\"txt2video_pipe\",\"Inpaint_pipe\",\"safe_pipe\", \"tokenizer\"]\n",
        "\n",
        "for name in variable_names:\n",
        "    if name in globals():\n",
        "      del globals()[name]\n",
        "    if name in locals():\n",
        "      del locals()[name]\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hok9JfsGeQW"
      },
      "outputs": [],
      "source": [
        "#@title 画像のメタデータを見る  {display-mode: \"form\"}\n",
        "from PIL import Image, PngImagePlugin\n",
        "import os\n",
        "image_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  output_info = Image.open(image_path).info\n",
        "except:\n",
        "  raise FileNotFoundError(\"画像を読み込めませんでした\")\n",
        "\n",
        "if image_path and os.path.isfile(image_path):\n",
        "    output_info = Image.open(image_path).info\n",
        "\n",
        "    for key,info in output_info.items():\n",
        "        print(f\"{key} : {info}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH5cPNi297Lr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title  ダウンロード{display-mode: \"form\"}\n",
        "#@markdown >ファイル or ディレクトリを指定してダウンロードします。\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "path = \"\" #@param {type:\"string\"}\n",
        "if not path:\n",
        "    path = \"/content/Generated\"\n",
        "\n",
        "if path.endswith(\".png\" or \".jpg\"):\n",
        "    try:\n",
        "        files.download(path)\n",
        "        print(\"\\033[32mダウンロードが正常に完了しました\")\n",
        "    except:\n",
        "        print(\"\\033[31m指定された画像が見つかりませんでした\\033[0m\")\n",
        "elif path.endswith(\".mp4\"):\n",
        "    try:\n",
        "        files.download(path)\n",
        "        print(\"\\033[32mダウンロードが正常に完了しました\")\n",
        "    except:\n",
        "        print(\"\\033[31m指定された動画ファイルが見つかりませんでした\\033[0m\")\n",
        "else:\n",
        "    for zip_number in range(1,100000):\n",
        "        zip_name=f\"Generated-No.{zip_number}\"\n",
        "        base_zip_path = os.path.join(\"/content\",zip_name)\n",
        "        if not os.path.isfile(base_zip_path):\n",
        "            break\n",
        "    zippath = base_zip_path+\".zip\"\n",
        "    try:\n",
        "        shutil.make_archive(base_zip_path, \"zip\", path)\n",
        "        files.download(zippath)\n",
        "        print(\"\\033[32mzipファイルへ圧縮が正常に完了しました\")\n",
        "        print(f'zipファイル名前は\\033[34m\"{zip_name}\"\\033[32mですご確認ください\\033[0m')\n",
        "    except:\n",
        "        print(\"\\033[31mダウンロードに失敗しました\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i6YlYLKMSU6K"
      },
      "outputs": [],
      "source": [
        "#@title txt2audio\n",
        "prompt = \"Techno-style  music\" #@param {type:\"string\"}\n",
        "negative_prompt = \"Low quality.\" #@param {type:\"string\"}\n",
        "audio_length_in_s = 30 #@param {type:\"number\"}\n",
        "num_inference_steps = 500 #@param {type:\"number\"}\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "\n",
        "prompt+=\",masterpiece\"\n",
        "import os\n",
        "import scipy\n",
        "import torch\n",
        "from diffusers import AudioLDM2Pipeline\n",
        "from IPython.display import Audio\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "repo_id = \"cvssp/audioldm2\"\n",
        "if \"pipe\" not in locals() and \"pipe\" not in globals():\n",
        "    pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "if \"numa\" in globals():\n",
        "    numa+=1\n",
        "else:\n",
        "    numa=1\n",
        "if seed is None or seed==-1:\n",
        "    seed = random.randint(1,1000000)\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "audio = pipe(prompt,\n",
        "             negative_prompt=negative_prompt,\n",
        "             num_inference_steps=num_inference_steps,\n",
        "             audio_length_in_s=audio_length_in_s,\n",
        "             num_waveforms_per_prompt=1,\n",
        "             generator=generator,\n",
        "             ).audios\n",
        "\n",
        "\n",
        "os.makedirs(\"/content/audio\",exist_ok=True)\n",
        "save_path=f\"/content/audio/audio_{numa}_{seed}.wav\"\n",
        "\n",
        "\n",
        "scipy.io.wavfile.write(save_path, rate=16000, data=audio[0])\n",
        "print(f\"\\033[38;2;0;255;255mseed: {seed}\")\n",
        "print(f\"save_path: {save_path}\\n\\033[0m\")\n",
        "Audio(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRB6MLjGbrof"
      },
      "outputs": [],
      "source": [
        "#@title Youtube_download {display-mode: \"form\"}\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    import pytube\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q pytube\n",
        "\n",
        "from pytube import (Playlist, YouTube)\n",
        "from requests import HTTPError\n",
        "Youtube_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "ローカルにダウンロードする = False # @param {type:\"boolean\"}\n",
        "def Youtube_download(Youtube_path,local_download):\n",
        "    Not_download_list=[]\n",
        "    mkdir_list=[\"/content/Youtube/File\",\"/content/Youtube/List\"]\n",
        "    for mk_path in mkdir_list:\n",
        "        os.makedirs(mk_path,exist_ok=True)\n",
        "    os.chdir(\"/content/Youtube\")\n",
        "    if Youtube_path:\n",
        "        if Youtube_path.startswith(\"https://www.youtube.com/playlist?list=\"):\n",
        "            try:\n",
        "                nu+=1\n",
        "            except:\n",
        "                nu=1\n",
        "            list_path=f\"/content/Youtube/Yotube_list_{nu}\"\n",
        "            os.makedirs(list_path,exist_ok=True)\n",
        "            os.chdir(list_path)\n",
        "            Y_list = Playlist(Youtube_path)\n",
        "            for video, path in zip(Y_list.videos, Y_list.video_urls[:3]):\n",
        "                try:\n",
        "                    video.streams.first().download()\n",
        "                except:\n",
        "                    Not_download_list.append(path)\n",
        "            if Not_download_list:\n",
        "                print(\"ダウンロードに失敗したパス\")\n",
        "                for ndl in Not_download_list:\n",
        "                    print(ndl)\n",
        "            if local_download:\n",
        "                zip_path=f\"/content/Youtube/zip-No_{zip_number}.zip\"\n",
        "                shutil.make_archive(zip_path, \"zip\", list_path)\n",
        "                files.download(zip_path)\n",
        "\n",
        "        elif Youtube_path.startswith(\"https://www.youtube.com/watch?v=\"):\n",
        "            os.chdir(\"/content/Youtube/File\")\n",
        "            try:\n",
        "                yt=YouTube(Youtube_path)\n",
        "                yt.streams.first().download()\n",
        "                yt_save_path=os.path.join(\"/content/Youtube/File\" , (yt.title+\".mp4\"))\n",
        "            except:\n",
        "                raise HTTPError(\"URLが無効です\")\n",
        "            if local_download:\n",
        "                try:\n",
        "                    files.download(yt_save_path)\n",
        "                except FileNotFoundError:\n",
        "                    print(f\"ファイルのダウンロードに失敗しました。\")\n",
        "\n",
        "        else:\n",
        "            raise HTTPError(\"URLが無効です\")\n",
        "    else:\n",
        "        raise HTTPError(\"URLの入力をお願いします\")\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "    print(\"処理が終了しました\")\n",
        "    print(f\"セーブパス: {os.path.basename(yt_save_path)}\")\n",
        "\n",
        "Youtube_download(Youtube_path,ローカルにダウンロードする)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC3E3W81SL8n"
      },
      "outputs": [],
      "source": [
        "#@title  グリッド画像の分割  (iamge generation){display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "\n",
        "### 各定数の設定\n",
        "# 縦方向分割数\n",
        "\n",
        "# 分割元ファイルパス\n",
        "input_path = \"\" # @param {type:\"string\"}\n",
        "output_dir = \"\" # @param {type:\"string\"}\n",
        "縦の分割回数 = 1 # @param {type:\"number\"}\n",
        "横の分割回数 = 3 # @param {type:\"number\"}\n",
        "#@markdown >heightとwidthは2以上の自然数の入力をお願いします\n",
        "height=縦の分割回数\n",
        "width=横の分割回数\n",
        "base_img_path=input_path\n",
        "\n",
        "\n",
        "if base_img_path==\"\" or  output_dir == \"\":\n",
        "  raise TypeError(\"pathが未入力です\")\n",
        "if output_dir is not dir:\n",
        "   output_dir = os.path.dirname(output_dir)\n",
        "\n",
        "def is_positive_integer(value):\n",
        "    try:\n",
        "        value = int(value)  # 整数に変換\n",
        "        if value > 0:  # 1以上の場合は True を返す\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except ValueError:  # ValueError が発生した場合は False を返す\n",
        "        return False\n",
        "\n",
        "if not is_positive_integer(height) or is_positive_integer(width):\n",
        "  raise TypeError(\"heightとwidthは、2以上の自然数である必要があります。\")\n",
        "\n",
        "def ImgSplit(im,w,h):\n",
        "    # 読み込んだ画像の高さと幅を指定分割数で割る\n",
        "    HEIGHT = h / height\n",
        "    WIDTH = w / width\n",
        "\n",
        "    # 縦の分割枚数\n",
        "    for h1 in range(height):\n",
        "        # 横の分割枚数\n",
        "        for w1 in range(width):\n",
        "            w2 = w1 * WIDTH\n",
        "            h2 = h1 * HEIGHT\n",
        "            yield im.crop((w2, h2, WIDTH + w2, HEIGHT + h2))\n",
        "\n",
        "#if __name__ == '__main__': このセルが直接実行された場合\n",
        "    # 画像の読み込み\n",
        "im = Image.open(base_img_path)\n",
        "w = im.size[0]\n",
        "h = im.size[1]\n",
        "length = math.log10(height * width) + 1\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for number, ig in enumerate(ImgSplit(im,w,h), 1):\n",
        "    # 出力\n",
        "    ig.save(output_dir + \"/\" + str(number).zfill(int(length)) + \".PNG\", \"PNG\")\n",
        "print(f\"\\033[34m分割が完了しました: {output_dir}\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3al9BGGP7DIR"
      },
      "outputs": [],
      "source": [
        "#@title  単語が含まれているファイルを移動{display-mode: \"form\"}\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_files_with_keyword(source_dir, destination_dir, keyword):\n",
        "    # 指定されたディレクトリ内のファイルを取得\n",
        "    files = os.listdir(source_dir)\n",
        "\n",
        "    for file in files:\n",
        "        # ファイル名にキーワードが含まれているかチェック\n",
        "        if keyword in file:\n",
        "            # 移動元のファイルパス\n",
        "            source_file = os.path.join(source_dir, file)\n",
        "            # 移動先のファイルパス\n",
        "            destination_file = os.path.join(destination_dir, file)\n",
        "\n",
        "            # ファイルを移動\n",
        "            shutil.move(source_file, destination_file)\n",
        "\n",
        "# 使用例\n",
        "検索対象のフォルダ = \"\"  # @param {type:\"string\"}\n",
        "移動先 = \"\"   # @param {type:\"string\"}\n",
        "単語 = \"\" # @param {type:\"string\"}\n",
        "\n",
        "source_directory=検索対象のフォルダ\n",
        "destination_directory=移動先\n",
        "keyword_to_search=単語\n",
        "os.makedirs(destination_directory)\n",
        "move_files_with_keyword(source_directory, destination_directory, keyword_to_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuI2OK7YI2pE"
      },
      "outputs": [],
      "source": [
        "#@title dir_size_counter {display-mode: \"form\"}\n",
        "#@markdown\n",
        "import os\n",
        "\n",
        "def get_folder_size(folder_path):\n",
        "    total_size = 0\n",
        "    if os.path.isfile(folder_path):\n",
        "        total_size+=os.path.getsize(folder_path)\n",
        "    else:\n",
        "        for path, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(path, file)\n",
        "                total_size += os.path.getsize(file_path)\n",
        "\n",
        "    return total_size\n",
        "\n",
        "folder_path = \"\" # @param {type:\"string\"}\n",
        "if not os.path.exists(folder_path):\n",
        "    raise FileNotFoundError(\"pathが無効です\")\n",
        "\n",
        "size_in_bytes = get_folder_size(folder_path)\n",
        "\n",
        "\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "size_in_gb = size_in_mb / 1024\n",
        "\n",
        "print(f\"Folder Size: {size_in_bytes} bytes\")\n",
        "print(f\"Folder Size: {size_in_kb:.2f} KB\")\n",
        "print(f\"Folder Size: {size_in_mb:.2f} MB\")\n",
        "print(f\"Folder Size: {size_in_gb:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRRD_VF59fA_"
      },
      "outputs": [],
      "source": [
        "#@title 画像変換 {display-mode: \"form\"}\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "input_path = \"\" #@param {type:\"string\"}\n",
        "output_path=\"\" #@param {type:\"string\"}\n",
        "Change_mode = \"png2jpg\" # @param [\"png2jpg\", \"jpg2png\"]\n",
        "\n",
        "#@markdown * png2jpg :png画像をjpg画像に変換します。\n",
        "\n",
        "\n",
        "#@markdown * jpg2png :jpg画像をpng画像に変換します。\n",
        "\n",
        "if not os.path.exists(input_path):\n",
        "  #raise FileNotFoundError('\\033[33m指定された \"dir\"または\"file\" が見つかりませんでした。\\033[0m')\n",
        "  sys.exit('\"input_path\"にdirまたはfileのパスを入力お願いします。')\n",
        "\n",
        "if not input_path.endswith(\".png\" or \".jpg\" or \".jpeg\"):\n",
        "  if output_path==\"\":\n",
        "    # 保存先のディレクトリパスを作成\n",
        "    save_dir_path = input_path +\"-\" +Change_mode\n",
        "  else:\n",
        "    save_dir_path=output_path\n",
        "  # 保存先のディレクトリが存在しない場合は作成する\n",
        "  if not os.path.exists(save_dir_path):\n",
        "    os.makedirs(save_dir_path)\n",
        "\n",
        "  # ディレクトリ内のファイルを取得\n",
        "  file_list = os.listdir(input_path)\n",
        "\n",
        "  # ファイルごとに処理を行う\n",
        "  for file_name in file_list:\n",
        "    # ファイルのパスを作成\n",
        "    file_path = os.path.join(save_dir_path, file_name)\n",
        "\n",
        "    # ファイルの拡張子を取得\n",
        "    file_extension = os.path.splitext(file_name)[1]\n",
        "    if Change_mode == \"png2jpg\":\n",
        "    # 最後が特定の単語であるかをチェックする\n",
        "      if file_extension.endswith(\".png\"):\n",
        "        try:\n",
        "          # 画像を開く\n",
        "          im = Image.open(file_path)\n",
        "          file_name_new = file_name.replace(\".png\", \".jpg\")#pngをjpg\n",
        "          # 保存先のファイルパスを作成\n",
        "          save_file_path = os.path.join(save_dir_path, file_name_new)\n",
        "          # 変換後の画像を保存する\n",
        "          im.save(save_file_path,format=\"JPEG\")\n",
        "          print(f\"\\033[34m{save_file_path}を保存しました。\\033[0m\")\n",
        "        except Exception as e:\n",
        "          print(f\"\\033[31m{file_name}の変換中にエラーが発生しました: {str(e)}\\033[0m\")\n",
        "      else:\n",
        "        print(f\"{file_name}はpngファイルではないため、変換をスキップしました。\")\n",
        "    elif Change_mode == \"jpg2png\":\n",
        "        try:\n",
        "          # 画像を開く\n",
        "          im = Image.open(file_path)\n",
        "          file_name_new = file_name.replace((\".jpg\"or\".jpeg\"), \".png\")#jpgをpng\n",
        "          # 保存先のファイルパスを作成\n",
        "          save_file_path = os.path.join(save_dir_path, file_name_new)\n",
        "          # 変換後の画像を保存する\n",
        "          im.save(save_file_path,format=\"PNG\")\n",
        "          print(f\"\\033[34m{save_file_path}を保存しました。\\033[0m\")\n",
        "        except Exception as e:\n",
        "          print(f\"\\033[31m{file_path}の変換中にエラーが発生しました: {str(e)}\\033[0m\")\n",
        "else:\n",
        "  if Change_mode ==\"png2jpg\":\n",
        "    if not output_path==\"\":\n",
        "      basename_new = input_path.replace(\".png\", \".jpg\")#jpgをpng\n",
        "      save_file_path=os.path.join(output_path, basename_new)\n",
        "      im = Image.open(input_path)\n",
        "      im.save(save_file_path,format=\"JPEG\")\n",
        "    else:\n",
        "      im = Image.open(input_path)\n",
        "      save_file_path = input_path.replace(\".png\", \".jpg\")\n",
        "      im.save(save_file_path,format=\"JPEG\")\n",
        "    print(f'\\033[34m\"{save_file_path}\"に保存しました。\\033[0m')\n",
        "  elif Change_mode == \"jpg2png\":\n",
        "    if not output_path==\"\":\n",
        "      basename_new = input_path.replace((\".jpg\"or\".jpeg\"), \".png\")#jpgをpng\n",
        "      save_file_path=os.path.join(output_path, basename_new)\n",
        "      im = Image.open(input_path)\n",
        "      im.save(save_file_path,format=\"PNG\")\n",
        "    else:\n",
        "      im = Image.open(input_path)\n",
        "      save_file_path = input_path.replace((\".jpg\"or\".jpeg\"), \".png\")\n",
        "      im.save(save_file_path,format=\"PNG\")\n",
        "    print(f'\\033[34m\"{save_file_path}\"に保存しました。\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyeuVK1DeJEv"
      },
      "outputs": [],
      "source": [
        "#@title mp4を再生  {display-mode: \"form\"}\n",
        "MP4_path= \"\" #@param {type:\"string\"}\n",
        "# mp4動画の再生\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "try:\n",
        "  mp4 = open(MP4_path, 'rb').read()\n",
        "except:\n",
        "  raise FileNotFoundError(\"指定されたmp4が見つかりませんでした\")\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT_pKvlmJXIq"
      },
      "outputs": [],
      "source": [
        "#@title  文字列トークンカウンター{display-mode: \"form\"}\n",
        "import pprint\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "prompt = \"\"  #@param {type:\"string\"}\n",
        "try:\n",
        "  tokens = tokenizer.tokenize(prompt)\n",
        "except:\n",
        "  text_model_id = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(text_model_id)\n",
        "  tokens = tokenizer.tokenize(prompt)\n",
        "print(len(tokens))\n",
        "pprint.pprint(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-5Gh7XWLwcr"
      },
      "outputs": [],
      "source": [
        "#@title 高画質化  {display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from diffusers import StableDiffusionUpscalePipeline\n",
        "import torch\n",
        "\n",
        "# load model and scheduler\n",
        "Prompt = \"\" #@param {type:\"string\"}\n",
        "prompt=\"masterpiece:2.0,best quality,high quality,\"+Prompt\n",
        "low_res_img_path = \"\" #@param {type:\"string\"}\n",
        "encoded_text = codecs.encode(low_res_img_path, 'utf-8')\n",
        "low_res_img_path = codecs.decode(encoded_text, 'utf-8')\n",
        "\n",
        "if \"pipeline2\" not in locals()  and \"pipeline2\" not in globals():\n",
        "  model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "  pipeline2 = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "    model_id, revision=\"fp16\", torch_dtype=torch.float16\n",
        "  )\n",
        "  pipeline2 = pipeline2.to(\"cuda\")\n",
        "if not os.path.exists(low_res_img_path):\n",
        "  raise FileNotFoundError(\"ファイルが見つかりませんでした\")\n",
        "try:\n",
        "  low_res_img = Image.open(low_res_img_path)\n",
        "except:\n",
        "  raise FileNotFoundError(\"画像を読み込めませんでした\")\n",
        "low_res_img = low_res_img.resize((128, 128))\n",
        "\n",
        "negative_prompt=\"low quality:2.0\"\n",
        "\n",
        "upscaled_image = pipeline2(prompt=prompt, image=low_res_img,negative_prompt=negative_prompt).images[0]\n",
        "\n",
        "try:\n",
        "  L+=1\n",
        "except:\n",
        "  L=1\n",
        "os.makedirs(\"/content/low_res_imgs\",exist_ok=True)\n",
        "path1=(f\"/content/low_res_imgs/No{L}.png\")\n",
        "upscaled_image.save(path1)\n",
        "print(f\"画像保存パス: ({path1})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4kpwhy30ePA"
      },
      "outputs": [],
      "source": [
        "#@title 画像フォルダを削除  {display-mode: \"form\"}\n",
        "\n",
        "del_path = \"\" #@param {type:\"string\"}\n",
        "if del_path ==\"\":\n",
        "  del_path=\"/content/Generated\"\n",
        "import shutil\n",
        "if not os.path.isdir(del_path):\n",
        "  raise TypeError(\"ディレクトリのみ削除が可能です\")\n",
        "#@markdown 未入力の場合 /content/Generatedを削除します\n",
        "\n",
        "YorS=input(\"本当に削除しますか？[yes/no]: \")\n",
        "if YorS.lower() in (\"yes\", \"y\"): # 入力された文字列を小文字にして、yesやyと一致するか判定する\n",
        "    try:\n",
        "        shutil.rmtree(del_path)\n",
        "        print(\"削除しました\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\033[31m{del_path}が見つかりませんでした\\033[0m\")\n",
        "elif YorS.lower() in (\"no\", \"n\"): # 入力された文字列を小文字にして、noやnと一致するか判定する\n",
        "    print(\"フォルダの削除を中止しました\")\n",
        "else:\n",
        "    print(\"yes/no のみの入力をお願いします。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t-Qqqp6la4WJ"
      },
      "outputs": [],
      "source": [
        "#@title url_Download\n",
        "import urllib.request , os\n",
        "import datetime\n",
        "def download_file(url, save_path):\n",
        "  other_url,split=os.path.splitext(url)\n",
        "  if save_path==\"\":\n",
        "    save_path=\"/content/download\"\n",
        "    choice_name=input(\"ファイル名(拡張子無し): \")\n",
        "    choice_name+=split\n",
        "    test_path=os.path.join(save_path,choice_name)\n",
        "    if os.path.exists(test_path):\n",
        "      now=datetime.now()\n",
        "      save_path=test_path+now\n",
        "  save_dir=os.path.dirname(save_path)\n",
        "  os.makedirs(save_dir,exist_ok=True)\n",
        "  if not url.endswith(split):\n",
        "    save_path+=split\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "  except HTTPError:\n",
        "    raise SystemError(\"URLからファイルを習得できませんでした\")\n",
        "  print(f\"保存先のパス: {save_path}\")\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "save_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi4EonYLXtN0"
      },
      "source": [
        "#追加オプション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1QPxPSzF_aP"
      },
      "source": [
        "#学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH1aO3M-zk5x"
      },
      "outputs": [],
      "source": [
        "#@title モデルを学習 {display-mode: \"form\"}\n",
        "\n",
        "学習で使用する単語 = \"Cat ears girl\" # @param {type:\"string\"}\n",
        "#概念を説明する単語 = \"\" # @param {type:\"string\"}\n",
        "学習ステップ = 20   # @param {type:\"number\"}\n",
        "\n",
        "入力する画像フォルダ = \"/content/drive/MyDrive/GS\" # @param {type:\"string\"}\n",
        "出力するフォルダ = \"/content/drive/MyDrive/make_model_2\" # @param {type:\"string\"}\n",
        "#概念のタイプ = \"style\" # @param [\"style\",\"object\"]\n",
        "モデル名前_or_パス = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "出力ファイル名 = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "終了したらランタイムを切断 = False # @param {type:\"boolean\"}\n",
        "#@markdown sd1.5系列とsd2.1系列では埋め込みに互換性がありません。\n",
        "\n",
        "driveに接続 = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown >用語の説明\n",
        "# @markdown * placeholder_token : 学習内で、使用するトークンです。新しい概念を入力します。\n",
        "# @markdown * initializer_token : 新しい概念が何であるかを要約する単語です。\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive_cn=driveに接続\n",
        "if driveに接続:\n",
        "  if not drive._os.path.ismount('/content/drive'):\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except:\n",
        "      print(\"ドライブの接続に失敗しました。\")\n",
        "      drive_cn=False\n",
        "\n",
        "\n",
        "\n",
        "if  drive_cn==False and \"/content/drive/MyDrive\" in 出力するフォルダ:\n",
        "  raise TypeError(\"Googleドライブに接続されていないため、ドライブに保存できません。\")\n",
        "\n",
        "if not os.path.isdir(入力する画像フォルダ):\n",
        "  raise FileNotFoundError(\"画像フォルダが存在しません\")\n",
        "\n",
        "if 出力するフォルダ is None:\n",
        "  raise FileNotFoundError(\"結果を出力するフォルダを入力してください\")\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(出力するフォルダ,exist_ok=True)\n",
        "try:\n",
        "  import diffusers,transformers\n",
        "except:\n",
        "  !pip install transformers diffusers -q\n",
        "  import transformers,diffusers\n",
        "\n",
        "if not os.path.exists(\"/content/script/diffusers\"):\n",
        "  %cd /content/script\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "  %cd diffusers\n",
        "\n",
        "try:\n",
        "  import accelerate,transformers,ftfy\n",
        "except:\n",
        "  !pip install -q accelerate>=0.16.0 transformers>=4.25.1 ftfy Jinja2 bitsandbytes\n",
        "  import bitsandbytes,accelerate,transformers,ftfy\n",
        "import accelerate,torchvision,transformers,ftfy ,diffusers,bitsandbytes\n",
        "\n",
        "size=512\n",
        "if モデル名前_or_パス==\"runwayml/stable-diffusion-v1-5\":\n",
        "  size=512\n",
        "#else:\n",
        "#  size=768\n",
        "\n",
        "#exportは使用不可\n",
        "%env pretrained_model_name_or_path=$モデル名前_or_パス\n",
        "%env train_data_dir=$入力する画像フォルダ\n",
        "%env placeholder_token=$学習で使用する単語\n",
        "%env resolution=$size\n",
        "%env max_train_steps=$学習ステップ\n",
        "%env output_dir=$出力するフォルダ\n",
        "\n",
        "\n",
        "%cd /content/script/diffusers/examples/textual_inversion\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path  \\\n",
        "  --instance_data_dir=$train_data_dir \\\n",
        "  --output_dir=$output_dir \\\n",
        "  --instance_prompt=$placeholder_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=1 \\\n",
        "  --learning_rate=1 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "\n",
        "base=os.path.join(出力するフォルダ,\"learned_embeds.safetensors\")\n",
        "if not 出力ファイル名==\"\":\n",
        "  after_name=出力ファイル名+\".safetensors\"\n",
        "  after=os.path.join(出力するフォルダ,after_name)\n",
        "  if os.path.exists(base):\n",
        "    os.rename(base,after)\n",
        "  else:\n",
        "    print(\"埋め込みファイルが見つかりませんでした。\")\n",
        "else:\n",
        "  after=base\n",
        "\n",
        "print(f\"\"\"\\033[34m\n",
        "学習が終了しました\n",
        "path: {出力するフォルダ}\\033[0m\n",
        "\"\"\")\n",
        "\n",
        "if 終了したらランタイムを切断:\n",
        "  from google.colab import runtime\n",
        "  print(\"ランタイムを切断中...\")\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-PpdeFgFjwa"
      },
      "outputs": [],
      "source": [
        "#@title 埋め込みを学習 {display-mode: \"form\"}\n",
        "\n",
        "学習で使用するトークン = \"flans\" # @param {type:\"string\"}\n",
        "概念を説明する単語 = \"flandre\" # @param {type:\"string\"}\n",
        "学習ステップ = 50   # @param {type:\"number\"}\n",
        "\n",
        "入力する画像フォルダ = \"/content/drive/MyDrive/GS\" # @param {type:\"string\"}\n",
        "出力するフォルダ = \"/content/drive/MyDrive/textjual\" # @param {type:\"string\"}\n",
        "概念のタイプ = \"style\" # @param [\"style\",\"object\"]\n",
        "モデル名前_or_パス = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "\n",
        "出力ファイル名 = \"Flans\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "終了したらランタイムを切断 = False # @param {type:\"boolean\"}\n",
        "#@markdown sd1.5系列とsd2.1系列では埋め込みに互換性がありません。\n",
        "\n",
        "driveに接続 = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown >用語の説明\n",
        "# @markdown * placeholder_token : 学習内で、使用するトークンです。新しい概念を入力します。\n",
        "# @markdown * initializer_token : 新しい概念が何であるかを要約する単語です。\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive_cn=driveに接続\n",
        "if driveに接続:\n",
        "  if not drive._os.path.ismount('/content/drive'):\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except:\n",
        "      print(\"ドライブの接続に失敗しました。\")\n",
        "      drive_cn=False\n",
        "\n",
        "\n",
        "\n",
        "if  drive_cn==False and \"/content/drive/MyDrive\" in 出力するフォルダ:\n",
        "  raise TypeError(\"Googleドライブに接続されていないため、ドライブに保存できません。\")\n",
        "\n",
        "if not os.path.isdir(入力する画像フォルダ):\n",
        "  raise FileNotFoundError(\"画像フォルダが存在しません\")\n",
        "\n",
        "if 出力するフォルダ is None:\n",
        "  raise FileNotFoundError(\"結果を出力するフォルダを入力してください\")\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(出力するフォルダ,exist_ok=True)\n",
        "\n",
        "\n",
        "try:\n",
        "  import diffusers,transformers\n",
        "except:\n",
        "  !pip install transformers diffusers -q\n",
        "  import transformers,diffusers\n",
        "\n",
        "if not os.path.exists(\"/content/script/diffusers\"):\n",
        "  %cd /content/script\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"setup_txt\" not in locals():\n",
        "  %cd /content/script/diffusers/examples/textual_inversion\n",
        "  !pip install -r ./requirements.txt -q\n",
        "  setup_txt=True\n",
        "\n",
        "import accelerate,torchvision,transformers,ftfy ,diffusers\n",
        "\n",
        "\n",
        "%cd /content/diffusers/examples/textual_inversion\n",
        "\n",
        "size=512\n",
        "if モデル名前_or_パス==\"runwayml/stable-diffusion-v1-5\":\n",
        "  size=512\n",
        "else:\n",
        "  size=768\n",
        "\n",
        "#exportは使用不可\n",
        "%env pretrained_model_name_or_path=$モデル名前_or_パス\n",
        "%env train_data_dir=$入力する画像フォルダ\n",
        "%env learnable_property=$概念のタイプ\n",
        "%env placeholder_token=$学習で使用するトークン\n",
        "%env initializer_token=$概念を説明する単語\n",
        "%env resolution=$size\n",
        "%env max_train_steps=$学習ステップ\n",
        "%env output_dir=$出力するフォルダ\n",
        "\n",
        "#--learning_rate=5  \\\n",
        "#--mixed_precision=\"fp16\" \\\n",
        "#learning_rateは整数\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path \\\n",
        "  --train_data_dir=$train_data_dir \\\n",
        "  --learnable_property=$learnable_property \\\n",
        "  --placeholder_token=$placeholder_token \\\n",
        "  --initializer_token=$initializer_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --learning_rate=5  \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$output_dir\n",
        "\n",
        "base=os.path.join(出力するフォルダ,\"learned_embeds.safetensors\")\n",
        "if not 出力ファイル名==\"\":\n",
        "  after_name=出力ファイル名+\".safetensors\"\n",
        "  after=os.path.join(出力するフォルダ,after_name)\n",
        "  if os.path.exists(base):\n",
        "    os.rename(base,after)\n",
        "  else:\n",
        "    print(\"埋め込みファイルが見つかりませんでした。\")\n",
        "else:\n",
        "  after=base\n",
        "\n",
        "print(f\"\"\"\\033[34m\n",
        "学習が終了しました\n",
        "path: {after}\\033[0m\n",
        "\"\"\")\n",
        "\n",
        "if 終了したらランタイムを切断:\n",
        "  from google.colab import runtime\n",
        "  print(\"ランタイムを切断中...\")\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJteaxBCoPKM"
      },
      "source": [
        "#説明書"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3nODsN-mW21"
      },
      "outputs": [],
      "source": [
        "#@title 埋め込みを適用 {display-mode: \"form\"}\n",
        "\n",
        "\n",
        "# @markdown * Repo_id_or_path : hugface_idまたはfile_pathの入力をお願いします。\n",
        "\n",
        "# @markdown * token : 埋め込みを呼び出す場合に\"Prompt\"または\"N_prompt\"のいずれかに入力お願いします。\n",
        "\n",
        "# @markdown * weight_name : Repo_idの場合にファイル名前を指定してください\n",
        "\n",
        "# @markdown  ーstep.3の終了後に使用可能です\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADhtGAW9qhmv"
      },
      "outputs": [],
      "source": [
        "#@title プロンプトの特殊トークン {display-mode: \"form\"}\n",
        "\n",
        "# @markdown >ランダムワード\n",
        "# @markdown\n",
        "# @markdown * {cat,dog},cute = \"cat , cute\" / \"dog , cute\"\n",
        "# @markdown * color,{blue,red,green} = \"color , blue\" / \"color , red\" / \"color , green\"\n",
        "\n",
        "#@markdown >''=文字のスイッチ\n",
        "\n",
        "#@markdown * man,{boy,girl, ' '} = \"man\" / \"man,boy\" / \"man,girl\"\n",
        "\n",
        "#@markdown >file_nameの特殊トークンについて\n",
        "\n",
        "#@markdown ファイル名にパラメータなどの値を入力できます。\n",
        "\n",
        "#@markdown * {prompt} : Prompt\n",
        "\n",
        "#@markdown * {seed} : seed値\n",
        "\n",
        "#@markdown * {model_name} : model_name\n",
        "\n",
        "#@markdown * {g_scale} : guidance_scale\n",
        "\n",
        "#@markdown * {time} : 現在時刻\n",
        "\n",
        "#@markdown * {number} : 生成した回数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDhgcTiB1sbA"
      },
      "outputs": [],
      "source": [
        "#@title \"自動で条件を決めて生成\" の詳細 {display-mode: \"form\"}\n",
        "\n",
        "\n",
        "#@markdown  * 詳細設定を推奨の値に設定\n",
        "\n",
        "#@markdown   * 次の機能をオンにします\n",
        "#@markdown   * 画面に表示\n",
        "#@markdown   * 画像の質を上げるプロントを追加する\n",
        "#@markdown   * プロンプトアシストを使う ( MagicPrompt )\n",
        "#@markdown   * 推奨するネガティブプロントを使用\n",
        "#@markdown   * 条件をメタデーターとして追加する\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK6-GlDG5Dvx"
      },
      "outputs": [],
      "source": [
        "#@title プロンプトアシスタントの詳細 {display-mode: \"form\"}\n",
        "\n",
        "# @markdown アニメ調の画像に適したアシスタントは \" anime-anything-promptgen-v2 \"\n",
        "\n",
        "# @markdown 多目的のアシスタントは \" MagicPrompt-Stable-Diffusion \"\n",
        "\n",
        "# @markdown 使用しない場合は \" None \" の選択をお願いします"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIqEx5TDV2IA"
      },
      "outputs": [],
      "source": [
        "#@title 用語の説明 {display-mode: \"form\"}\n",
        "\n",
        "# @markdown * txt2img  : テキストから画像\n",
        "\n",
        "# @markdown * img2img : 画像から画像\n",
        "\n",
        "# @markdown * Inpaint : 書いた画像に色をつける\n",
        "\n",
        "# @markdown * txt2video : テキストから動画\n",
        "\n",
        "# @markdown * safe : より安定した安全な画像の生成(txt2img)\n",
        "\n",
        "# @markdown * seed (\"-1\"以上) / seed値を指定します。0の場合ランダムな数字を割り当てます。\n",
        "\n",
        "# @markdown * guidance_scale (5≦15 推奨\"7.5\") / promptの強さの値です。強すぎるとノイズが発生する一方、弱すぎると絵が崩壊します。\n",
        "\n",
        "# @markdown * history_d (\"rand_new\", \"rand_init\" )  推奨:\"rand_new\n",
        "\n",
        "# @markdown * moment(0.1≦1.0 ) 推奨\"0.8\"\n",
        "\n",
        "# @markdown * momentum_hist(-1.0≦1.0)  推奨\"0.2\"\n",
        "\n",
        "#@markdown * 拡散ステップ(1≦1000 推奨\"50\") / 計算をする回数を指定します。回数を減らすほど生成速度が速くなります\n",
        "\n",
        "# @markdown * 縦・横の大きさ ( 推奨\"512\" ) / 大きくすればするほど生成速度が遅くなります(img2img、Inpaint**以外のみ**)\n",
        "\n",
        "#@markdown  * safety_level(強さ) ： WEAK＜MEDIUM＜STRONG＜MAX\n",
        "\n",
        "#@markdown  * 条件を統一 : プロンプトアシスタントを使用するとき、最初の画像のプロンプトを繰り返し使用します\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB3pvcv0VZKd"
      },
      "outputs": [],
      "source": [
        "#@title デフォルト(値が未入力の場合) {display-mode: \"form\"}\n",
        "\n",
        "#@markdown >保存する先のパス\n",
        "#@markdown * デフォルトでは /content/Generated_images に保存されます。なければ作るようになっています。\n",
        "#@markdown * ドライブに保存する場合 /content/drive/MyDriveを最初につけてください\n",
        "\n",
        "# @markdown >file_name\n",
        "#@markdown * デフォルトは \"GIMG-{number}\" です\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0CbxSb2n8Re"
      },
      "outputs": [],
      "source": [
        "#@title 追記 {display-mode: \"form\"}\n",
        "\n",
        "# @markdown 2024.1.27日時点でmoment付きEuler または EulerA において、history_d を \"rand_init\" にすると、1枚目が崩壊するバグがあります。\n",
        "# @markdown なお、通常のEuler系のサンプラーでは起きません\n",
        "\n",
        "#@markdown 条件: moment:0.8、moment_hist:0.6\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoIXG55qgRsh"
      },
      "source": [
        "#Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJXQRW_E3AsI"
      },
      "source": [
        ">免責事項:\n",
        "*  このモデルは、趣味で作成したものであり、商用利用などは意図していません。\n",
        "*  本プロジェクトを利用することにより生じた一切の問題について、当方は一切責任を負いません。\n",
        "\n",
        "ー本プロジェクトとは、本画像生成ノートブックや、githubのページなどをさします\n",
        "___\n",
        ">本プロジェクトの目的\n",
        "* プログラミングの個人的な学習\n",
        "* diffusersをベースにした画像生成ノートブックです。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "謝辞\n",
        "\n",
        "本ノートブックの作成にあたり、オープンソースのリソースやフリーのツールを使用させていただきました。これらのリソースやツールがあったからこそ、本プロジェクトを実現することができました。\n",
        "\n",
        "この場を借りて、オープンソースのコミュニティや、フリーのツールを提供してくださった方々に感謝の意を表します。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ONEtEJyRGYSL",
        "iIEW0jvHK7I1",
        "a1QPxPSzF_aP",
        "OJteaxBCoPKM"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}