{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suzukimain/diffusers_in_Colab/blob/main/diffusers_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eicnuls7qg7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d3c985-8cb5-4471-c1fc-21a6005cd508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title   (option)ドライブに接続 { run: \"auto\", display-mode: \"form\"}\n",
        "Google_driveに接続 = True  # @param {type:\"boolean\"}\n",
        "\n",
        "conect_drive=False\n",
        "\n",
        "from google.colab import drive\n",
        "import google.colab.drive as drive\n",
        "if Google_driveに接続:\n",
        "    Gdrive=\"GoogleDrive: \\033[32m接続成功\\033[0m\"\n",
        "    if not drive._os.path.ismount('/content/drive'):\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            conect_drive=True\n",
        "        except:\n",
        "            Gdrive=\"GoogleDrive: \\033[31m接続失敗\\033[0m\"\n",
        "            conect_drive=False\n",
        "else:\n",
        "    Gdrive=\"GoogleDrive: \\033[33m接続なし\\033[0m\"\n",
        "    if drive._os.path.ismount('/content/drive'):\n",
        "        drive.flush_and_unmount()\n",
        "        conect_drive=False\n",
        "        print(\"GoogleDriveの接続を解除しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4UJqC_WpaGw"
      },
      "outputs": [],
      "source": [
        "#@title   #Step1.セットアップ (Setup) { run: \"auto\", display-mode: \"form\"}\n",
        "print(\"実行中…\")\n",
        "#if torch.cuda.device_count()==False:\n",
        "#  raise RuntimeError(\"deviceをGPUに変更お願いします\")\n",
        "\n",
        "import torch,os\n",
        "\n",
        "import locale #この2行は非常に重要\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "if \"conect_drive\" not in locals() and globals():\n",
        "    conect_drive=False\n",
        "\n",
        "\n",
        "need_install=True\n",
        "try:\n",
        "    import torch, diffusers ,transformers ,accelerate ,safetensors ,huggingface_hub ,omegaconf\n",
        "    need_install=False\n",
        "except:\n",
        "    need_install=True\n",
        "if \"step1_finish\" not in locals():\n",
        "    need_install=True\n",
        "\n",
        "\n",
        "if need_install:\n",
        "    !pip install diffusers transformers omegaconf accelerate sacremoses googletrans==3.1.0a0 -q\n",
        "    import torch\n",
        "    import diffusers\n",
        "    import transformers\n",
        "    import accelerate\n",
        "    import safetensors\n",
        "    import huggingface_hub\n",
        "    import omegaconf\n",
        "\n",
        "import diffusers ,transformers ,accelerate ,safetensors ,huggingface_hub ,omegaconf\n",
        "#transformers.utils.move_cache()\n",
        "\n",
        "import glob\n",
        "import gc\n",
        "import time\n",
        "import sys\n",
        "import requests\n",
        "import urllib.request\n",
        "import spacy\n",
        "import codecs\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import googletrans\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image,PngImagePlugin\n",
        "import datetime\n",
        "from IPython.display import display, Markdown\n",
        "from diffusers import (StableDiffusionPipeline, DPMSolverMultistepScheduler,\n",
        "                       StableDiffusionImg2ImgPipeline, DiffusionPipeline, AutoencoderKL,\n",
        "                       UNet2DConditionModel, PNDMScheduler,\n",
        "                       schedulers,TextToVideoZeroPipeline,\n",
        "                       StableDiffusionInpaintPipeline,\n",
        "                       StableDiffusionPipelineSafe,\n",
        "                      )\n",
        "from diffusers import (\n",
        "    DDPMScheduler,\n",
        "    DDIMScheduler,\n",
        "    PNDMScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "from diffusers.pipelines.stable_diffusion_safe import SafetyConfig\n",
        "from transformers import (pipeline, CLIPTextModel, CLIPTokenizer, AutoModel, AutoTokenizer)\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from googletrans import Translator\n",
        "from IPython.display import display, HTML\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import save_file\n",
        "from torch import Generator\n",
        "import imageio\n",
        "from base64 import b64encode\n",
        "from google.colab import drive\n",
        "import google.colab.drive as drive\n",
        "from multiprocessing import Process, Manager\n",
        "import multiprocessing as mp\n",
        "\n",
        "# safety_checker.pyファイルからIFSafetyCheckerクラスをインポート\n",
        "#from diffusers.pipelines.deepfloyd_if.safety_checker import IFSafetyChecker\n",
        "\n",
        "from diffusers import logging as df_logging\n",
        "from transformers import logging as tf_logging\n",
        "import threading\n",
        "df_logging.set_verbosity_error()\n",
        "tf_logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "step1_finish=True\n",
        "\n",
        "if drive._os.path.ismount('/content/drive'):\n",
        "    Connect_Gdrive=\"\\033[34mGoogleDrive: 接続成功\\033[0m\"\n",
        "else:\n",
        "    Connect_Gdrive=\"\\033[34mGoogleDrive: \\033[33m接続なし\\033[0m\"\n",
        "print(\"\\n\\033[34m___________________________________________\\033[0m\\n\")\n",
        "print(Connect_Gdrive)\n",
        "print(\"\\n\\033[32mセットアップが完了しました。\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_TXXMSVDc5h"
      },
      "outputs": [],
      "source": [
        "#@title  #Step2.モデル選択 (Model Selection){display-mode: \"form\"}\n",
        "\n",
        "#\"\\033[31m先にStep.1を実行してください\\033[0m\"\n",
        "\n",
        "\n",
        "# @markdown >使用するモデルの切り替え (model change)\n",
        "\n",
        "model_select = \"Counterfeit-V2.5(Anime)(better)\" # @param [\"stable diffusion-v2.1(basic)\", \"Counterfeit-V2.5(Anime)(better)\", \"loliDiffusion(Anime)\", \"waifu diffusion-v1.4(Anime)\", \"Anything-v3.0(Anime)\", \"Anything-v4.5(Anime)\", \"anything-midjourney-v-4-1(Anime)\", \"ACertainThing(Anime)\", \"anime-kawai-diffusion(Anime)\", \"AB4.5_AC0.2(Anime)\", \"basil_mix(Anime)\", \"Counterfeit(Anime)\", \"Counterfeit-V2.0(Anime)\", \"chilled_remix(Anime)\", \"Double-Exposure-Diffusion(Anime)\", \"EimisAnimeDiffusion_1.0v(Anime)\", \"7th_Layer(Anime)\", \"Riga_Collection(Anime)\", \"Waifu-Diffusers(Anime)\", \"JWST-Deep-Space-diffusion(space)\", \"sd-db-epic-space-machine(space_ship)\", \"spacemidj(space)\", \"nasa-space-v2(space)\", \"openjourney-v4(Reality)\", \"Realistic_Vision_V2.0(Reality)\", \"meinamix_meinaV10(Reality)\", \"search\"] {allow-input: true}\n",
        "del_word_list=[\"(basic)\",\"(Anime)\",\"(Reality)\",\"(space_ship)\",\"(space)\",\"(better)\"]\n",
        "for del_word in del_word_list:\n",
        "    model_select=model_select.replace(del_word, \"\" )\n",
        "#@markdown モデルの選択方法\n",
        "\n",
        "#@markdown * ボックスの右の三角を押すと出るリストから選択\n",
        "\n",
        "#@markdown * URLを入力 ( **hugfaceにあるモデルのみ** )\n",
        "\n",
        "#@markdown * モデル名を入力 ( **diffusersのみ** )\n",
        "\n",
        "#@markdown * ダウンロードしたモデルが保存されているパスを入力\n",
        "\n",
        "#@markdown *  **search** と入力すると全てのディレクトリから候補を探します。\n",
        "\n",
        "# @markdown >モードの切り替え (mode change)\n",
        "mode_select = \"Quick\" #@param [\"Nomal(better)\",\"Quick\"]\n",
        "\n",
        "#@markdown * \"Nomal\" 品質と生成時間のバランス重視です(fp32)\n",
        "\n",
        "#@markdown * \"Quick\" 少し品質が低下する代わりに生成時間が短縮します(fp16)\n",
        "\n",
        "auto = True  # @param {type:\"boolean\"}\n",
        "# @markdown モデル名前だけで検索するとき、hugface上で最もLikeが多いモデルを選択します。(推奨:ON)\n",
        "\n",
        "if \"step1_finish\" not in locals():\n",
        "    raise NameError(\"\\033[33m先にStep.1の実行をお願いします\\033[0m\")\n",
        "\n",
        "if \"count_number\" not in locals():\n",
        "    count_number=0\n",
        "    input_skip=False\n",
        "\n",
        "if \"model_url\" not in locals():\n",
        "    model_url=\"\"\n",
        "\n",
        "if \"token_dict\" not in locals():\n",
        "    token_dict=[]\n",
        "\n",
        "\n",
        "\n",
        "class version_sort:\n",
        "    def extract_version(self, version_string) -> str:\n",
        "        match = re.search(r'[vV\\-_](0?\\d+(\\.\\d+)*)', version_string)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "        else:\n",
        "            return \"0\"\n",
        "\n",
        "    def convert_version(self, version: str) -> int:\n",
        "        converted_version = 0\n",
        "        version_parts = version.split('.')\n",
        "        if len(version_parts) > 0:\n",
        "            for i in range(len(version_parts)):\n",
        "                if i == len(version_parts) - 1:\n",
        "\n",
        "                    converted_version += int(version_parts[i])\n",
        "                else:\n",
        "                    converted_version += int(version_parts[i]) * (100 ** (len(version_parts) - i - 1))\n",
        "        return converted_version\n",
        "\n",
        "    def sort(self,mylist) -> list:\n",
        "        version_dict = {}\n",
        "        for item in mylist:\n",
        "            version = self.extract_version(item)\n",
        "            converted_version = self.convert_version(version)\n",
        "            version_dict[item] = converted_version\n",
        "        sorted_list = sorted(version_dict, key=lambda x: version_dict[x], reverse=True)\n",
        "        return sorted_list\n",
        "\n",
        "version=version_sort()\n",
        "\n",
        "\n",
        "class Step2_class:\n",
        "    def __init__(self,model_select):\n",
        "\n",
        "        self.model_id, self.model_name, self.vae_name, self.model_file=\"\",\"\",\"\",\"\"\n",
        "        can_EN,input_url=False,False\n",
        "\n",
        "\n",
        "        self.Error_M1= (\n",
        "                   '''URLを読み込めませんでした。この機能がサポートしている形式は次の通りです。\n",
        "                      形式:\"https://huggingface.co/<repo_name>/<model_name>/blob/main/<path_to_file>.safetensors\"\n",
        "                      例1: \"https://huggingface.co/gsdf/Counterfeit-V3.0/blob/main/Counterfeit-V3.0.safetensors\"\n",
        "                      例2: \"https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.ckpt\"\n",
        "                      補足:huggingfaceにあれば、diffusersのタグがついていないモデルでも、ほとんどの場合使用できます。\n",
        "                    ''')\n",
        "        self.Error_M2= (\n",
        "                   '''hugface_pathを読み込めませんでした。この機能がサポートしている形式は次の通りです。\n",
        "                      形式: <repo_name>/<model_name>\"\n",
        "                      例1: \"Linaqruf/anything-v3.0\"\n",
        "                      例2: \"stabilityai/stable-diffusion-2-1\"\n",
        "                      補足:diffusersのタグがついているモデルのみを対象としています\n",
        "                      (下のモデル名をコピー&ペースト、または、model_selectの右側の三角を押すと出てくるドロップダウンからお選びください。)\n",
        "\n",
        "                      \"stable diffusion-v2.1\"\n",
        "                      \"waifu diffusion-v1.4\"\n",
        "                      \"Anything-v3.0\"\n",
        "                      \"anything-midjourney-v-4-1\"\n",
        "                      \"Anything-v4.5\"\n",
        "                      \"AB4.5_AC0.2\"\n",
        "                      \"basil_mix\"\n",
        "                      \"Waifu-Diffusers\"\n",
        "                      \"Double-Exposure-Diffusion\"\n",
        "                      \"openjourney-v4\"\n",
        "                      \"ACertainThing\"\n",
        "                      \"Counterfeit-V2.0\"\n",
        "                      \"Counterfeit-V2.5\"\n",
        "                      \"7th_Layer\"\n",
        "                      \"EimisAnimeDiffusion_1.0v\"\n",
        "                      \"Riga_Collection\"\n",
        "                      \"anime-kawai-diffusion\"\n",
        "                      \"Realistic_Vision_V2.0\"\n",
        "                      \"meinamix_meinaV10\"\n",
        "                      \"loliDiffusion\"\n",
        "                      ''')\n",
        "        self.Error_M3=(\n",
        "                  '''指定されたパスを認識できませんでした。次をお試しください\n",
        "                     ・ファイルのパスが存在するかの確認\n",
        "                     ・空白が混入していないかの確認(pathの最後に半角空白が意図せずつくことがあります)\n",
        "                     ・\"\\\"や、拡張子以外の\".\"などの特殊記号が含まれているかの確認(認識されない可能性があります)\n",
        "                  ''')\n",
        "\n",
        "        self.exts =  [\".safetensors\", \".ckpt\"]\n",
        "\n",
        "        self.exclude=[\n",
        "            \"safety_checker/model.safetensors\",\n",
        "            \"unet/diffusion_pytorch_model.safetensors\",\n",
        "            \"vae/diffusion_pytorch_model.safetensors\",\n",
        "            \"text_encoder/model.safetensors\",\n",
        "            \"safety_checker/model.ckpt\",\n",
        "            \"unet/diffusion_pytorch_model.ckpt\",\n",
        "            \"vae/diffusion_pytorch_model.ckpt\",\n",
        "            \"text_encoder/model.ckpt\",\n",
        "            \"VAEs/\",\n",
        "                 ]\n",
        "\n",
        "\n",
        "        #<model_select>:(<model_id>,<input_url>)\n",
        "        self.model_dict = {\n",
        "            \"stable diffusion-v2.1\" : (\"stabilityai/stable-diffusion-2-1\", False),\n",
        "            \"waifu diffusion-v1.4\": (\"hakurei/waifu-diffusion\", False),\n",
        "            \"Anything-v3.0\": (\"Linaqruf/anything-v3.0\", False),\n",
        "            \"anything-midjourney-v-4-1\": (\"Joeythemonster/anything-midjourney-v-4-1\", False),\n",
        "            \"Anything-v4.5\": (\"shibal1/anything-v4.5-clone\", False),\n",
        "            \"AB4.5_AC0.2\": (\"aioe/AB4.5_AC0.2\", False),\n",
        "            \"basil_mix\": (\"nuigurumi/basil_mix\",False),\n",
        "            \"Waifu-Diffusers\": (\"Nilaier/Waifu-Diffusers\",False),\n",
        "            \"Double-Exposure-Diffusion\": (\"joachimsallstrom/Double-Exposure-Diffusion\", False),\n",
        "            \"openjourney-v4\": (\"prompthero/openjourney-v4\", False),\n",
        "            \"ACertainThing\": (\"JosephusCheung/ACertainThing\", False),\n",
        "            \"Counterfeit-V2.0\": (\"gsdf/Counterfeit-V2.0\", False),\n",
        "            \"Counterfeit-V2.5\": (\"gsdf/Counterfeit-V2.5\", False),\n",
        "            \"chilled_remix\":(\"chilled_remix\",True),\n",
        "            \"chilled_reversemix\":(\"chilled_reversemix\",True),\n",
        "            \"7th_Layer\": (\"syaimu/7th_test\", False),\n",
        "            \"EimisAnimeDiffusion_1.0v\": (\"eimiss/EimisAnimeDiffusion_1.0v\", False),\n",
        "            \"JWST-Deep-Space-diffusion\" : (\"dallinmackay/JWST-Deep-Space-diffusion\",False),\n",
        "            \"Riga_Collection\": (\"natsusakiyomi/Riga_Collection\", False),\n",
        "            \"sd-db-epic-space-machine\" : (\"rabidgremlin/sd-db-epic-space-machine\", False),\n",
        "            \"spacemidj\" : (\"Falah/spacemidj\",False),\n",
        "            \"anime-kawai-diffusion\": (\"Ojimi/anime-kawai-diffusion\",False),\n",
        "            \"Realistic_Vision_V2.0\": (\"SG161222/Realistic_Vision_V2.0\",False),\n",
        "            \"nasa-space-v2\" : (\"sd-dreambooth-library/nasa-space-v2-768\", False),\n",
        "            \"meinamix_meinaV10\": (\"namvuong96/civit_meinamix_meinaV10\",False),\n",
        "            \"loliDiffusion\": (\"loliDiffusion\" ,True)\n",
        "            }\n",
        "\n",
        "        self.EN='''埋め込み: 有効\\n有効化の鍵: <EasyNegative>,<bad-hands>\\n\n",
        "                   ※埋め込みを使用する場合、「有効化の鍵」を＜＞ごとコピー＆ペーストしてください'''\n",
        "\n",
        "\n",
        "    def model_safe_check(self,model_list) ->str:\n",
        "        if len(model_list)>1:\n",
        "           for check_model in model_list:\n",
        "                match = bool(re.search(r\"(?i)[-＿]sfw\", check_model))\n",
        "                if match:\n",
        "                    return check_model\n",
        "        return model_list[0]\n",
        "\n",
        "\n",
        "    def key_check(self,keyword):\n",
        "        global key_dict\n",
        "        if \"key_dict\" not in globals():\n",
        "            key_dict = {}\n",
        "        key = str(keyword)\n",
        "        key_in = False\n",
        "        if key in key_dict:\n",
        "            if keyword == key_dict[key]:\n",
        "              key_in = True\n",
        "        key_dict[key] = keyword\n",
        "        return key_in\n",
        "\n",
        "    def check_url(self,url):\n",
        "        flag = True\n",
        "        try:\n",
        "            f = urllib.request.urlopen(url)\n",
        "            f.close()\n",
        "        except:\n",
        "            flag = False\n",
        "        return flag\n",
        "\n",
        "\n",
        "    def model_name_search(self,model_name):\n",
        "        #このautoを消して受け取るようにすれば、autoがオフでユーザーに選択を求める\n",
        "        #autoはhugfaceで最もLikeの数が多いモデルを読み込む\n",
        "        url = f\"https://huggingface.co/api/models?search={model_name}\"\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        with_like={}\n",
        "        choice_path=\"\"\n",
        "        repo_model_list = []\n",
        "        if len(data) > 0:\n",
        "            for item in data:\n",
        "                model_id,like,private_value,tag_value = item[\"modelId\"],item[\"likes\"],item[\"private\"],item[\"tags\"]\n",
        "                if (\"diffusers\" in tag_value and\n",
        "                    \"Flax\" not in tag_value and\n",
        "                    \"TPU\" not in tag_value and\n",
        "                     (not private_value)):\n",
        "                     repo_model_list.append(model_id)\n",
        "                     with_like.update({len(with_like) + 1: (model_id,like)})\n",
        "        if with_like:\n",
        "            if not auto:\n",
        "                print(\"以下のモデルパスが見つかりました。\")\n",
        "                if not len(with_like)==1:\n",
        "                    sorted_with_like = sorted(with_like.items(), key=lambda x: x[1][1], reverse=True)\n",
        "                    for i, (model_id, (model_name, like)) in enumerate(sorted_with_like, 1):\n",
        "                        print(f\"{i}.モデル名: {model_name}, 評価: {like}\")\n",
        "                    while True:\n",
        "                        choice = int(input(\"使用するモデルパスの選択: \"))\n",
        "                        if 1<=choice<=len(repo_model_list):\n",
        "                            choice_path=repo_model_list[choice-1]\n",
        "                            break\n",
        "                        else:\n",
        "                            print(f\"1~{len(repo_model_list)} までの数字の入力をお願いします\")\n",
        "                else:\n",
        "                    choice_path,like=with_like[1]\n",
        "            else:\n",
        "                max_pair = max(with_like.items(), key=lambda x: x[1][1])\n",
        "                choice_path = max_pair[1][0]\n",
        "        else:\n",
        "            raise ValueError(\"モデルが見つかりませんでした。model_select の変更をお試しください\")\n",
        "        print(f\"使用するモデルパスは{choice_path}です。\")\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "    def file_name_set(self,model_name):\n",
        "        url = f\"https://huggingface.co/api/models/{model_name}\"\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        choice_path=\"\"\n",
        "        file_value_n = []\n",
        "        siblings = data[\"siblings\"]\n",
        "        if data:\n",
        "            for item in siblings:\n",
        "                fi_path=item[\"rfilename\"]\n",
        "                if any(fi_path.endswith(ext) for ext in self.exts) and not any(fi_path.endswith(ex) for ex in self.exclude):\n",
        "                    file_value_n.append(fi_path)\n",
        "        else:\n",
        "            raise ValueError(\"使用可能なファイルが見つかりませんでした。\\nモデル名前の確認をお試しください\")\n",
        "        if file_value_n:\n",
        "            file_value=version.sort(file_value_n)\n",
        "            if not auto:\n",
        "                print(\"以下のモデルパスが見つかりました。\")\n",
        "                if not len(file_value)==1:\n",
        "                    sorted_with_like = sorted(file_value)\n",
        "                    for i, file_name in enumerate(sorted_with_like, 1):\n",
        "                        print(f\"{i}.ファイル名: {file_name}\")\n",
        "                    while True:\n",
        "                        choice = input(\"使用するモデルパスの選択: \")\n",
        "                        if not isinstance(choice, int):\n",
        "                            print(\"自然数のみ有効です\")\n",
        "                            continue\n",
        "                        if 1<=choice<=len(file_value):\n",
        "                            choice_path=file_value[choice-1]\n",
        "                            break\n",
        "                        else:\n",
        "                            print(f\"1~{len(file_value)} までの数字の入力をお願いします\")\n",
        "            else:\n",
        "                choice_path=self.model_safe_check(file_value)\n",
        "        else:\n",
        "            raise FileNotFoundError(\"指定されたリポジトリに使用可能なファイルが見つかりません\")\n",
        "        print(f\"使用するファイルパスは{choice_path}です。\")\n",
        "        return choice_path\n",
        "\n",
        "\n",
        "    def File_search(self):\n",
        "        search_path=\"\"\n",
        "        paths = []\n",
        "        for root, dirs, files in os.walk(\"/\"):\n",
        "            for file in files:\n",
        "                if any(file.endswith(ext) for ext in self.exts):\n",
        "                    path = os.path.join(root, file)\n",
        "                    if path not in self.exclude:\n",
        "                        if not path.startswith(\"/root/.cache\"):\n",
        "                            paths.append(path)\n",
        "        num_path=len(paths)\n",
        "        if num_path == 0:\n",
        "            raise FileNotFoundError(\"\\033[33mモデルファイルが見つかりませんでした\\033[0m\")\n",
        "        else:\n",
        "            print(f\"モデルファイルの候補が{num_path}個見つかりました。\")\n",
        "        for s, path in enumerate(paths, 1):\n",
        "            print(f\"{s}: {path}\")\n",
        "        num = int(input(f\"番号を入力してください(1〜{num_path}): \"))\n",
        "        if 1 <= num <= len(paths):\n",
        "            search_path=(paths[num-1])\n",
        "            print(f\"選択されたモデルファイル: {search_path}\\n\")\n",
        "            print('設定を変更するが、上記のモデルファイルをそのまま使う場合は、\"入力を飛ばす\"をオンにするのを推奨します\\n')\n",
        "        else:\n",
        "            raise TypeError(f\"\\033[33m無効な文字です。有効な数字: 1〜{len(paths)}\\033[0m\")\n",
        "        return search_path\n",
        "\n",
        "\n",
        "    def model_select_type_check(self,model_select: str):\n",
        "        repo_name, model_name, word, branch, file_name,model_id = \"\", \"\", \"\", \"\", \"\",\"\"\n",
        "        input_url=False\n",
        "        if model_select==\"search\":\n",
        "            model_path=self.File_search()\n",
        "            input_url=True\n",
        "        elif model_select.startswith(\"https://huggingface.co/\"):\n",
        "            input_url=True\n",
        "            if self.check_url(model_select)==False:\n",
        "                raise ValueError(self.Error_M1)\n",
        "            else:\n",
        "                model_path=model_select\n",
        "        elif os.path.isfile(model_select):\n",
        "            input_url=True\n",
        "            model_path=model_select\n",
        "        elif \"/\" in model_select and model_select.count(\"/\") == 1:\n",
        "            model_select_keyword = model_select.split(\"/\")\n",
        "            repo_name, model_name = model_select_keyword[:2]\n",
        "            index_url=f\"https://huggingface.co/{model_select}/blob/main/model_index.json\"\n",
        "            if self.check_url(index_url)==True:\n",
        "                file_path=self.file_name_set(model_select)\n",
        "                model_path=model_select\n",
        "            else:\n",
        "                raise ValueError(self.Error_M2)\n",
        "        else:\n",
        "            model_path=self.model_name_search(model_select)\n",
        "        return model_path,input_url\n",
        "\n",
        "\n",
        "    def diffusers_model_select(self,model_select):\n",
        "        if model_select in self.model_dict:\n",
        "            model_path,input_url = self.model_dict[model_select]\n",
        "            if input_url:\n",
        "                model_ids=self.model_name_search(model_path)\n",
        "                model_file_path=self.file_name_set(model_ids)\n",
        "                model_path=f\"https://huggingface.co/{model_ids}/blob/main/{model_file_path}\"\n",
        "        else:\n",
        "            model_path,input_url = self.model_select_type_check(model_select)\n",
        "        return model_path,input_url\n",
        "\n",
        "\n",
        "    def pipe_create(self,model_path,input_url):\n",
        "        if input_url:\n",
        "            base_pipe = StableDiffusionPipeline.from_single_file(\n",
        "                model_path,torch_dtype=torch.float16 if mode_select==\"Quick\" else torch.float32\n",
        "                ).to(\"cuda:0\")\n",
        "        else:\n",
        "            base_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                model_path,torch_dtype=torch.float16 if mode_select==\"Quick\" else torch.float32\n",
        "                ).to(\"cuda:0\")\n",
        "        return base_pipe\n",
        "\n",
        "\n",
        "stpe2=Step2_class(model_select)\n",
        "\n",
        "\n",
        "model_path,input_url=stpe2.diffusers_model_select(model_select)\n",
        "base_pipe=stpe2.pipe_create(model_path,input_url)\n",
        "\n",
        "gc.collect()\n",
        "if input_url:\n",
        "    print(f\"\\033[34mモデルPath:{model_path}\")\n",
        "else:\n",
        "    print(f\"\\033[34mモデルID: {model_path}\")\n",
        "print(\"モデルのセットアップが終了しました\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCtR5TwuUvY"
      },
      "outputs": [],
      "source": [
        "#@title  #Step3.パイプラインの設定 (Pipeline Setup){display-mode: \"form\"}\n",
        "\n",
        "# @markdown >パイプラインの種類\n",
        "\n",
        "パイプラインの種類= \"txt2img\" #@param [\"txt2img\", \"img2img\",\"Inpaint\",\"txt2video\",\"safe\"]\n",
        "# @markdown * txt2img  : テキストから画像\n",
        "\n",
        "# @markdown * img2img : 画像から画像\n",
        "\n",
        "# @markdown * Inpaint : 書いた画像に色をつける\n",
        "\n",
        "# @markdown * txt2video : テキストから動画\n",
        "\n",
        "# @markdown * safe : より安定して安全な画像の生成ができます(txt2img)\n",
        "\n",
        "#@markdown >vaeを選択\n",
        "vaeを指定 = \"default(better)\" # @param [\"default(better)\", \"waifu-diffusion\",\"Counterfeit-V2.5\",\"anything-v3.0\"]\n",
        "#@markdown defaultを選択した場合、モデルに含まれている本来のvaeを使用します\n",
        "\n",
        "#@markdown >スケジューラーを変更\n",
        "\n",
        "Scheduler_select = \"ddpm\" # @param [\"EulerA\", \"Euler\",\"dpm\",\"ddpm\",\"ddim\",\"pndm\",\"lms\"]\n",
        "if パイプラインの種類==\"txt2video\" and Scheduler_select!=(\"ddim\" or \"pndm\"):\n",
        "    print('txt2videoの場合、Schedulerは\"ddim\"or\"pndm\"のみ使用可能です。(Schedulerをddimに設定しました)')\n",
        "    Scheduler_select=\"ddim\"\n",
        "\n",
        "# @markdown ノイズの入力に使用するSchedulersを変更します。\n",
        "\n",
        "# @markdown * EulerA ( EulerAncestralDiscreteScheduler ) : 画像の結果にランダム性をもたらします\n",
        "\n",
        "# @markdown * Euler (   EulerDiscreteScheduler ) : 画像に統一性をもたせます\n",
        "\n",
        "#@markdown 上記以外のスケジューラーはmoment関連のパラメータが使用出来ません。\n",
        "\n",
        "#@markdown * DDPM : 生成速度を多少犠牲にする代わりに画質が高いです。(推奨)\n",
        "\n",
        "\n",
        "\n",
        "# @markdown >フィルターを調整\n",
        "\n",
        "\n",
        "\n",
        "# @markdown **注意事項 : 変更する時は注意して下さい**\n",
        "\n",
        "Filter_off = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown 追記:人が映り込んだだけでフィルタリングされることがあったので追加しました\n",
        "\n",
        "##@markdown ---\n",
        "\n",
        "##@markdown >model_selectのsearch選択のみ\n",
        "#入力を飛ばす = True  # @param {type:\"boolean\"}\n",
        "#if model_select!=\"search\":\n",
        "#  入力を飛ばす=False\n",
        "#input_skip=入力を飛ばす\n",
        "\n",
        "if パイプラインの種類==\"safe\":\n",
        "    if Scheduler_select ==\"EulerA\" or Scheduler_select == \"Euler\":\n",
        "        Scheduler_select=\"ddim\"\n",
        "        print('safe_pipelineでは、ソナー付きの\"EulerA\" or \"Euler\"を使用すると絵が崩壊するバグが発生しているので、ddimに設定しました。')\n",
        "\n",
        "if vaeを指定 == \"waifu-diffusion\":\n",
        "    vae_name=\"hakurei/waifu-diffusion\"\n",
        "\n",
        "elif vaeを指定 == \"Counterfeit-V2.5\":\n",
        "    vae_name= \"gsdf/Counterfeit-V2.5\"\n",
        "\n",
        "elif vaeを指定 == \"anything-v3.0\":\n",
        "    vae_name= \"Linaqruf/anything-v3.0\"\n",
        "\n",
        "#laion/CLIP-ViT-H-14-laion2B-s32B-b79K\n",
        "\n",
        "\n",
        "if not vaeを指定 == \"default(better)\":\n",
        "    vae_change=True\n",
        "    try:\n",
        "        vae = AutoencoderKL.from_pretrained(vae_name)\n",
        "    except:\n",
        "        vae = AutoencoderKL.from_pretrained(vae_name , subfolder=\"vae\")\n",
        "else:\n",
        "    vae=None\n",
        "    vae_change=False\n",
        "\n",
        "def print_format():\n",
        "    word_format=\"\"\n",
        "    if パイプラインの種類 == \"txt2img\":\n",
        "        word_format=\"パイプラインの種類: txt2img\\n\"\n",
        "    elif パイプラインの種類 == \"img2img\":\n",
        "        word_format=\"パイプラインの種類: img2img\\n\"\n",
        "    elif パイプラインの種類 == \"txt2video\":\n",
        "        word_format=\"パイプラインの種類: txt2video\"\n",
        "    elif パイプラインの種類 == \"Inpaint\":\n",
        "        word_format=\"パイプラインの種類: Inpaint\"\n",
        "    elif パイプラインの種類 == \"safe\":\n",
        "        word_format=\"パイプラインの種類: safe\"\n",
        "    return word_format\n",
        "\n",
        "word_format=print_format()\n",
        "\n",
        "\n",
        "def result():\n",
        "    if Filter_off == False:\n",
        "        filter_level = \"フィルターの強度:通常\"\n",
        "    else:\n",
        "        filter_level = \"\\033[33mフィルターの強度:無効\\033[0m\"\n",
        "    return filter_level\n",
        "\n",
        "\n",
        "if Scheduler_select==\"Euler\"or Scheduler_select==\"EulerA\":\n",
        "    if not os.path.exists(\"/content/script/Euler_mod\"):\n",
        "        os.makedirs(\"/content/script/Euler_mod\",exist_ok=True)\n",
        "        !git clone https://github.com/alexblattner/modified-euler-samplers-for-sonar-diffusers.git /content/script/Euler_mod\n",
        "    path_1 = \"/content/script/Euler_mod/EulerANew.py\"\n",
        "    path_2 = \"/content/script/Euler_mod/EulerNew.py\"\n",
        "    sys.path.append(path_1)\n",
        "    sys.path.append(path_2)\n",
        "    %cd /content/script/Euler_mod\n",
        "    try:\n",
        "        import EulerANew,EulerNew\n",
        "        from EulerANew import EulerA\n",
        "        from EulerNew import Euler\n",
        "    except:\n",
        "        !python EulerANew.py\n",
        "        !python EulerNew.py\n",
        "        import EulerANew,EulerNew\n",
        "        from EulerANew import EulerA\n",
        "        from EulerNew import Euler\n",
        "    %cd /content\n",
        "else:\n",
        "    EulerA=None\n",
        "    Euler=None\n",
        "\n",
        "\n",
        "\n",
        "EN='''埋め込み: 有効\\n有効化の鍵: <EasyNegative>,<bad-hands>\\n\n",
        "※埋め込みを使用する場合、「有効化の鍵」を＜＞ごとコピー＆ペーストしてください'''\n",
        "\n",
        "class make_main_pipe:\n",
        "    def __init__(self,base_pipe,Scheduler_select,vae):\n",
        "        self.base_pipe=base_pipe\n",
        "        self.Scheduler_select=Scheduler_select\n",
        "        self.vae=vae\n",
        "        self.pipe_args_setup = {}\n",
        "        self.stetas={}\n",
        "        self.main_name=\"\"\n",
        "\n",
        "    def main_pipe_set(self):\n",
        "        txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe=None,None,None,None,None\n",
        "        textual_inversion_dict ={\n",
        "            \"EasyNegativeV2.safetensors\": \"EasyNegative\",\n",
        "            \"bad-hands-5.pt\": \"bad-hands\",\n",
        "            }\n",
        "        Scheduler_dict={\n",
        "            \"ddpm\":(\"ddpmS\",DDPMScheduler),\n",
        "            \"ddim\":(\"ddim_S\",DDIMScheduler),\n",
        "            \"pndm\":(\"pndm_S\",PNDMScheduler),\n",
        "            \"lms\" :(\"lms_S\",LMSDiscreteScheduler),\n",
        "            \"dpm\": (\"dpm_S\",DPMSolverMultistepScheduler),\n",
        "            \"EulerA\":(\"EulerA_S\",EulerA),\n",
        "            \"Euler\":(\"Euler_S\",Euler),\n",
        "            }\n",
        "        pipe_class_dict={\n",
        "            \"txt2img\":(\"txt2img_pipe\",StableDiffusionPipeline),\n",
        "            \"img2img\":(\"img2img_pipe\",StableDiffusionImg2ImgPipeline),\n",
        "            \"txt2video\":(\"txt2video_pipe\",TextToVideoZeroPipeline),\n",
        "            \"Inpaint\":(\"Inpaint_pipe\",StableDiffusionInpaintPipeline),\n",
        "            \"safe\":(\"safe_pipe\",StableDiffusionPipelineSafe),\n",
        "            }\n",
        "        self.Scheduler_name,self.Scheduler_class = Scheduler_dict[self.Scheduler_select]\n",
        "        scheduler = self.Scheduler_class.from_config(self.base_pipe.scheduler.config)\n",
        "        self.stetas[\"vae\"]=self.vae if not vaeを指定==\"default(better)\" else self.base_pipe.vae\n",
        "        self.stetas[\"text_encoder\"]=self.base_pipe.text_encoder\n",
        "        self.stetas[\"tokenizer\"]=self.base_pipe.tokenizer\n",
        "        self.stetas[\"unet\"]=self.base_pipe.unet\n",
        "        self.stetas[\"scheduler\"]=scheduler\n",
        "        self.stetas[\"safety_checker\"]=self.base_pipe.safety_checker if not Filter_off else None\n",
        "        self.stetas[\"requires_safety_checker\"]=False if not Filter_off else True\n",
        "        self.stetas[\"feature_extractor\"]=self.base_pipe.feature_extractor\n",
        "        self.main_name,self.pipe_class=pipe_class_dict[パイプラインの種類]\n",
        "        if パイプラインの種類 == \"txt2img\":\n",
        "            txt2img_pipe =self.pipe_class(**self.stetas).to(\"cuda:0\")\n",
        "        elif パイプラインの種類 == \"img2img\":\n",
        "            img2img_pipe =self.pipe_class(**self.stetas).to(\"cuda:0\")\n",
        "        elif パイプラインの種類 == \"txt2video\":\n",
        "            txt2video_pipe =self.pipe_class(**self.stetas).to(\"cuda:0\")\n",
        "        elif パイプラインの種類 ==\"Inpaint\":\n",
        "            Inpaint_pipe =self.pipe_class(**self.stetas).to(\"cuda:0\")\n",
        "        elif パイプラインの種類 ==\"safe\":\n",
        "            safe_pipe =self.pipe_class(**self.stetas).to(\"cuda:0\")\n",
        "        else:\n",
        "            raise ValueError(\"想定外の処理がされました\")\n",
        "\n",
        "        if not パイプラインの種類==\"safe\":\n",
        "                try:#weight_name=,token=がないとエラーになる\n",
        "                    if パイプラインの種類 == \"txt2img\":\n",
        "                        txt2img_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                        txt2img_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                    elif パイプラインの種類 == \"img2img\":\n",
        "                        img2img_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                        img2img_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                    elif パイプラインの種類 == \"txt2video\":\n",
        "                        txt2video_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                        txt2video_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                    elif パイプラインの種類 ==\"Inpaint\":\n",
        "                        Inpaint_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"EasyNegativeV2.safetensors\", token=\"EasyNegative\")\n",
        "                        Inpaint_pipe.load_textual_inversion(\"embed/negative\", weight_name=\"bad-hands-5.pt\", token=\"bad-hands\")\n",
        "                    if \"EasyNegative\" and \"bad-hands\" in token_dict:\n",
        "                        token_dict.append(\"EasyNegative\")\n",
        "                        token_dict.append(\"bad-hands\")\n",
        "                except ValueError:\n",
        "                    if \"EasyNegative\" or \"bad-hands\" in token_dict:\n",
        "                        print(\"既に埋め込みは適用されています。\")\n",
        "                        EN=\"\\033[33m埋め込み: 適用済み\\033[34m\"\n",
        "                    else:\n",
        "                        EN=\"\\033[33m埋め込み: このモデルではsd1.5系列の埋め込みは使用不可です\\033[34m\"\n",
        "           # else:\n",
        "           #     print(\"\\033[31mこのパイプラインでは埋め込みがサポートされていません\\033[0m\")\n",
        "           #     EN=\"\\033[33m埋め込み: このモデルでは使用不可です\\033[34m\"\n",
        "        else:\n",
        "            EN=\"\\033[33m埋め込み: このモデルでは使用不可です\\033[0m\"\n",
        "       #if model_select==\"txt2img\":\n",
        "        #    txt2img_pipe.enable_vae_tiling()\n",
        "        return base_pipe,txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe\n",
        "\n",
        "MMP=make_main_pipe(base_pipe,Scheduler_select,vae)\n",
        "base_pipe,txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe=MMP.main_pipe_set()\n",
        "\n",
        "\n",
        "filter_level=result()\n",
        "\n",
        "\n",
        "model_print=(f\"model_path: {model_path}\")\n",
        "\n",
        "def k():\n",
        "    global fin\n",
        "    fin=True\n",
        "    return fin\n",
        "fin=k()\n",
        "#\\033[31mが赤、\\033[33mが黄色、\\033[34mが青、\\033[32mが緑、\\033[0mが白\n",
        "# \"\\033[32m\" は緑色に変更するための\"ANSI Escape Code\"であり、\"\\033[0m\"はデフォルトの文字色に戻すためのコードです。\n",
        "# \\033[38;2;0;255;255m　水色\n",
        "#\\033[38;2;74;229;110m　黄緑\n",
        "\n",
        "MS=\"____________________________________________________________________________\"\n",
        "Finish1=\"\\033[32m画像生成の準備が出来ました。手順に移ってください。\\033[0m\"\n",
        "Finish2=\"\\033[32m(Now that the image generation is ready, please proceed to step 3.)\\033[0m\"\n",
        "status=(f\"\"\"\n",
        "\\033[34m{MS}\\n\\n\n",
        "{model_print}\\n\\n\n",
        "Scheduler: {Scheduler_select}\\n\\n\n",
        "{word_format}\\n\n",
        "{filter_level}\\n\\n\n",
        "{Finish1}\n",
        "\\033[0m\"\"\")\n",
        "if Scheduler_select!=\"Euler\"and Scheduler_select!=\"EulerA\":\n",
        "    print('\\nmomentは、\"Scheduler_selectが \"Euler\"、\"EulerA\"のいずれかでのみ有効です。')\n",
        "print(status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXSW3nl8UT7x"
      },
      "outputs": [],
      "source": [
        "#@title  #Step4.画像の生成  (iamge generation){display-mode: \"form\"}\n",
        "#from re import escape\n",
        "#@markdown #自動生成\n",
        "\n",
        "自動で条件を決めて生成 = False #@param {type:\"boolean\"}\n",
        "auto_G=自動で条件を決めて生成\n",
        "#@markdown **操作がよくわからない方はチェックをつけて下さい。自動で生成します**\n",
        "\n",
        "#@markdown >この機能の詳細\n",
        "#@markdown  * 詳細設定を推奨の値に設定\n",
        "#@markdown  * プロンプトが入力されていない場合、初期値として \"1girl\" / \"1woman\" のいずれかを入力\n",
        "\n",
        "#@markdown  >次の機能をオンにします\n",
        "#@markdown   * 画面に表示\n",
        "#@markdown   * 画像の質を上げるプロントを追加する\n",
        "#@markdown   * プロンプトアシストを使う ( MagicPrompt )\n",
        "#@markdown   * 推奨するネガティブプロントを使用\n",
        "#@markdown   * 条件をメタデーターとして追加する\n",
        "\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown -----\n",
        "\n",
        "# @markdown >生成したい枚数を入力してください　/ Please enter the number of images you want to generate here.\n",
        "生成する枚数 = 25 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "枚数制限なし = False #@param {type:\"boolean\"}\n",
        "num_imgs=生成する枚数\n",
        "#if 生成する枚数 <= 0 or isinstance(生成する枚数, float):\n",
        "#   print(\"\\033[31m警告:無効な数字が入力された為デフォルトの1枚に設定しました\\033[0m\")\n",
        "#   生成する枚数 = 1\n",
        "#if 生成する枚数 is None:\n",
        "#  print(\"\\033[31m警告:無効な形式な為デフォルトの1枚に設定しました\\033[0m\")\n",
        "#  生成する枚数 = 1\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "# @markdown  >生成する画像の条件を**英語で**入力してください　(Please input the conditions for generating images in **English**.)\n",
        "\n",
        "Prompt = \"smail,1girl, {white,blue,red,purple} hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\" # @param [\"smail,1girl, white hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\",\"smail,1girl, {white,blue,red,purple} hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\", \"Please draw a beautiful Mount Fuji with the sun rising from the summit\", \"Earth, space, high resolution\"] {allow-input: true}\n",
        "画像の質を上げるプロントを追加する = True #@param {type:\"boolean\"}\n",
        "add_good_prompt=画像の質を上げるプロントを追加する\n",
        "#プロンプトアシストを使う = True #@param {type:\"boolean\"}\n",
        "日本語入力 = False #@param {type:\"boolean\"}\n",
        "JP_INPUT=日本語入力\n",
        "\n",
        "# @markdown >**プロンプトの例**\n",
        "# @markdown * cute, cat\n",
        "# @markdown * Earth, space, high resolution\n",
        "# @markdown * Please draw a beautiful Mount Fuji with the sun rising from the summit\n",
        "# @markdown * smail,1girl, white hair, medium hair, cat ears, looking at viewer, :3, cute,white_dress\n",
        "\n",
        "# @markdown >**ランダムワード**\n",
        "# @markdown  * {cat,dog},cute ＝ \"cat , cute\" / \"dog , cute\"\n",
        "# @markdown  * color,{blue,red,green} ＝ \"color , blue\" / \"color , red\" / \"color , green\"\n",
        "\n",
        "# @markdown ------\n",
        "# @markdown >プロンプトアシスタントの選択\n",
        "text_generate_model= \"MagicPrompt-Stable-Diffusion\" #@param [\"None\",\"MagicPrompt-Stable-Diffusion\",\"anime-anything-promptgen-v2\"]\n",
        "\n",
        "# @markdown アニメ調の画像に適したアシスタントは \" anime-anything-promptgen-v2 \"\n",
        "\n",
        "# @markdown 多目的のアシスタントは \" MagicPrompt-Stable-Diffusion \"\n",
        "\n",
        "# @markdown 使用しない場合は \" None \" の選択をお願いします\n",
        "\n",
        "条件を統一する = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown 最初の画像のプロンプトを繰り返し使用します\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "# @markdown >画像を入力として送リます。\n",
        "\n",
        "入力する画像 = \"/content/gas\" #@param {type:\"string\"}\n",
        "# @markdown パイプラインの種類を \"img2img\" or\"Inpaint\"とした場合のみに使えます\n",
        "\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "#@markdown #詳細設定\n",
        "\n",
        "seed値 = -1 # @param {type:\"number\"}\n",
        "seed_number=seed値\n",
        "guidance_scale = 7 #@param {type:\"slider\", min:5, max:15, step:0.5}\n",
        "momentum = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "momentum_hist = 0.6 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "history_d = \"rand_init\" # @param [\"rand_new\", \"rand_init\"]\n",
        "拡散ステップ = 25  # @param {type:\"number\"}\n",
        "## @markdown >img2img**以外**\n",
        "縦の大きさ = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\",\"1920\", \"3840\",\"4000\",\"7680\"]\n",
        "横の大きさ = \"512\" #@param [\"480\",\"512\",\"600\", \"768\",\"800\", \"1080\",\"1152\", \"1440\", \"1920\", \"3840\",\"4000\",\"7680\"]\n",
        "\n",
        "# @markdown >img2img、Inpaintのみ\n",
        "strength = 0.8 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "#@markdown >txt2video のみ\n",
        "video_length= 8  # @param {type:\"number\"}\n",
        "#@markdown >safeのみ\n",
        "safety_level = \"MAX\" # @param [\"MAX\",\"STRONG\",\"MEDIUM\",\"WEAK\"]\n",
        "#@markdown 強さ ： WEAK＜MEDIUM＜STRONG＜MAX\n",
        "\n",
        "if auto_G:\n",
        "    guidance_scale=8.5\n",
        "    momentum=0.95\n",
        "    momentum_hist=0.75\n",
        "    拡散ステップ=35\n",
        "    縦の大きさ=512\n",
        "    横の大きさ=512\n",
        "    strength=0.8\n",
        "    print(\"自動的にパラメーターが指定されました。オフにしたい場合は'自動で生成'のチェックを外してください\")\n",
        "\n",
        "\n",
        "sd_step=拡散ステップ\n",
        "\n",
        "height = int(縦の大きさ)\n",
        "width = int(横の大きさ)\n",
        "\n",
        "#@markdown >用語の説明\n",
        "\n",
        "# @markdown * seed (\"-1\"以上) / seed値を指定します。0の場合ランダムな数字を割り当てます。\n",
        "\n",
        "# @markdown * guidance_scale (5≦15 推奨\"7.5\") / promptの強さの値です。強すぎるとノイズが発生する一方、弱すぎると絵が崩壊します。\n",
        "\n",
        "# @markdown * history_d (\"rand_new\", \"rand_init\" )  推奨:\"rand_new\n",
        "\n",
        "# @markdown * moment(0.1≦1.0 ) 推奨\"0.8\"\n",
        "\n",
        "# @markdown * momentum_hist(-1.0≦1.0)  推奨\"0.2\"\n",
        "\n",
        "#@markdown * 拡散ステップ(1≦1000 推奨\"50\") / 計算をする回数を指定します。回数を減らすほど生成速度が速くなります\n",
        "\n",
        "# @markdown * 縦・横の大きさ ( 推奨\"512\" ) / 大きくすればするほど生成速度が遅くなります(img2img、Inpaint**以外のみ**)\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "# @markdown >必要であればネガティブプロンプトを入力してください。人物を生成するときにおすすめです\n",
        "\n",
        "# @markdown よくわからない方ボタンを押してください。おすすめのネガティブプロントを使います\n",
        "\n",
        "## @markdown (If necessary, please enter a negative prompt. It is recommended for generating characters.)\n",
        "\n",
        "N_prompt = \"elf ears:1.0,logo:1.1,character:2.0,bad hands\"  # @param {type:\"string\"}\n",
        "推奨するネガティブプロントを使用 = True #@param {type:\"boolean\"}\n",
        "# @markdown ネガティブプロンプトとは、**ネガティブな要素を除く**ものです。\n",
        "\n",
        "## @markdown (Negative prompts are used to exclude negative elements from an image. For example, you can use a negative prompt to exclude low quality images or images that are not beautiful.)\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "#@markdown >保存する先を指定します\n",
        "\n",
        "## @markdown (If you would like to specify a location to save the generated image, please enter the path.)\n",
        "\n",
        "保存する先のパス = \"\"  # @param {type:\"string\"}\n",
        "#@markdown * デフォルトでは /content/Generated_images に保存されます。なければ作るようになっています。\n",
        "保存する先のパス = 保存する先のパス.strip()\n",
        "\n",
        "\n",
        "#@markdown * ドライブに保存する場合 /content/drive/MyDrive を最初につけてください\n",
        "\n",
        "# @markdown >file_nameを指定します\n",
        "\n",
        "#@markdown デフォルトは \"GIMG-{number}\" です\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown >file_nameの特殊トークンについて\n",
        "\n",
        "#@markdown ファイル名にパラメータなどの値を入力できます。\n",
        "\n",
        "#@markdown * {prompt} : Prompt\n",
        "\n",
        "#@markdown * {seed} : seed値\n",
        "\n",
        "#@markdown * {model_name} : model_name\n",
        "\n",
        "#@markdown * {g_scale} : guidance_scale\n",
        "\n",
        "#@markdown * {time} : 現在時刻\n",
        "\n",
        "#@markdown * {number} : 生成した回数\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "# @markdown >グリッド画像の設定\n",
        "\n",
        "横の画像数 = 5 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "num_grid=int(横の画像数)\n",
        "##@markdown 0の場合は、自動で設定します。\n",
        "\n",
        "# @markdown ------\n",
        "\n",
        "# @markdown >オプション\n",
        "\n",
        "画像を表示 = True  # @param {type:\"boolean\"}\n",
        "グリッド画像を表示 = True  # @param {type:\"boolean\"}\n",
        "画像情報を表示 = True  # @param {type:\"boolean\"}\n",
        "条件をメタデーターとして追加する = True  # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "警告メッセージを非表示 = False #@param {type:\"boolean\"}\n",
        "\n",
        "if \"can_EN\" not in locals():\n",
        "    can_EN = False\n",
        "\n",
        "\n",
        "\n",
        "if not add_good_prompt and not 警告メッセージを非表示:\n",
        "    print('\\033[33m\"画像の質を上げるプロントを追加する\"がオフになっています。')\n",
        "\n",
        "def obj_check(value):\n",
        "    global obj_list\n",
        "    init=False\n",
        "    reuse=False\n",
        "    if \"obj_list\" not in globals():\n",
        "        obj_list={}\n",
        "        init=True\n",
        "    key = value + \"_old\"\n",
        "    if not init:\n",
        "        if key in obj_list:\n",
        "            old_Value=obj_list[key]\n",
        "            if old_Value is value or old_Value==str(value):\n",
        "                reuse=True\n",
        "    obj_list[key] = value\n",
        "    return reuse\n",
        "\n",
        "\n",
        "def run_html_js(path,moji):\n",
        "    import datetime\n",
        "    num=len(path)\n",
        "    now_a = datetime.datetime.now()\n",
        "    datetimes = now_a.strftime(\"%Y%m%d%H%M%S\")\n",
        "    html_dis = f'''\n",
        "    <style>\n",
        "      #clipborad-text-{datetimes} {{\n",
        "        border: none; /* 枠線を消す */\n",
        "        color: #0ff; /* 文字色を青にする */\n",
        "        font-size: 15px; /* 文字の大きさを16pxにする */\n",
        "      }}\n",
        "    </style>\n",
        "    <span style=\"color: #4ae56e\" font-size:16px>{moji}</span> <!-- <p>タグを<span>タグに変更 -->\n",
        "    <input type=\"text\" value=\"{path}\" id=\"clipborad-text-{datetimes}\" size=\"{num}\" readonly> <!-- size属性とid属性を追加 -->\n",
        "    <button id=\"copy-button-{datetimes}\" onclick=\"copyToClipboard('{datetimes}')\">Copy</button> <!-- id属性とonclick属性を追加 -->\n",
        "    '''\n",
        "    js_code = '''\n",
        "    function copyToClipboard(datetimes) {\n",
        "      var copyText = document.getElementById(\"clipborad-text-\" + datetimes); // datetimeを結合\n",
        "      var copyButton = document.getElementById(\"copy-button-\" + datetimes); // datetimeを結合\n",
        "      copyText.select();\n",
        "      navigator.clipboard.writeText(copyText.value);\n",
        "      document.execCommand(\"copy\");\n",
        "      copyButton.textContent = \"Copied!\"; // ボタンの文字を変更\n",
        "      setTimeout(function() {\n",
        "        copyButton.textContent = \"Copy\"; // 1秒後に元に戻す\n",
        "        }, 1000);\n",
        "    }\n",
        "    '''\n",
        "    display(HTML(html_dis))\n",
        "    display(HTML('<script>{}</script>'.format(js_code)))\n",
        "\n",
        "\n",
        "def img_set(path):\n",
        "    #対策↓:AttributeError: 'str' object has no attribute 'seek'\n",
        "    if os.path.isfile(path):\n",
        "        init_image = Image.open(path)\n",
        "        init_image = init_image.resize((height, width))\n",
        "    else:\n",
        "        init_image = None\n",
        "        if パイプラインの種類==\"txt2img\"or\"safe\":\n",
        "            raise FileNotFoundError('\\033[31m\"入力する画像\"のpathが存在しません。使用しない場合は空白にお願いします\\033[0m')\n",
        "    return init_image\n",
        "\n",
        "\n",
        "class Scheduler_setup(make_main_pipe):\n",
        "    def __init__(self):\n",
        "        if パイプラインの種類==\"txt2img\":\n",
        "            self.main_name=txt2img_pipe\n",
        "        elif パイプラインの種類==\"img2img\":\n",
        "            self.main_name=txt2img_pipe\n",
        "        elif パイプラインの種類==\"txt2video\":\n",
        "            self.main_name=txt2video_pipe\n",
        "        elif パイプラインの種類==\"Inpaint\":\n",
        "            self.main_name=Inpaint_pipe\n",
        "        elif パイプラインの種類==\"safe\":\n",
        "            self.main_name=safe_pipe\n",
        "        else:\n",
        "            self.main_name=None\n",
        "            raise TypeError(\"想定外の処理です\")\n",
        "\n",
        "    def moment_set(self,Scheduler_select,vae):\n",
        "        if Scheduler_select==\"Euler\" or Scheduler_select==\"EulerA\":\n",
        "            self.main_name.scheduler.history_d =history_d\n",
        "            self.main_name.scheduler.momentum = momentum\n",
        "            self.main_name.scheduler.momentum_hist = momentum_hist\n",
        "sc_set=Scheduler_setup()\n",
        "sc_set.moment_set(Scheduler_select,vae)\n",
        "if (not Prompt.endswith(\",\")) and (Prompt is not None):\n",
        "    Prompt=Prompt+\",\"\n",
        "\n",
        "img_dir=False\n",
        "img_dir_num=1\n",
        "img_path=\"\"\n",
        "img_dict = []\n",
        "if パイプラインの種類==\"img2img\":\n",
        "    if os.path.isfile(入力する画像) and 入力する画像.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        img_path=入力する画像\n",
        "    elif os.path.isdir(入力する画像):\n",
        "        files = os.listdir(入力する画像)\n",
        "        img_ext = [\".jpg\", \".png\",\".jpeg\"]\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1]\n",
        "            if ext in img_ext:\n",
        "                img_path = os.path.join(入力する画像, file)\n",
        "                img_dict.append(img_path)\n",
        "        if img_dict:\n",
        "            img_dir=True\n",
        "            img_dir_num=len(img_dict)\n",
        "        else:\n",
        "            raise FileNotFoundError(\"指定されたフォルダ内に画像が見つかりませんでした\")\n",
        "    else:\n",
        "        raise FileNotFoundError('入力する画像が見つかりませんでした。画像を入力しない場合は、Step.1のパイプラインの種類を\"txt2img\"に変更お願いします')\n",
        "\n",
        "if not img_dir:\n",
        "    num=生成する枚数\n",
        "else:\n",
        "    num=生成する枚数*(len(img_dict))\n",
        "\n",
        "if JP_INPUT:\n",
        "    tr = Translator()\n",
        "    Prompt_2_a = tr.translate(Prompt, src=\"ja\", dest=\"en\").text\n",
        "    Prompt_2=Prompt_2_a\n",
        "else:\n",
        "    Prompt_2=Prompt\n",
        "\n",
        "def txt_pipe(text_generate_model):\n",
        "    if auto_G:\n",
        "        text_generate_model=\"MagicPrompt-Stable-Diffusion\"\n",
        "    txt_pipe_dict={\"MagicPrompt-Stable-Diffusion\":\"Gustavosta/MagicPrompt-Stable-Diffusion\",\n",
        "                   \"anime-anything-promptgen-v2\":\"FredZhang7/anime-anything-promptgen-v2\",\n",
        "                   \"None\":\"\"\n",
        "                  }\n",
        "    if not text_generate_model==\"None\":\n",
        "        txt_model_name= str(txt_pipe_dict[text_generate_model])\n",
        "        model = AutoModelForCausalLM.from_pretrained(txt_model_name)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(txt_model_name)\n",
        "        nlp = pipeline('text-generation', model=model, tokenizer=tokenizer,pad_token_id=50256)\n",
        "    else:\n",
        "        try:\n",
        "            nlp=nlp\n",
        "        except:\n",
        "            nlp=None\n",
        "    return nlp\n",
        "\n",
        "need_txt_pipe=obj_check(text_generate_model)\n",
        "if need_txt_pipe:\n",
        "    nlp=txt_pipe(text_generate_model)\n",
        "else:\n",
        "    try:\n",
        "        nlp=nlp\n",
        "    except:\n",
        "        nlp=txt_pipe(text_generate_model)\n",
        "\n",
        "\n",
        "txt_generator = torch.Generator(\"cpu\")\n",
        "\n",
        "class txt_model_setup:\n",
        "    def __init__(self,nlp,Prompt,Prompt_2,add_good_prompt,auto_G,JP_INPUT,text_generate_model,N_prompt):\n",
        "        global Prompt_list , make_images_list\n",
        "        Prompt_list=[]\n",
        "        make_images_list=[]\n",
        "        self.text_model_name=None\n",
        "        self.pipe_name=None\n",
        "        Prompt=Prompt\n",
        "        self.N_prompt=N_prompt\n",
        "        Prompt_2=Prompt_2\n",
        "        self.add_good_prompt=add_good_prompt\n",
        "        self.auto_G=auto_G\n",
        "        self.tokens=None\n",
        "        JP_INPUT=JP_INPUT\n",
        "        self.txt_model_name=\"\"\n",
        "        self.txt_pipe_name=\"\"\n",
        "        nlp=nlp\n",
        "        self.good_word = \"masterpiece:2.0,best quality,high quality,\"\n",
        "        text_generate_model=text_generate_model\n",
        "        if self.add_good_prompt or self.auto_G:\n",
        "            self.mini_prompt=True\n",
        "        else:\n",
        "            self.mini_prompt=False\n",
        "\n",
        "\n",
        "\n",
        "    def get_tokens_as_list(self,word_list):\n",
        "        tokens_list = []\n",
        "        for word in word_list:\n",
        "            tokenized_word = self.tokenizer_with_prefix_space([word], add_special_tokens=False).input_ids[0]\n",
        "            tokens_list.append(tokenized_word)\n",
        "        return tokens_list\n",
        "\n",
        "    def p_token(self,Prompt):\n",
        "        self.tokens = int(len(self.tokenizer.tokenize(Prompt)))\n",
        "        return self.tokens\n",
        "    def txt_G(self,nlp,Prompt_2):\n",
        "        n_word=[\"EasyNegative\",\"bat_hands\",\"white background\",\" simple background\",\"  simple background\",\"Loss of eye highlights\",\"simple background\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"bad hands\",\"bad legs\",\"worst quality\",\"low quality\",\"Not five fingers\",\"blurred\",\"Missing finger\",\"Simple background\",\"Cat with deformed face\",\"medium quality\",\"purple hair\",\"Loss of eye highlights\",\"Fingers fused together\",\"Writing Sweet Fingers\",\"deleted\",\"lowres\",\"Low quality animals\",\"deformed animals\",\"hands emerging from impossible places\",\"bad anatomy\",\"more than three limbs hands/legs\",\"low resolution\",\"blurry\",\"absurdres\",\"pixelated\",\"sketchy\",\"nonsensical anatomy\",\"unrealistic pose\",\"mosaic\",\"unclear details\",\"distorted colors\",\"unrealistic proportions\",\"poor quality\",\"fuzzy\",\"missing head:1.6\",\"out of focus\",\"hazy\",\"grainy\",\"text\",\"error\",\"missing fingers:0.9\",\"extra digit\",\"fewer digits\",\"cropped\",\"jpeg artifacts\",\"signature\",\"watermark\",\"username\",\"standard quality\",\"bad feet_hand_finger_leg_eye\",\"bad\",\"text font ui\",\"bad shadow\",\"poorly drawn\",\"black-white\",\"ugly\",\"duplicate\",\"mutation\",\"mutilated\",\"malformed mutated:1.1\",\"malformed:1.1\",\"The background is incoherent\",\"simple background\",\"low-quality background\",\"low background\",\"bad body\",\"long body\",\"broken limb\",\"anatomical nonsense\",\"extra limbs\",\"missing limb\",\"incorrect limb\",\"multiple heads\",\"twisted head\",\"poorly drawn face\",\"1 unit with multiple heads:1.3\",\"heads together:1.0\",\"abnormal eye:1.2 proportion\",\"cropped:1.0\",\"bad eyes\",\"fused eyes\",\"poorly drawn eyes\",\"bad mouth\",\"poorly drawn mouth\",\"bad tongue\",\"too long tongue\",\"bad ears\",\"poorly drawn ears\",\"extra ears\",\"heavy ears\",\"long neck\",\"too thick neck\",\"bad neck\",\"bad breasts\",\"missing arms\",\"disappearing arms\",\"extra arms\",\"three arms:2.0\",\"mutated hands and fingers\",\"fused hand\",\"missing fingers\",\"extra digits\",\"huge thighs\",\"disappearing thigh\",\"missing thighs\",\"extra thighs\",\"bad feet\",\"huge calf\",\"disappearing legs\",\"bad gloves\",\"fused gloves\",\"beard\",\"artist name\",\"text watermark\",\"unnatural\",\"obviously wrong\",\"distorted face\",\"floating hair\",\"floating body parts\",\"severed body parts\",\"incorrect leg position\",\"deformed\",\"fused body and hands\",\"disregard of physics\",\"distorted shape\",\"doll-like object not present in the image\",\"body fusion\",\"abnormal fingers\",\"fingers resembling fish fins\",\"dot eyes\",\"unclear background\",\"mosaic\",\"body bending\",\"incorrect leg-to-torso ratio\",\"excessively large breasts\",\"unsettling appearance\",\"eyes filled with solid color\",\"lack of lower body\",\"splitting\",\"creepy doll-like appearance\",\"distorted eyes\",\"lines on the skin\",\"legs bending in unnatural directions\",\"abnormal finger count\",\"missing arms\",\"floating hands\",\"lack of nose or mouth\",\"incorrect body part ratios\",\"bad\",\"longbody\",\"lowres\",\"bad anatomy\",\"bad hands\",\"missing fingers\",\"Distorted eye contour\",\"Missing part from the ankles onward\",\"extra digit\",\"fewer digits\",\"split wings\",\"Vampire wings floating in the air\",\"bad wing\",\"wonder egg priority\",\"egg priority\",\"demon\"]\n",
        "        if not N_prompt==\"\":\n",
        "            words = N_prompt.split(\",\")\n",
        "            n_word.extend(words)\n",
        "        if self.mini_prompt==True:\n",
        "            self.max_length=64\n",
        "        else:\n",
        "            self.max_length=74\n",
        "\n",
        "        Prompt_4_M = nlp(Prompt_2, max_length=self.max_length, num_return_sequences=10 ,repetition_penalty=1.2, early_stopping=False ,do_sample=True, temperature=0.4, top_k=10)\n",
        "        for V in range(len(Prompt_4_M)):\n",
        "            Prompt_4_M[V] = str(Prompt_4_M[V]['generated_text']).replace('  ', '').lstrip(',')\n",
        "        Prompt_4_I=''.join(Prompt_4_M)\n",
        "        Prompt_4_I=Prompt_4_M[0]\n",
        "        af_text=\"\"\n",
        "        af_text.replace(\",,\", \",\")\n",
        "        for np_word in n_word:\n",
        "            af_text = Prompt_4_I.replace(np_word, \"\")\n",
        "        if self.mini_prompt==True:\n",
        "            Prompt_4=self.good_word+af_text\n",
        "        else:\n",
        "            Prompt_4=af_text\n",
        "        return Prompt_4\n",
        "\n",
        "    def easy_prompt(self,nlp,Prompt_2,text_generate_model):\n",
        "        if self.auto_G:\n",
        "            text_generate_model=\"MagicPrompt-Stable-Diffusion\"\n",
        "        txt_pipe_dict={\"MagicPrompt-Stable-Diffusion\":(\"Gustavosta/MagicPrompt-Stable-Diffusion\",\"MagicPrompt_base\",\"MagicPrompt_tokenizer\",\"MagicPrompt_with\"),\n",
        "                       \"anime-anything-promptgen-v2\":(\"FredZhang7/anime-anything-promptgen-v2\",\"AnythingPrompt_base\",\"AnythingPrompt_tokenizer\",\"AnythingPrompt_with\"),\n",
        "                       \"None\":(\"\",\"\",\"\",\"\")\n",
        "                       }\n",
        "        self.txt_model_name,self.model,self.tokenizer,self.tokenizer_with_prefix_space = txt_pipe_dict[text_generate_model]\n",
        "        Prompt_2_G=str(Prompt_2)\n",
        "        contents = re.findall(\"\\{(.*?)\\}\", Prompt_2_G)\n",
        "        count = 0\n",
        "        for content in contents:\n",
        "            if not content or len(content) == 0:\n",
        "                continue\n",
        "            lst = content.split(\",\")\n",
        "            choice = random.choice(lst)\n",
        "            Prompt_2_G = re.sub(\"\\{.*?\\}\", choice, Prompt_2_G, count=1)\n",
        "            count += 1\n",
        "        if text_generate_model == \"None\":\n",
        "            self.good_word = \"masterpiece:2.0,best quality,high quality,\"\n",
        "            text_model_name =\"\"\n",
        "            if self.mini_prompt:\n",
        "                Prompt_4=self.good_word+Prompt_2_G\n",
        "            else:\n",
        "                Prompt_4 = Prompt_2_G\n",
        "        else:\n",
        "            Prompt_4 = self.txt_G(nlp,Prompt_2_G)\n",
        "        return Prompt_4\n",
        "\n",
        "\n",
        "    def main_task(self,nlp,Prompt_2):\n",
        "        Prompt_4=self.easy_prompt(nlp,Prompt_2,text_generate_model)\n",
        "        return Prompt_4\n",
        "    def sub_task(self,nlp,Prompt_2,Prompt_list,num):\n",
        "        for U in range(num):\n",
        "            #何もないものをリストに入れしまっている\n",
        "            Prompt_4=self.main_task(nlp,Prompt_2)\n",
        "            Prompt_list.append(Prompt_4)\n",
        "\n",
        "tms=txt_model_setup(nlp,Prompt,Prompt_2,add_good_prompt,auto_G,JP_INPUT,text_generate_model,N_prompt)\n",
        "CPU_P_2 = threading.Thread(target=tms.sub_task,args=(nlp,Prompt_2,Prompt_list,num))\n",
        "if mode_select==\"txt2video\":\n",
        "    Prompt_4= tms.main_task(nlp,Prompt_2)\n",
        "else:\n",
        "    CPU_P_2.start()\n",
        "    Prompt_4=\"\"\n",
        "\n",
        "\n",
        "if 推奨するネガティブプロントを使用 or 自動で条件を決めて生成 :\n",
        "    おすすめのネガティブプロント = \",Loss of eye :1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0,bad hands:2.0,bad legs:2.0,EasyNegative,bat_hands:1.3,worst quality:2.0, low quality:2.0,Not five fingers:2.0,blurred,Simple_background:2.0,Missing finger:1.7,Cat with deformed face:1.3 ,medium quality, purple hair,Loss of eye highlights:1.5,Fingers fused together:1.3,Writing Sweet Fingers:2.0 ,deleted:0.5, lowres,Low quality animals, deformed animals ,hands emerging from impossible places:1.7, bad anatomy, more than three limbs hands/legs:1.5, low resolution, blurry, absurdres,pixelated, sketchy, nonsensical anatomy, unrealistic pose, mosaic, unclear details, distorted colors, unrealistic proportions, poor quality, fuzzy, missing head:1.6, out of focus, hazy, grainy, text, error, missing fingers:0.9, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, standard quality, bad feet_hand_finger_leg_eye, bad, text font ui, bad shadow, poorly drawn, black-white, ugly, duplicate, mutation, mutilated, malformed mutated:1.1, malformed:1.1, The background is incoherent, simple background, low-quality background, low background, bad body, long body, broken limb, anatomical nonsense, extra limbs, missing limb, incorrect limb, multiple heads, twisted head, poorly drawn face, 1 unit with multiple heads:1.3, heads together:1.0, abnormal eye:1.2 proportion, cropped:1.0, bad eyes, fused eyes, poorly drawn eyes, bad mouth, poorly drawn mouth, bad tongue, too long tongue, bad ears, poorly drawn ears, extra ears, heavy ears, long neck, too thick neck, bad neck,  bad breasts, missing arms, disappearing arms, extra arms, three arms:2.0, mutated hands and fingers, fused hand, missing fingers, extra digits, huge thighs, disappearing thigh, missing thighs, extra thighs, bad feet, huge calf, disappearing legs, bad gloves, fused gloves, beard, artist name, text watermark, unnatural, obviously wrong, distorted face, floating hair, floating body parts, severed body parts, incorrect leg position, deformed, fused body and hands, disregard of physics, distorted shape, doll-like object not present in the image, body fusion, abnormal fingers, fingers resembling fish fins, dot eyes, unclear background, mosaic, body bending, incorrect leg-to-torso ratio, excessively large breasts, unsettling appearance, eyes filled with solid color, lack of lower body, splitting, creepy doll-like appearance, distorted eyes, lines on the skin, legs bending in unnatural directions, abnormal finger count, missing arms, floating hands, lack of nose or mouth,, incorrect body part ratios, bad, longbody, lowres, bad anatomy, bad hands, missing fingers,  Distorted eye contour, Missing part from the ankles onward, extra digit, fewer digits, split wings, Vampire wings floating in the air, bad wing, comic,chainsaw man,demon\"\n",
        "else:\n",
        "    おすすめのネガティブプロント =\"\"\n",
        "    if not 警告メッセージを非表示:\n",
        "        print('\\033[33m\"推奨ネガティブプロンプト\"がオフになっています。\\033[0m')\n",
        "\n",
        "\n",
        "negative_prompt2 = N_prompt + おすすめのネガティブプロント\n",
        "\n",
        "if 枚数制限なし:\n",
        "    生成する枚数=100000\n",
        "\n",
        "\n",
        "def image_grid(imgs,cols): #縦よこ\n",
        "    all_num=len(imgs)\n",
        "    if all_num<cols:\n",
        "        cols=all_num\n",
        "    if all_num>1:\n",
        "        am=0\n",
        "        w, h = imgs[0].size\n",
        "        rows,b= divmod(all_num,cols)\n",
        "        if b!=0:\n",
        "            rows+=1\n",
        "            am=cols-b\n",
        "            white_img = Image.new(\"RGB\", (w,h), (255, 255, 255))\n",
        "            for x in range(am):\n",
        "                imgs.append(white_img)\n",
        "        grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "        grid_w, grid_h = grid.size\n",
        "        for i, img in enumerate(imgs):\n",
        "            grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    elif all_num==1:\n",
        "        grid=None\n",
        "        print(\"画像が1枚のためグリッド画像化できません\")\n",
        "    else:\n",
        "        grid=None\n",
        "        print(\"グリッド画像に使用可能な画像がありません。\")\n",
        "    return grid\n",
        "\n",
        "\n",
        "\n",
        "if not conect_drive:\n",
        "    if \"/content/drive/MyDrive\" in 保存する先のパス:\n",
        "      保存する先のパス=\"/content/Generated_images\"\n",
        "      print(\"\\033[31mGoogleドライブに接続されていないためデフォルトのパスに保存しました\\033[0m\")\n",
        "    else:\n",
        "      image_save_path=os.path.join(保存する先のパス,\"Images\")\n",
        "else:\n",
        "    保存する先のパス=\"/content/Generated_images\"\n",
        "    print(\"保存する先のパスが未入力のため、デフォルトのパスに保存しました。\")\n",
        "\n",
        "image_save_path=os.path.join(保存する先のパス,\"Images\")\n",
        "\n",
        "Grid_save_path=os.path.join(保存する先のパス,\"Grid\")\n",
        "os.makedirs(image_save_path, exist_ok=True)\n",
        "os.makedirs(Grid_save_path, exist_ok=True)\n",
        "\n",
        "if seed_number is None:\n",
        "    seed_number=-1\n",
        "\n",
        "def seed_set(seed_number):\n",
        "    global seed\n",
        "    if seed_number==-1:\n",
        "        seed = random.randint(1,1000000)\n",
        "    else:\n",
        "        seed=seed_number\n",
        "    return seed\n",
        "seed=seed_set(seed_number)\n",
        "\n",
        "\n",
        "def path_token_video(Prompt_4,seed_number,model_name,guidance_scale,file_name,image_save_path):\n",
        "    global L\n",
        "    try:\n",
        "        L+=1\n",
        "    except:\n",
        "        L=1\n",
        "    file_name_old=\"\"\n",
        "    if not file_name:\n",
        "        file_name=(\"Gvideo\")\n",
        "    now = datetime.datetime.now()\n",
        "    file_name_encoded = codecs.encode(file_name, 'utf-8')\n",
        "    file_name_decoded = codecs.decode(file_name_encoded, 'utf-8')\n",
        "    path_d = {\"{prompt}\":Prompt_4,\"{seed}\": seed, \"{model_name}\": model_name, \"{g_scale}\": guidance_scale,\"{time}\":now ,\"{number}\":L}\n",
        "    for key, value in path_d.items():\n",
        "        file_name_old = file_name_decoded.replace(key, str(value))\n",
        "    while True:\n",
        "        file_new=(f\"{file_name_old}-{L}.mp4\")\n",
        "        file_test = os.path.join(image_save_path , file_new)\n",
        "        if os.path.exists(file_test):\n",
        "            L+=1\n",
        "        else:\n",
        "           path_new=file_test\n",
        "           file_new=file_new\n",
        "           break\n",
        "    return path_new,file_new\n",
        "\n",
        "\n",
        "def path_token_img(Prompt_4,seed_number,model_name,guidance_scale,file_name,image_save_path):\n",
        "    global z\n",
        "    try:\n",
        "        z+=1\n",
        "    except:\n",
        "        z=1\n",
        "    file_name_old=\"\"\n",
        "    if not file_name:\n",
        "        file_name=(\"GIMG\")\n",
        "    now = datetime.datetime.now()\n",
        "    file_name_encoded = codecs.encode(file_name, 'utf-8')\n",
        "    file_name_decoded = codecs.decode(file_name_encoded, 'utf-8')\n",
        "    path_d = {\"{prompt}\":Prompt_4,\"{seed}\": seed, \"{model_name}\": model_name, \"{g_scale}\": guidance_scale,\"{time}\":now ,\"{number}\":z}\n",
        "    for key, value in path_d.items():\n",
        "        file_name_old = file_name_decoded.replace(key, str(value))\n",
        "    while True:\n",
        "        file_new=(f\"{file_name_old}-{z}.png\")\n",
        "        file_test = os.path.join(image_save_path , file_new)\n",
        "        if os.path.exists(file_test):\n",
        "            z+=1\n",
        "        else:\n",
        "            path_new=file_test\n",
        "            file_new=file_new\n",
        "            break\n",
        "    return path_new,file_new\n",
        "\n",
        "\n",
        "\n",
        "def play_mp4(path_new):\n",
        "    mp4 = open(path_new, 'rb').read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "    HTML_code=(f\"\"\"\n",
        "               <video width=\"70%\" height=\"70%\" controls>\n",
        "                     <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "               </video>\"\"\")\n",
        "    try:\n",
        "        display(HTML(HTML_code))\n",
        "    except:\n",
        "        display(HTML('<script>{}</script>'.format(HTML_code)))\n",
        "\n",
        "\n",
        "\n",
        "generator = torch.Generator(\"cuda\")\n",
        "\n",
        "\n",
        "class generate_class:\n",
        "    def __init__(self,Prompt_list,make_images_list,Grid_save_path,img_dir,img_path,img_dict,seed,generator,num_grid,Prompt_4,image_save_path,sd_step,model_name,file_name):\n",
        "        seed=seed\n",
        "        generator=generator\n",
        "        self.num_grid=num_grid\n",
        "        self.st=num\n",
        "        self.Prompt_4=Prompt_4\n",
        "        Prompt_4=Prompt_4\n",
        "        image_save_path=image_save_path\n",
        "        self.image_save_path=image_save_path\n",
        "        sd_step=sd_step\n",
        "        model_name=model_name\n",
        "        file_name=file_name\n",
        "        grid_img=None\n",
        "        self.img_dir=img_dir\n",
        "        self.img_path=img_path\n",
        "        self.img_dict=img_dict\n",
        "        self.Grid_save_path=Grid_save_path\n",
        "        self.init_image=None\n",
        "        self.grid_imgs=[]\n",
        "        self.generate_time_all_after=0\n",
        "        self.nsfw_content_detected=None\n",
        "        self.generate_time_all=0\n",
        "        self.generate_start_time=0\n",
        "        self.generate_end_time=0\n",
        "        self.i=0\n",
        "        self.CPU_P_do=False\n",
        "        self.CPU_P=None\n",
        "        self.GPU_P=None\n",
        "        Prompt_list,make_images_list=Prompt_list,make_images_list\n",
        "        self.generate_num=1\n",
        "        self.Prompt_use=\"\"\n",
        "\n",
        "    def generate_images(self,Prompt_list,make_images_list,seed,generator,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe):\n",
        "        for self.j in range(self.st):\n",
        "                #生成されない時ここのインデントを確認する\n",
        "                while True:\n",
        "                    if len(Prompt_list)>0:\n",
        "                        self.Prompt_use=Prompt_list.pop(0)\n",
        "                        break\n",
        "                    else:\n",
        "                        time.sleep(0.5)\n",
        "                        #continueがついていると、生成されない\n",
        "                Prompt_use=self.Prompt_use\n",
        "                path_new,file_new=path_token_img(Prompt_use,seed_number,model_name,guidance_scale,file_name,image_save_path)\n",
        "                if seed_number==-1:\n",
        "                    seed=seed_set(seed_number)\n",
        "                now = datetime.datetime.now()\n",
        "                date_str = now.strftime(\"%Y-%m-%d_UTC-%H:%M:%S\")\n",
        "                path = os.path.join(image_save_path, file_name)\n",
        "                generate_start_time = time.time()\n",
        "                generator.manual_seed(seed)\n",
        "                if パイプラインの種類 == \"img2img\":\n",
        "                    output = img2img_pipe(Prompt_use,image=self.init_image, strength=strength,negative_prompt=negative_prompt2, num_inference_steps=sd_step,guidance_scale=guidance_scale,generator=generator)\n",
        "                elif パイプラインの種類 == \"Inpaint\":\n",
        "                    output = Inpaint_pipe(Prompt_use,image=self.init_image, strength=strength,negative_prompt=negative_prompt2, num_inference_steps=sd_step,height=height,width=width,guidance_scale=guidance_scale,generator=generator)\n",
        "                elif パイプラインの種類 == \"safe\":\n",
        "                    safety_level_dict={\"MAX\":SafetyConfig.MAX,\n",
        "                                       \"STRONG\":SafetyConfig.STRONG,\n",
        "                                       \"MEDIUM\":SafetyConfig.MEDIUM,\n",
        "                                       \"WEAK\":SafetyConfig.WEAK,\n",
        "                                       }\n",
        "                    self.safety_level_choise = safety_level_dict[safety_level]\n",
        "                    output = safe_pipe(Prompt_use,negative_prompt=negative_prompt2, guidance_scale=guidance_scale, num_inference_steps=sd_step,height=height,width=width,generator=generator,**self.safety_level_choise  )\n",
        "                else:\n",
        "                    output = txt2img_pipe(Prompt_use, negative_prompt=negative_prompt2, guidance_scale=guidance_scale, num_inference_steps=sd_step,height=height,width=width,generator=generator)\n",
        "                self.nsfw_content_detected=output.nsfw_content_detected\n",
        "                make_image=output.images[0]\n",
        "                if self.nsfw_content_detected is None:\n",
        "                    bloke=False\n",
        "                else:\n",
        "                    if False in self.nsfw_content_detected:\n",
        "                        bloke=False\n",
        "                    else:\n",
        "                        bloke=True\n",
        "                info = make_image.info\n",
        "                metadata = {\n",
        "                    \"Seed\": seed,\n",
        "                    \"model\": model_name,\n",
        "                    \"G_scale\":guidance_scale,\n",
        "                    \"D_step\":sd_step,\n",
        "                    \"Prompt\": Prompt_use,\n",
        "                    \"n_prompt\":negative_prompt2\n",
        "                    }\n",
        "                generate_end_time = time.time()\n",
        "                self.generate_time = generate_end_time - generate_start_time\n",
        "                self.generate_time_all += self.generate_time\n",
        "                self.generate_time_after=(\"{:.2f}s\".format(self.generate_time))\n",
        "                if 枚数制限なし:\n",
        "                    text_0=(f\"\\033[34m画像生成が完了しました ({self.generate_num}/∞)  {self.generate_time_after}\")\n",
        "                else:\n",
        "                    text_0=(f\"\\033[34m画像生成が完了しました ({self.generate_num}/{self.st})  {self.generate_time_after}\")\n",
        "                text_1=(f\"\"\"{text_0}\\nseed値:\\033[38;2;0;255;255m {seed}\\n\\033[34mファイルの名前: \\033[32m{file_new}\\n\\033[0m\"\"\")\n",
        "                text_2=(f\"\\033[92mプロンプト:  {Prompt_use}\\033[0m\")\n",
        "                make_images_list.append([make_image,path_new,bloke,metadata,text_1,text_2])\n",
        "                if not bloke:\n",
        "                    self.grid_imgs.append(make_image)\n",
        "                else:\n",
        "                    pass\n",
        "                self.generate_num+=1\n",
        "\n",
        "    def last_task(self,make_images_list):\n",
        "        for T in range(self.st):\n",
        "            while True:\n",
        "                if len(make_images_list)>0:\n",
        "                    make_image,path_new,bloke,metadata,text_1,text_2=make_images_list.pop(0)\n",
        "                    break\n",
        "                else:\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "            if not bloke:\n",
        "                if 条件をメタデーターとして追加する or auto_G:\n",
        "                    pnginfo = PngImagePlugin.PngInfo()\n",
        "                    info = make_image.info\n",
        "                    for key, value in metadata.items():\n",
        "                        pnginfo.add_text(key, str(value))\n",
        "                    make_image.save(path_new, pnginfo=pnginfo)\n",
        "                else:\n",
        "                    make_image.save(path_new)\n",
        "            if 画像情報を表示 or auto_G:\n",
        "                print(text_1.format(T+1),end=\"\")\n",
        "                if not bloke:\n",
        "                    run_html_js(path_new,\"保存先のパス: \")\n",
        "            if 画像を表示 and not bloke:\n",
        "                print()\n",
        "                display(make_image)\n",
        "            if 画像情報を表示 or auto_G and not bloke:\n",
        "                print(text_2)\n",
        "            if bloke:\n",
        "                print(\"ブロックされました\\n\")\n",
        "\n",
        "    def grid_task(self):\n",
        "        try:\n",
        "            y=y\n",
        "        except:\n",
        "            y=1\n",
        "        while True:\n",
        "            grid_test_path=os.path.join(self.Grid_save_path,f\"Grid_imgs-{y}.png\")\n",
        "            if os.path.exists(grid_test_path):\n",
        "                y+=1\n",
        "            else:\n",
        "                grid_path=grid_test_path\n",
        "                break\n",
        "        if 生成する枚数>1:\n",
        "            grid = image_grid(self.grid_imgs,cols=self.num_grid)\n",
        "            if grid is not None:\n",
        "                grid.save(grid_path)\n",
        "                grid_img = Image.open(grid_path)\n",
        "                if グリッド画像を表示 or auto_G:\n",
        "                    run_html_js(grid_path,\"グリッド画像のパス: \")\n",
        "                    #print(f\"\\033[34mgrid_save_path: \\033[32m{grid_path}\\033[0m\")\n",
        "                    display(grid_img)\n",
        "        print(\"\\033[38;2;135;206;235m1枚あたりの生成時間の平均: {:.2f}s\\033[0m\".format(self.generate_time_all_after))\n",
        "\n",
        "    def generate_video(self,seed,generator,image_save_path,sd_step,model_name,file_name,txt2video_pipe):\n",
        "        T=1\n",
        "        chunk_size=4\n",
        "        path_new,file_new=path_token_video(self.Prompt_4,seed_number,model_name,guidance_scale,file_name,image_save_path)\n",
        "        now = datetime.datetime.now()\n",
        "        date_str = now.strftime(\"%Y-%m-%d_UTC-%H:%M:%S\")\n",
        "        path = os.path.join(image_save_path, file_name)\n",
        "        generate_start_time = time.time()\n",
        "        generator = torch.Generator(\"cuda\")\n",
        "        result = []\n",
        "        chunk_ids = np.arange(0, video_length, chunk_size - 1)\n",
        "        for T in range(len(chunk_ids)):\n",
        "            print(f\"Processing chunk {T + 1} / {len(chunk_ids)}\")\n",
        "            ch_start = chunk_ids[T]\n",
        "            ch_end = video_length if T == len(chunk_ids) - 1 else chunk_ids[T + 1]\n",
        "            frame_ids = [0] + list(range(ch_start, ch_end))\n",
        "            generator.manual_seed(seed)\n",
        "            output = txt2video_pipe(prompt=self.Prompt_4, video_length=len(frame_ids),num_inference_steps=sd_step,t0=(sd_step-5),t1=(sd_step-3) ,negative_prompt=negative_prompt2, guidance_scale=guidance_scale,height=height,width=width,generator=generator, frame_ids=frame_ids)\n",
        "            result.append(output.images[1:])\n",
        "\n",
        "        result = np.concatenate(result)\n",
        "        result = [(r * 255).astype(\"uint8\") for r in result]\n",
        "        imageio.mimsave(path_new, result, fps=4)\n",
        "        generate_end_time=time.time()\n",
        "        generate_time=generate_end_time-generate_start_time\n",
        "        print(f\"\\033[34m動画生成が完了しました  {generate_time}s\")\n",
        "        if 画像情報を表示:\n",
        "            print(f\"\\033[34mseed値:\\033[32m {seed}\")\n",
        "            print(f\"\\033[34mファイルの名前:( \\033[32m{file_new})\\033[0m\")\n",
        "            run_html_js(path_new,\"動画ファイルのパス: \")\n",
        "        play_mp4(path_new)\n",
        "\n",
        "    def main_2(self,Prompt_list,make_images_list,seed,generator,num_grid,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe):\n",
        "        if パイプラインの種類==\"txt2img\"or\"safe\":\n",
        "            self.generate_images(Prompt_list,make_images_list,seed,generator,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe)\n",
        "        else:\n",
        "            if not self.img_dir:\n",
        "                self.img_path=self.img_path\n",
        "                self.init_image=img_set(self.img_path)\n",
        "                self.generate_images(Prompt_list,make_images_list,seed,generator,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe)\n",
        "            else:\n",
        "                for img_path in self.img_dict:\n",
        "\n",
        "                    self.init_image=img_set(img_path)\n",
        "                    self.generate_images(Prompt_list,make_images_list,seed,generator,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe)\n",
        "\n",
        "\n",
        "    def main_t(self,seed,generator,num_grid,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe):\n",
        "        if __name__ == '__main__':\n",
        "            self.GPU_P = threading.Thread(target=self.main_2, args=(Prompt_list,make_images_list,seed,generator,num_grid,image_save_path,sd_step,model_name,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe))\n",
        "            self.GPU_last = threading.Thread(target=self.last_task,args=(make_images_list,))\n",
        "            self.GPU_P.start()\n",
        "            self.GPU_last.start()\n",
        "            self.GPU_last.join()\n",
        "        self.generate_time_all_after=self.generate_time_all/生成する枚数\n",
        "        self.grid_task()\n",
        "\n",
        "\n",
        "generate_cls=generate_class(Prompt_list,make_images_list,Grid_save_path,img_dir,img_path,img_dict,seed,generator,num_grid,Prompt_4,image_save_path,sd_step,model_path,file_name)\n",
        "if パイプラインの種類==\"txt2video\":\n",
        "  generate_cls.generate_video(seed,generator,image_save_path,sd_step,model_path,file_name,txt2video_pipe)\n",
        "else:\n",
        "  generate_cls.main_t(seed,generator,num_grid,image_save_path,sd_step,model_path,file_name,txt2img_pipe,img2img_pipe,Inpaint_pipe,safe_pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_z_kzPCz5fP"
      },
      "outputs": [],
      "source": [
        "#@title   (option)埋め込みを適用 { run: \"auto\", display-mode: \"form\"}\n",
        "#@markdown >埋め込みを適用\n",
        "Repo_id_or_path = \"/content/drive/MyDrive/textjual8/Flans.safetensors\" # @param {type:\"string\"}\n",
        "weight_name= \"\" # @param {type:\"string\"}\n",
        "token = \"girl\" # @param {type:\"string\"}\n",
        "#@markdown * Repo_id_or_path : hugface_idまたはfile_pathの入力をお願いします。\n",
        "\n",
        "# @markdown * token : 埋め込みを呼び出す場合に\"Prompt\"または\"N_prompt\"のいずれかに入力お願いします。\n",
        "\n",
        "# @markdown * weight_name : Repo_idの場合にファイル名前を指定してください\n",
        "\n",
        "# @markdown step.3の終了後に使用可能です\n",
        "\n",
        "class add_textual(make_main_pipe):\n",
        "  def __init__(self,Repo_id_or_path,weight_name,token,txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe):\n",
        "     self.txt2img_pipe=txt2img_pipe\n",
        "     self.img2img_pipe=img2img_pipe\n",
        "     self.txt2video_pipe=txt2video_pipe\n",
        "     self.Inpaint_pipe=Inpaint_pipe\n",
        "     self.safe_pipe=safe_pipe\n",
        "     self.sta={}\n",
        "  def load_textual(self):\n",
        "    Custom_tokens=\"\"\n",
        "    do=True\n",
        "    if not (Repo_id_or_path and token)==\"\":\n",
        "      if not os.path.isfile(Repo_id_or_path):\n",
        "        if not weight_name==\"\":\n",
        "          raise TypeError(\"'weight_name' の入力をお願いします\" )\n",
        "        else:\n",
        "          self.sta[\"weight_name\"]=weight_name\n",
        "    else:\n",
        "      do=False\n",
        "    if do:\n",
        "      try:\n",
        "        if パイプラインの種類 == \"img2img\":\n",
        "          img2img_pipe.load_textual_inversion(Repo_id_or_path,**self.sta, token=token)\n",
        "        elif パイプラインの種類 == \"txt2video\":\n",
        "          txt2video_pipe.load_textual_inversion(Repo_id_or_path, **self.sta, token=token)\n",
        "        elif パイプラインの種類 ==\"Inpaint\":\n",
        "          Inpaint_pipe.load_textual_inversion(Repo_id_or_path, **self.sta, token=token)\n",
        "        else:\n",
        "          txt2img_pipe.load_textual_inversion(Repo_id_or_path,**self.sta, token=token)\n",
        "        print(f\"トークン{token}\")\n",
        "        token_dict.append(token)\n",
        "        a = ','.join([x for x in token_dict if x not in ['[', ']', \"'\"]])\n",
        "        Custom_tokens=f\"カスタムトークン: {a}\\n\"\n",
        "\n",
        "      except ValueError:\n",
        "        if token in token_dict:\n",
        "          print(\"すでに埋め込みは適用済みです\")\n",
        "          a = ','.join([x for x in token_dict if x not in ['[', ']', \"'\"]])\n",
        "          Custom_tokens=f\"カスタムトークン: {a}\\n\"\n",
        "        else:\n",
        "          print(\"カスタム埋め込みの適用に失敗しました\")\n",
        "    return Custom_tokens\n",
        "\n",
        "ct=add_textual(Repo_id_or_path,weight_name,token,txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe)\n",
        "Custom_tokens=ct.load_textual()\n",
        "print(Custom_tokens)\n",
        "\n",
        "ct=add_textual(Repo_id_or_path,weight_name,token,txt2img_pipe,img2img_pipe,txt2video_pipe,Inpaint_pipe,safe_pipe)\n",
        "Custom_tokens=ct.load_textual()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#サブ機能"
      ],
      "metadata": {
        "id": "iIEW0jvHK7I1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ5y7hyEiCpa",
        "outputId": "4d648f3d-b2f1-4e9a-a30a-f0a9253e8af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1250"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title メモリの初期化(Beta) {display-mode: \"form\"}\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "variable_names = [\"base_pipe\",\"txt2img_pipe\",\"img2img_pipe\",\"txt2video_pipe\",\"Inpaint_pipe\",\"safe_pipe\", \"tokenizer\"]\n",
        "\n",
        "for name in variable_names:\n",
        "    if name in globals():\n",
        "      del globals()[name]\n",
        "    if name in locals():\n",
        "      del locals()[name]\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#追加学習"
      ],
      "metadata": {
        "id": "XGWeO1rbLYfs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-PpdeFgFjwa"
      },
      "outputs": [],
      "source": [
        "#@title 埋め込みを学習 {display-mode: \"form\"}\n",
        "\n",
        "学習で使用するトークン = \"flans\" # @param {type:\"string\"}\n",
        "概念を説明する単語 = \"flandre\" # @param {type:\"string\"}\n",
        "学習ステップ = 50   # @param {type:\"number\"}\n",
        "\n",
        "入力する画像フォルダ = \"/content/drive/MyDrive/GS\" # @param {type:\"string\"}\n",
        "出力するフォルダ = \"/content/drive/MyDrive/textjual\" # @param {type:\"string\"}\n",
        "概念のタイプ = \"style\" # @param [\"style\",\"object\"]\n",
        "モデル名前_or_パス = \"runwayml/stable-diffusion-v1-5\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "\n",
        "出力ファイル名 = \"Flans\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "終了したらランタイムを切断 = False # @param {type:\"boolean\"}\n",
        "#@markdown sd1.5系列とsd2.1系列では埋め込みに互換性がありません。\n",
        "\n",
        "driveに接続 = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown >用語の説明\n",
        "# @markdown * placeholder_token : 学習内で、使用するトークンです。新しい概念を入力します。\n",
        "# @markdown * initializer_token : 新しい概念が何であるかを要約する単語です。\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive_cn=driveに接続\n",
        "if driveに接続:\n",
        "  if not drive._os.path.ismount('/content/drive'):\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except:\n",
        "      print(\"ドライブの接続に失敗しました。\")\n",
        "      drive_cn=False\n",
        "\n",
        "\n",
        "\n",
        "if  drive_cn==False and \"/content/drive/MyDrive\" in 出力するフォルダ:\n",
        "  raise TypeError(\"Googleドライブに接続されていないため、ドライブに保存できません。\")\n",
        "\n",
        "if not os.path.isdir(入力する画像フォルダ):\n",
        "  raise FileNotFoundError(\"画像フォルダが存在しません\")\n",
        "\n",
        "if 出力するフォルダ is None:\n",
        "  raise FileNotFoundError(\"結果を出力するフォルダを入力してください\")\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(出力するフォルダ,exist_ok=True)\n",
        "\n",
        "\n",
        "try:\n",
        "  import diffusers,transformers\n",
        "except:\n",
        "  !pip install transformers diffusers -q\n",
        "  import transformers,diffusers\n",
        "\n",
        "if not os.path.exists(\"/content/script/diffusers\"):\n",
        "  %cd /content/script\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \"setup_txt\" not in locals():\n",
        "  %cd /content/script/diffusers/examples/textual_inversion\n",
        "  !pip install -r ./requirements.txt -q\n",
        "  setup_txt=True\n",
        "\n",
        "import accelerate,torchvision,transformers,ftfy ,diffusers\n",
        "\n",
        "\n",
        "%cd /content/diffusers/examples/textual_inversion\n",
        "\n",
        "size=512\n",
        "if モデル名前_or_パス==\"runwayml/stable-diffusion-v1-5\":\n",
        "  size=512\n",
        "else:\n",
        "  size=768\n",
        "\n",
        "#exportは使用不可\n",
        "%env pretrained_model_name_or_path=$モデル名前_or_パス\n",
        "%env train_data_dir=$入力する画像フォルダ\n",
        "%env learnable_property=$概念のタイプ\n",
        "%env placeholder_token=$学習で使用するトークン\n",
        "%env initializer_token=$概念を説明する単語\n",
        "%env resolution=$size\n",
        "%env max_train_steps=$学習ステップ\n",
        "%env output_dir=$出力するフォルダ\n",
        "\n",
        "#--learning_rate=5  \\\n",
        "#--mixed_precision=\"fp16\" \\\n",
        "#learning_rateは整数\n",
        "!accelerate launch textual_inversion.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path \\\n",
        "  --train_data_dir=$train_data_dir \\\n",
        "  --learnable_property=$learnable_property \\\n",
        "  --placeholder_token=$placeholder_token \\\n",
        "  --initializer_token=$initializer_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=4 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --learning_rate=5  \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$output_dir\n",
        "\n",
        "base=os.path.join(出力するフォルダ,\"learned_embeds.safetensors\")\n",
        "if not 出力ファイル名==\"\":\n",
        "  after_name=出力ファイル名+\".safetensors\"\n",
        "  after=os.path.join(出力するフォルダ,after_name)\n",
        "  if os.path.exists(base):\n",
        "    os.rename(base,after)\n",
        "  else:\n",
        "    print(\"埋め込みファイルが見つかりませんでした。\")\n",
        "else:\n",
        "  after=base\n",
        "\n",
        "print(f\"\"\"\\033[34m\n",
        "学習が終了しました\n",
        "path: {after}\\033[0m\n",
        "\"\"\")\n",
        "\n",
        "if 終了したらランタイムを切断:\n",
        "  from google.colab import runtime\n",
        "  print(\"ランタイムを切断中...\")\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH1aO3M-zk5x"
      },
      "outputs": [],
      "source": [
        "#@title モデルを学習 {display-mode: \"form\"}\n",
        "\n",
        "学習で使用する単語 = \"Cat ears girl\" # @param {type:\"string\"}\n",
        "#概念を説明する単語 = \"\" # @param {type:\"string\"}\n",
        "学習ステップ = 20   # @param {type:\"number\"}\n",
        "\n",
        "入力する画像フォルダ = \"/content/drive/MyDrive/GS\" # @param {type:\"string\"}\n",
        "出力するフォルダ = \"/content/drive/MyDrive/make_model_2\" # @param {type:\"string\"}\n",
        "#概念のタイプ = \"style\" # @param [\"style\",\"object\"]\n",
        "モデル名前_or_パス = \"/content/drive/MyDrive/loliDiffusion_SFW_.safetensors\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\"] {allow-input: true}\n",
        "#出力ファイル名 = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "終了したらランタイムを切断 = False # @param {type:\"boolean\"}\n",
        "#@markdown sd1.5系列とsd2.1系列では埋め込みに互換性がありません。\n",
        "\n",
        "driveに接続 = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown >用語の説明\n",
        "# @markdown * placeholder_token : 学習内で、使用するトークンです。新しい概念を入力します。\n",
        "# @markdown * initializer_token : 新しい概念が何であるかを要約する単語です。\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive_cn=driveに接続\n",
        "if driveに接続:\n",
        "  if not drive._os.path.ismount('/content/drive'):\n",
        "    try:\n",
        "      drive.mount('/content/drive')\n",
        "    except:\n",
        "      print(\"ドライブの接続に失敗しました。\")\n",
        "      drive_cn=False\n",
        "\n",
        "\n",
        "\n",
        "if  drive_cn==False and \"/content/drive/MyDrive\" in 出力するフォルダ:\n",
        "  raise TypeError(\"Googleドライブに接続されていないため、ドライブに保存できません。\")\n",
        "\n",
        "if not os.path.isdir(入力する画像フォルダ):\n",
        "  raise FileNotFoundError(\"画像フォルダが存在しません\")\n",
        "\n",
        "if 出力するフォルダ is None:\n",
        "  raise FileNotFoundError(\"結果を出力するフォルダを入力してください\")\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(出力するフォルダ,exist_ok=True)\n",
        "try:\n",
        "  import diffusers,transformers\n",
        "except:\n",
        "  !pip install transformers diffusers -q\n",
        "  import transformers,diffusers\n",
        "\n",
        "if not os.path.exists(\"/content/script/diffusers\"):\n",
        "  %cd /content/script\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "  %cd diffusers\n",
        "\n",
        "try:\n",
        "  import accelerate,transformers,ftfy\n",
        "except:\n",
        "  !pip install -q accelerate>=0.16.0 transformers>=4.25.1 ftfy Jinja2 bitsandbytes\n",
        "  import bitsandbytes,accelerate,transformers,ftfy\n",
        "import accelerate,torchvision,transformers,ftfy ,diffusers,bitsandbytes\n",
        "\n",
        "size=512\n",
        "if モデル名前_or_パス==\"runwayml/stable-diffusion-v1-5\":\n",
        "  size=512\n",
        "#else:\n",
        "#  size=768\n",
        "\n",
        "#exportは使用不可\n",
        "%env pretrained_model_name_or_path=$モデル名前_or_パス\n",
        "%env train_data_dir=$入力する画像フォルダ\n",
        "%env placeholder_token=$学習で使用する単語\n",
        "%env resolution=$size\n",
        "%env max_train_steps=$学習ステップ\n",
        "%env output_dir=$出力するフォルダ\n",
        "\n",
        "\n",
        "%cd /content/script/diffusers/examples/textual_inversion\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$pretrained_model_name_or_path  \\\n",
        "  --instance_data_dir=$train_data_dir \\\n",
        "  --output_dir=$output_dir \\\n",
        "  --instance_prompt=$placeholder_token \\\n",
        "  --resolution=$resolution \\\n",
        "  --train_batch_size=1 \\\n",
        "  --learning_rate=1 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "\n",
        "base=os.path.join(出力するフォルダ,\"learned_embeds.safetensors\")\n",
        "if not 出力ファイル名==\"\":\n",
        "  after_name=出力ファイル名+\".safetensors\"\n",
        "  after=os.path.join(出力するフォルダ,after_name)\n",
        "  if os.path.exists(base):\n",
        "    os.rename(base,after)\n",
        "  else:\n",
        "    print(\"埋め込みファイルが見つかりませんでした。\")\n",
        "else:\n",
        "  after=base\n",
        "\n",
        "print(f\"\"\"\\033[34m\n",
        "学習が終了しました\n",
        "path: {出力するフォルダ}\\033[0m\n",
        "\"\"\")\n",
        "\n",
        "if 終了したらランタイムを切断:\n",
        "  from google.colab import runtime\n",
        "  print(\"ランタイムを切断中...\")\n",
        "  runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#追加機能"
      ],
      "metadata": {
        "id": "DnKRJORxLhwS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxGYicFhvS6Y"
      },
      "outputs": [],
      "source": [
        "#@title 画像のメタデータを見る  {display-mode: \"form\"}\n",
        "from PIL import Image, PngImagePlugin\n",
        "import os\n",
        "image_metadata_path = \"/content/drive/MyDrive/ima/Images/GIMG-60.png\" #@param {type:\"string\"}\n",
        "if not os.path.exists(image_metadata_path):\n",
        "  raise FileNotFoundError(\"ファイルが見つかりませんでした\")\n",
        "try:\n",
        "  output_info = Image.open(image_metadata_path).info\n",
        "except:\n",
        "  raise FileNotFoundError(\"画像を読み込めませんでした\")\n",
        "\n",
        "try:\n",
        "  print(\"seed: \"+output_info[\"Seed\"]+\"\\n\")\n",
        "  print(\"diffusion_step: \"+output_info[\"D_step\"]+\"\\n\")\n",
        "  print(\"guidance_scale: \"+output_info[\"G_scale\"]+\"\\n\")\n",
        "  print(\"model_name : \"+output_info[\"model\"]+\"\\n\")\n",
        "  print(\"prompt: \"+output_info[\"Prompt\"]+\"\\033[0m\\n\")\n",
        "except:\n",
        "  print(\"\\033[31mメタデーターが見つかりませんでした\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC3E3W81SL8n"
      },
      "outputs": [],
      "source": [
        "#@title  グリッド画像の分割  (iamge generation){display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "\n",
        "### 各定数の設定\n",
        "# 縦方向分割数\n",
        "\n",
        "# 分割元ファイルパス\n",
        "input_path = \"\" # @param {type:\"string\"}\n",
        "output_dir = \"\" # @param {type:\"string\"}\n",
        "縦の分割回数 = 1 # @param {type:\"number\"}\n",
        "横の分割回数 = 3 # @param {type:\"number\"}\n",
        "#@markdown >heightとwidthは2以上の自然数の入力をお願いします\n",
        "height=縦の分割回数\n",
        "width=横の分割回数\n",
        "base_img_path=input_path\n",
        "\n",
        "\n",
        "if base_img_path==\"\" or  output_dir == \"\":\n",
        "  raise TypeError(\"pathが未入力です\")\n",
        "if output_dir is not dir:\n",
        "   output_dir = os.path.dirname(output_dir)\n",
        "\n",
        "def is_positive_integer(value):\n",
        "    try:\n",
        "        value = int(value)  # 整数に変換\n",
        "        if value > 0:  # 1以上の場合は True を返す\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except ValueError:  # ValueError が発生した場合は False を返す\n",
        "        return False\n",
        "\n",
        "if not is_positive_integer(height) or is_positive_integer(width):\n",
        "  raise TypeError(\"heightとwidthは、2以上の自然数である必要があります。\")\n",
        "\n",
        "def ImgSplit(im,w,h):\n",
        "    # 読み込んだ画像の高さと幅を指定分割数で割る\n",
        "    HEIGHT = h / height\n",
        "    WIDTH = w / width\n",
        "\n",
        "    # 縦の分割枚数\n",
        "    for h1 in range(height):\n",
        "        # 横の分割枚数\n",
        "        for w1 in range(width):\n",
        "            w2 = w1 * WIDTH\n",
        "            h2 = h1 * HEIGHT\n",
        "            yield im.crop((w2, h2, WIDTH + w2, HEIGHT + h2))\n",
        "\n",
        "#if __name__ == '__main__': このセルが直接実行された場合\n",
        "    # 画像の読み込み\n",
        "im = Image.open(base_img_path)\n",
        "w = im.size[0]\n",
        "h = im.size[1]\n",
        "length = math.log10(height * width) + 1\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for number, ig in enumerate(ImgSplit(im,w,h), 1):\n",
        "    # 出力\n",
        "    ig.save(output_dir + \"/\" + str(number).zfill(int(length)) + \".PNG\", \"PNG\")\n",
        "print(f\"\\033[34m分割が完了しました: {output_dir}\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3al9BGGP7DIR"
      },
      "outputs": [],
      "source": [
        "#@title  単語が含まれているファイルを移動{display-mode: \"form\"}\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def move_files_with_keyword(source_dir, destination_dir, keyword):\n",
        "    # 指定されたディレクトリ内のファイルを取得\n",
        "    files = os.listdir(source_dir)\n",
        "\n",
        "    for file in files:\n",
        "        # ファイル名にキーワードが含まれているかチェック\n",
        "        if keyword in file:\n",
        "            # 移動元のファイルパス\n",
        "            source_file = os.path.join(source_dir, file)\n",
        "            # 移動先のファイルパス\n",
        "            destination_file = os.path.join(destination_dir, file)\n",
        "\n",
        "            # ファイルを移動\n",
        "            shutil.move(source_file, destination_file)\n",
        "\n",
        "# 使用例\n",
        "検索対象のフォルダ = \"/content/drive/MyDrive/GS\"  # @param {type:\"string\"}\n",
        "移動先 = \"/content/drive/MyDrive/GS_grid\"   # @param {type:\"string\"}\n",
        "単語 = \"grid_imgs\" # @param {type:\"string\"}\n",
        "\n",
        "source_directory=検索対象のフォルダ\n",
        "destination_directory=移動先\n",
        "keyword_to_search=単語\n",
        "os.makedirs(destination_directory)\n",
        "move_files_with_keyword(source_directory, destination_directory, keyword_to_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH5cPNi297Lr"
      },
      "outputs": [],
      "source": [
        "#@title  ダウンロード{display-mode: \"form\"}\n",
        "#@markdown >ファイル or ディレクトリを指定してダウンロードします。\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "path = \"/content/Generated_images/GIMG-27.png\" #@param {type:\"string\"}\n",
        "\n",
        "# 最後が特定の単語であるかをチェックする\n",
        "if path.endswith(\".png\" or \".jpg\"):\n",
        "  try:\n",
        "    files.download(path)\n",
        "    print(\"\\033[32mダウンロードが正常に完了しました\")\n",
        "  except:\n",
        "    print(\"\\033[31m指定された画像が見つかりませんでした\\033[0m\")\n",
        "elif path.endswith(\".mp4\"):\n",
        "  try:\n",
        "    files.download(path)\n",
        "    print(\"\\033[32mダウンロードが正常に完了しました\")\n",
        "  except:\n",
        "    print(\"\\033[31m指定された動画ファイルが見つかりませんでした\\033[0m\")\n",
        "else:\n",
        "  try:\n",
        "    zip_number+=1\n",
        "  except:\n",
        "    zip_number=1\n",
        "  zip_name=f\"Generated_images-No.{zip_number}\"\n",
        "  zip_save_dir=os.path.join(\"/content\",zip_name)\n",
        "  zippath=zip_save_dir+\".zip\"\n",
        "  try:\n",
        "    shutil.make_archive(zip_save_dir, \"zip\", images_save_dir_path)\n",
        "    files.download(zippath)\n",
        "    print(\"\\033[32mzipファイルへ圧縮が正常に完了しました\")\n",
        "    print(f'zipファイル名前は\\033[34m\"{zip_name}\"\\033[32mですご確認ください\\033[0m')\n",
        "  except:\n",
        "    zip_number-=1\n",
        "    print(\"\\033[31m指定されたディレクトリが見つかりませんでした\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRRD_VF59fA_"
      },
      "outputs": [],
      "source": [
        "#@title 画像変換 {display-mode: \"form\"}\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "input_path = \"\" #@param {type:\"string\"}\n",
        "output_path=\"\" #@param {type:\"string\"}\n",
        "Change_mode = \"png2jpg\" # @param [\"png2jpg\", \"jpg2png\"]\n",
        "\n",
        "#@markdown * png2jpg :png画像をjpg画像に変換します。\n",
        "\n",
        "\n",
        "#@markdown * jpg2png :jpg画像をpng画像に変換します。\n",
        "\n",
        "if not os.path.exists(input_path):\n",
        "  #raise FileNotFoundError('\\033[33m指定された \"dir\"または\"file\" が見つかりませんでした。\\033[0m')\n",
        "  sys.exit('\"input_path\"にdirまたはfileのパスを入力お願いします。')\n",
        "\n",
        "if not input_path.endswith(\".png\" or \".jpg\" or \".jpeg\"):\n",
        "  if output_path==\"\":\n",
        "    # 保存先のディレクトリパスを作成\n",
        "    save_dir_path = input_path +\"-\" +Change_mode\n",
        "  else:\n",
        "    save_dir_path=output_path\n",
        "  # 保存先のディレクトリが存在しない場合は作成する\n",
        "  if not os.path.exists(save_dir_path):\n",
        "    os.makedirs(save_dir_path)\n",
        "\n",
        "  # ディレクトリ内のファイルを取得\n",
        "  file_list = os.listdir(input_path)\n",
        "\n",
        "  # ファイルごとに処理を行う\n",
        "  for file_name in file_list:\n",
        "    # ファイルのパスを作成\n",
        "    file_path = os.path.join(save_dir_path, file_name)\n",
        "\n",
        "    # ファイルの拡張子を取得\n",
        "    file_extension = os.path.splitext(file_name)[1]\n",
        "    if Change_mode == \"png2jpg\":\n",
        "    # 最後が特定の単語であるかをチェックする\n",
        "      if file_extension.endswith(\".png\"):\n",
        "        try:\n",
        "          # 画像を開く\n",
        "          im = Image.open(file_path)\n",
        "          file_name_new = file_name.replace(\".png\", \".jpg\")#pngをjpg\n",
        "          # 保存先のファイルパスを作成\n",
        "          save_file_path = os.path.join(save_dir_path, file_name_new)\n",
        "          # 変換後の画像を保存する\n",
        "          im.save(save_file_path,format=\"JPEG\")\n",
        "          print(f\"\\033[34m{save_file_path}を保存しました。\\033[0m\")\n",
        "        except Exception as e:\n",
        "          print(f\"\\033[31m{file_name}の変換中にエラーが発生しました: {str(e)}\\033[0m\")\n",
        "      else:\n",
        "        print(f\"{file_name}はpngファイルではないため、変換をスキップしました。\")\n",
        "    elif Change_mode == \"jpg2png\":\n",
        "        try:\n",
        "          # 画像を開く\n",
        "          im = Image.open(file_path)\n",
        "          file_name_new = file_name.replace((\".jpg\"or\".jpeg\"), \".png\")#jpgをpng\n",
        "          # 保存先のファイルパスを作成\n",
        "          save_file_path = os.path.join(save_dir_path, file_name_new)\n",
        "          # 変換後の画像を保存する\n",
        "          im.save(save_file_path,format=\"PNG\")\n",
        "          print(f\"\\033[34m{save_file_path}を保存しました。\\033[0m\")\n",
        "        except Exception as e:\n",
        "          print(f\"\\033[31m{file_path}の変換中にエラーが発生しました: {str(e)}\\033[0m\")\n",
        "else:\n",
        "  if Change_mode ==\"png2jpg\":\n",
        "    if not output_path==\"\":\n",
        "      basename_new = input_path.replace(\".png\", \".jpg\")#jpgをpng\n",
        "      save_file_path=os.path.join(output_path, basename_new)\n",
        "      im = Image.open(input_path)\n",
        "      im.save(save_file_path,format=\"JPEG\")\n",
        "    else:\n",
        "      im = Image.open(input_path)\n",
        "      save_file_path = input_path.replace(\".png\", \".jpg\")\n",
        "      im.save(save_file_path,format=\"JPEG\")\n",
        "    print(f'\\033[34m\"{save_file_path}\"に保存しました。\\033[0m')\n",
        "  elif Change_mode == \"jpg2png\":\n",
        "    if not output_path==\"\":\n",
        "      basename_new = input_path.replace((\".jpg\"or\".jpeg\"), \".png\")#jpgをpng\n",
        "      save_file_path=os.path.join(output_path, basename_new)\n",
        "      im = Image.open(input_path)\n",
        "      im.save(save_file_path,format=\"PNG\")\n",
        "    else:\n",
        "      im = Image.open(input_path)\n",
        "      save_file_path = input_path.replace((\".jpg\"or\".jpeg\"), \".png\")\n",
        "      im.save(save_file_path,format=\"PNG\")\n",
        "    print(f'\\033[34m\"{save_file_path}\"に保存しました。\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyeuVK1DeJEv"
      },
      "outputs": [],
      "source": [
        "#@title mp4を再生  {display-mode: \"form\"}\n",
        "MP4_path= \"\" #@param {type:\"string\"}\n",
        "# mp4動画の再生\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "try:\n",
        "  mp4 = open(MP4_path, 'rb').read()\n",
        "except:\n",
        "  raise FileNotFoundError(\"指定されたmp4が見つかりませんでした\")\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT_pKvlmJXIq"
      },
      "outputs": [],
      "source": [
        "#@title  文字列トークンカウンター{display-mode: \"form\"}\n",
        "import pprint\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "prompt = \"\"  #@param {type:\"string\"}\n",
        "try:\n",
        "  tokens = tokenizer.tokenize(prompt)\n",
        "except:\n",
        "  text_model_id = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(text_model_id)\n",
        "  tokens = tokenizer.tokenize(prompt)\n",
        "print(len(tokens))\n",
        "pprint.pprint(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-5Gh7XWLwcr"
      },
      "outputs": [],
      "source": [
        "#@title 高画質化  {display-mode: \"form\"}\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from diffusers import StableDiffusionUpscalePipeline\n",
        "import torch\n",
        "\n",
        "# load model and scheduler\n",
        "Prompt = \"\" #@param {type:\"string\"}\n",
        "prompt=\"masterpiece:2.0,best quality,high quality,\"+Prompt\n",
        "low_res_img_path = \"\" #@param {type:\"string\"}\n",
        "encoded_text = codecs.encode(low_res_img_path, 'utf-8')\n",
        "low_res_img_path = codecs.decode(encoded_text, 'utf-8')\n",
        "\n",
        "if \"pipeline2\" not in locals()  and \"pipeline2\" not in globals():\n",
        "  model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "  pipeline2 = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "    model_id, revision=\"fp16\", torch_dtype=torch.float16\n",
        "  )\n",
        "  pipeline2 = pipeline2.to(\"cuda\")\n",
        "if not os.path.exists(low_res_img_path):\n",
        "  raise FileNotFoundError(\"ファイルが見つかりませんでした\")\n",
        "try:\n",
        "  low_res_img = Image.open(low_res_img_path)\n",
        "except:\n",
        "  raise FileNotFoundError(\"画像を読み込めませんでした\")\n",
        "low_res_img = low_res_img.resize((128, 128))\n",
        "\n",
        "negative_prompt=\"low quality:2.0\"\n",
        "\n",
        "upscaled_image = pipeline2(prompt=prompt, image=low_res_img,negative_prompt=negative_prompt).images[0]\n",
        "\n",
        "try:\n",
        "  L+=1\n",
        "except:\n",
        "  L=1\n",
        "path1=(f\"/content/low_res_imgs/No{L}.png\")\n",
        "upscaled_image.save(path1)\n",
        "print(f\"画像保存パス: ({path1})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4kpwhy30ePA"
      },
      "outputs": [],
      "source": [
        "#@title 画像フォルダを削除  {display-mode: \"form\"}\n",
        "\n",
        "del_path = \"/content/drive/MyDrive/korect/Images\" #@param {type:\"string\"}\n",
        "if del_path ==\"\":\n",
        "  del_path=\"/content/Generated_images\"\n",
        "import shutil\n",
        "if not os.path.isdir(del_path):\n",
        "  raise TypeError(\"ディレクトリのみ削除が可能です\")\n",
        "#@markdown 未入力の場合 /content/Generated_imagesを削除します\n",
        "\n",
        "YorS=input(\"本当に削除しますか？[yes/no]: \")\n",
        "if YorS.lower() in (\"yes\", \"y\"): # 入力された文字列を小文字にして、yesやyと一致するか判定する\n",
        "  try:\n",
        "    shutil.rmtree(del_path)\n",
        "    print(\"削除しました\")\n",
        "  except FileNotFoundError:\n",
        "    print(f\"\\033[31m{del_path}が見つかりませんでした\\033[0m\")\n",
        "elif YorS.lower() in (\"no\", \"n\"): # 入力された文字列を小文字にして、noやnと一致するか判定する\n",
        "  print(\"フォルダの削除を中止しました\")\n",
        "else:\n",
        "  print(\"yes/no のみの入力をお願いします。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t-Qqqp6la4WJ"
      },
      "outputs": [],
      "source": [
        "#@title url_Download\n",
        "import urllib.request , os\n",
        "import datetime\n",
        "def download_file(url, save_path):\n",
        "  other_url,split=os.path.splitext(url)\n",
        "  if save_path==\"\":\n",
        "    save_path=\"/content/download\"\n",
        "    choice_name=input(\"ファイル名(拡張子無し): \")\n",
        "    choice_name+=split\n",
        "    test_path=os.path.join(save_path,choice_name)\n",
        "    if os.path.exists(test_path):\n",
        "      now=datetime.now()\n",
        "      save_path=test_path+now\n",
        "  save_dir=os.path.dirname(save_path)\n",
        "  os.makedirs(save_dir,exist_ok=True)\n",
        "  if not url.endswith(split):\n",
        "    save_path+=split\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "  except HTTPError:\n",
        "    raise SystemError(\"URLからファイルを習得できませんでした\")\n",
        "  print(f\"保存先のパス: {save_path}\")\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "save_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "download_file(url, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJXQRW_E3AsI"
      },
      "source": [
        "#**Readme**(日本語版)\n",
        "#利用規約\n",
        "\n",
        "本画像生成ノーブックを使用するにあたって、利用規約の内容に全て同意したとみなします。\n",
        "\n",
        "# **重要な注意点**：\n",
        "* **商用利用はご遠慮ください。**\n",
        "* **画像生成によって起こった問題について、当方は一切責任を負いません。**\n",
        "\n",
        ">免責事項:\n",
        "*  使用にあたっては、自己責任でお願いします。\n",
        "*  本モデルは予告なく変更・非公開・削除する可能性があります。\n",
        "*  利用規約は予告なく変更する場合があります。\n",
        "*  このモデルは、趣味で作成したものであり、商用利用などは意図していません。\n",
        "*  使用にあたって発生した通信量、電気料金など金銭に関わるものの負担は追い兼ねます\n",
        "*  Stable Diffusion-Ver2.1やその他の追加ライブラリに関する規約がある場合は、それらも確認することを強くお勧めします。\n",
        "*  本プロジェクトを利用することにより生じた一切の問題について、当方は一切責任を負いません。\n",
        "\n",
        "ー本プロジェクトとは、本画像生成ノートブックや、githubのページなどをさします\n",
        "___\n",
        "#本プロジェクトの説明\n",
        "・プログラミングの個人的な学習\n",
        "・Stable Diffusionをベースにした画像生成ノートブックです。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "謝辞\n",
        "\n",
        "本画像生成ノートブックの作成にあたり、オープンソースのリソースやフリーのツールを使用させていただきました。個人的な利用でしたが、これらのリソースやツールがあったからこそ、本プロジェクトを実現することができました。\n",
        "この場を借りて、オープンソースのコミュニティや、フリーのツールを提供してくださった方々に感謝の意を表します。素晴らしいツールや技術を提供してくださり、本プロジェクトを支援してくださったことに心から感謝いたします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKISm_HGOcgG"
      },
      "source": [
        "#**Readme(English_ver)**\n",
        "# Terms of Use\n",
        "\n",
        "By using this image generation notebook, you agree to all the contents of the Terms of Use.\n",
        "\n",
        "Important Notice:\n",
        "**Please refrain from using for commercial purposes.**\n",
        "**I am not responsible for any problems caused by image generation.**\n",
        "\n",
        ">Disclaimer:\n",
        "* Please use it at your own risk.\n",
        "* This NoteBook may be changed, unpublished, or deleted without notice.\n",
        "* The terms of use may be changed without notice.\n",
        "* This NoteBook is created for personal use and is not intended for commercial use.\n",
        "* If there are terms and conditions for Stable Diffusion-Ver2.1 and other additional libraries, it is strongly recommended to confirm them as well.\n",
        "* I am not responsible for any problems caused by using this project.\n",
        "\n",
        "ー This project refers to the image generation notebook and GitHub pages.\n",
        "\n",
        "---\n",
        "\n",
        "# Description of this project\n",
        "\n",
        "This is an image generation notebook based on Stable Diffusion.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Acknowledgements\n",
        "\n",
        "I used open source resources and free tools to create this image generation notebook. Although it was for personal use, it was only possible to realize this project because of these resources and tools.\n",
        "I would like to express my gratitude to the open source community and those who provide free tools. I sincerely appreciate your support for this project by providing great tools and technologies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QBK6ZmVwqOW"
      },
      "source": [
        "もしかしたら日本文をいれるといいかもしれません。\n",
        "\n",
        "masterpiece:2.0,best quality,high quality,cat ears,りんご,春,smail,cute,loli,fantasy art,beautiful,artstation,trending on artstation,alluring,masterpiece"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XGWeO1rbLYfs",
        "DnKRJORxLhwS"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}